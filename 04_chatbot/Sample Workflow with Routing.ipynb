{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5d50fa-aff8-4da5-a04f-ccf1741f2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import (\n",
    "    RetrievalQA,\n",
    "    ConversationalRetrievalChain,\n",
    "    RetrievalQAWithSourcesChain,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import pandas as pd\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from semantic_router import Route, RouteLayer\n",
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abca920e-4920-46df-8a0f-9314293dfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting some helper variables\n",
    "\n",
    "retrieval_strategy = \"colbert\"\n",
    "model = \"mistral-7b-instruct-v0.2\"\n",
    "\n",
    "rootdir = \"..\"\n",
    "persist_directory = \"./../embeddings\"\n",
    "index_root = rootdir + \"/../colbert_index/\"\n",
    "colbert_path = rootdir + \"/../colbertv2.0/\"\n",
    "index_path = rootdir + \"/../colbert_index/colbert/indexes/documents/\"\n",
    "transcript_path = rootdir + \"/../colbert_index/colbert/indexes/transcripts/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6762a64b-75b6-4d0d-a58b-2772ab803e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 07, 13:03:30] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Start Colbert models for documents and transcripts\n",
    "RAG1 = RAGPretrainedModel.from_index(index_path = index_path)\n",
    "RAG2 = RAGPretrainedModel.from_index(index_path = transcript_path)\n",
    "\n",
    "# Get metadata for both models and convert to DataFrame\n",
    "df_rag1 = pd.read_json(index_path+'docid_metadata_map.json').T.reset_index()\n",
    "df_rag2 = pd.read_json(transcript_path+'docid_metadata_map.json').T.reset_index()\n",
    "\n",
    "# Helper to identify relevant documents for retrievers\n",
    "def filter_pids(df, search_term):\n",
    "    return list(df['index'][df.course_number==search_term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c81e82-cc39-4dd6-9ccc-c484faf755c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = {\n",
    "    \"501\": \"Being a Data Scientist\",\n",
    "    \"502\": \"Math Methods I\",\n",
    "    \"503\": \"Data Science Ethics\",\n",
    "    \"505\": \"Data Manipulation\",\n",
    "    \"511\": \"SQL and Databases\",\n",
    "    \"515\": \"Efficient Data Processing\",\n",
    "    \"516\": \"Big Data: Scalable Data Processing\",\n",
    "    \"521\": \"Visual Exploration of Data\",\n",
    "    \"522\": \"Information Visualization I\",\n",
    "    \"523\": \"Communicating Data Science Results\",\n",
    "    \"524\": \"Presenting Uncertainty\",\n",
    "    \"532\": \"Data Mining I\",\n",
    "    \"542\": \"Supervised Learning\",\n",
    "    \"543\": \"Unsupervised Learning\",\n",
    "    \"571\": \"Business SQL\",  # No syllabus for this one :(\n",
    "    \"593\": \"Milestone I\",\n",
    "    \"601\": \"Qualitative Inquiry for Data Scientists\",\n",
    "    \"602\": \"Math Methods II\",\n",
    "    \"611\": \"Database Architecture & Technology\",\n",
    "    \"622\": \"Information Visualization II\",\n",
    "    \"630\": \"Causal Inference\",\n",
    "    \"631\": \"Experiment Design and Analysis\",\n",
    "    \"632\": \"Data Mining II\",\n",
    "    \"642\": \"Deep Learning I\",\n",
    "    \"643\": \"Machine Learning Pipelines\",\n",
    "    \"644\": \"Reinforcement Learning Algorithms\",\n",
    "    \"652\": \"Network Analysis\",\n",
    "    \"655\": \"Applied Natural Language Processing\",\n",
    "    \"673\": \"Cloud Computing\",\n",
    "    \"680\": \"Learning Analytics and Educational Data Science\",\n",
    "    \"681\": \"Health Analytics\",\n",
    "    \"682\": \"Social Media Analytics\",\n",
    "    \"685\": \"Search and Recommender Systems\",\n",
    "    \"687\": \"Introduction to Sports Analytics\",\n",
    "    \"688\": \"Data Science for Social Good\",\n",
    "    \"696\": \"Milestone II\",\n",
    "    \"699\": \"Capstone\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9972be7-c2b7-428f-a75c-9585e2598bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-07 13:03:31 INFO semantic_router.utils.logger local\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build semantic routes for each class\n",
    "routes = []\n",
    "for num, name in zip(courses.keys(), courses.values()):\n",
    "    route_name = \"SIADS \" + str(num)\n",
    "    route_utterances = [route_name.lower(), route_name.lower().replace(\" \",\"\"),\n",
    "                        name.lower(), name.lower() + \" class\", name.lower() + \" course\"]\n",
    "    routes.append(Route(name=route_name, utterances=route_utterances))\n",
    "\n",
    "# Select local encoder and build route layer\n",
    "encoder = HuggingFaceEncoder(str=\"/Users/arnewman/.cache/huggingface/hub/models--sentence-transformers--UAE-Large-V1/\", device=\"mps\")\n",
    "rl = RouteLayer(encoder=encoder, routes=routes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e5a99cd-1db9-4353-8efc-cf7e494fbbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIADS 652\n"
     ]
    }
   ],
   "source": [
    "# Select relevant documents based on query and create retrievers\n",
    "# If relevant documents cannot be identified, build retrievers on all documents\n",
    "# Separate retrievers from the documents index and the transcripts index\n",
    "\n",
    "query = \"What are the week 3 assignments in the network analysis class?\"\n",
    "r = rl(query)\n",
    "print(r.name if r.name else \"No match\")\n",
    "\n",
    "if r.name:\n",
    "    doc_list = filter_pids(df_rag1, r.name)\n",
    "    if len(doc_list) > 0:\n",
    "        retriever1 = RAG1.as_langchain_retriever(k=5, doc_ids=doc_list)        \n",
    "    trans_list = filter_pids(df_rag2, r.name)\n",
    "    if len(trans_list) > 0:\n",
    "        retriever2 = RAG2.as_langchain_retriever(k=5, doc_ids=trans_list)\n",
    "else:\n",
    "    retriever1 = RAG1.as_langchain_retriever(k=5)\n",
    "    retriever2 = RAG2.as_langchain_retriever(k=5)\n",
    "\n",
    "retriever = EnsembleRetriever(retrievers=[retriever1, retriever2], weights=[0.5, 0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21765aca-43b1-406b-b772-7f84f1be008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "llm_open = OpenAI(openai_api_base = \"http://localhost:7999/v1\",\n",
    "                  model = \"mistral-7b-instruct-v0.2\",\n",
    "                  openai_api_key = \"hello\",\n",
    "                  temperature = 0.1,\n",
    "                  top_p = 1,\n",
    "                  max_tokens = 1024,\n",
    "                  callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "\n",
    "# Set prompt template\n",
    "\n",
    "template = '''\n",
    "Use only the following pieces of context to answer the question at the end. \n",
    "Keep your answers concise and do not provide additional explanations or interpretations. \n",
    "If the answer cannot be deduced from the context, just say that you don't know the answer, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "'''\n",
    "\n",
    "# Define processing chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_open,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"])},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84339208-d2eb-441b-8296-79ffebf3dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display results\n",
    "def process_llm_response(llm_response):\n",
    "    print(f\"\\nQuestion: {llm_response['query']}\")\n",
    "    print(f\"\\nAnswer: {llm_response['result']}\")\n",
    "    print(\"\\n\\nSources:\")\n",
    "    for i, source in enumerate(llm_response[\"source_documents\"]):\n",
    "        m = source.metadata\n",
    "        try:\n",
    "            print(f\"{i + 1}. {m['course_title']} ({m['course_number']}): {m['heading']}\")\n",
    "        except:\n",
    "            print(f\"{i + 1}. {m['course_title']} ({m['course_number']}): {m['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4467a7f-13f0-4135-9dfb-d0e87ce8ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "Loading searcher for index documents for the first time... This may take a few seconds\n",
      "[Apr 07, 13:06:17] #> Loading codec...\n",
      "[Apr 07, 13:06:17] #> Loading IVF...\n",
      "[Apr 07, 13:06:17] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 07, 13:06:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 843.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 07, 13:06:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 44.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 07, 13:06:18] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 07, 13:06:18] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What are the week 3 assignments in the network analysis class?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2024,  1996,  2733,  1017, 14799,  1999,  1996,\n",
      "         2897,  4106,  2465,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "Loading searcher for index transcripts for the first time... This may take a few seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 07, 13:06:18] #> Loading codec...\n",
      "[Apr 07, 13:06:18] #> Loading IVF...\n",
      "[Apr 07, 13:06:18] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1259.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 07, 13:06:18] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.74it/s]\n",
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . What are the week 3 assignments in the network analysis class?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2054,  2024,  1996,  2733,  1017, 14799,  1999,  1996,\n",
      "         2897,  4106,  2465,  1029,   102,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Question: What are the week 3 assignments in the network analysis class?\n",
      "\n",
      "Answer: The week 3 assignments in the network analysis class include programming and reflection questions aimed at applying network analysis concepts covered in lectures and readings using NetworkX tutorials. The assignments will be partly auto-graded and partly manually graded. The goal is to analyze both real and synthetic networks.\n",
      "\n",
      "\n",
      "Sources:\n",
      "1. Network Analysis (SIADS 652): 04_link-prediction.en.txt\n",
      "2. Network Analysis (SIADS 652): Assignment And Quizzes\n",
      "3. Network Analysis (SIADS 652): Grading\n",
      "4. Network Analysis (SIADS 652): 04_link-prediction.en.txt\n",
      "5. Network Analysis (SIADS 652): 04_the-small-world-phenomenon.en.txt\n",
      "6. Network Analysis (SIADS 652): Course Schedule\n",
      "7. Network Analysis (SIADS 652): 01_random-graphs.en.txt\n",
      "8. Network Analysis (SIADS 652): Course Syllabus For SIADS 652: Network Analysis\n",
      "9. Network Analysis (SIADS 652): Course Communication Expectations\n",
      "10. Network Analysis (SIADS 652): 06_applications.en.txt\n"
     ]
    }
   ],
   "source": [
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96cbf6-d790-44a9-b616-0e970bf44469",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
