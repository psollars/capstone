{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af5d50fa-aff8-4da5-a04f-ccf1741f2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import (\n",
    "    RetrievalQA,\n",
    "    ConversationalRetrievalChain,\n",
    "    RetrievalQAWithSourcesChain,\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import pandas as pd\n",
    "from ragatouille import RAGPretrainedModel\n",
    "from semantic_router import Route, RouteLayer\n",
    "from semantic_router.encoders import HuggingFaceEncoder\n",
    "\n",
    "import gradio as gr\n",
    "from json2html import Json2Html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abca920e-4920-46df-8a0f-9314293dfe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting some helper variables\n",
    "\n",
    "retrieval_strategy = \"colbert\"\n",
    "model = \"mistral-7b-instruct-v0.2\"\n",
    "\n",
    "rootdir = \"..\"\n",
    "persist_directory = \"./../embeddings\"\n",
    "index_root = rootdir + \"/../colbert_index/\"\n",
    "colbert_path = rootdir + \"/../colbertv2.0/\"\n",
    "index_path = rootdir + \"/../colbert_index/colbert/indexes/documents/\"\n",
    "transcript_path = rootdir + \"/../colbert_index/colbert/indexes/transcripts/\"\n",
    "combined_path = rootdir + \"/../colbert_index/colbert/indexes/combined/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6762a64b-75b6-4d0d-a58b-2772ab803e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 20:29:09] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Start Colbert models for documents and transcripts\n",
    "# RAG1 = RAGPretrainedModel.from_index(index_path = index_path)\n",
    "# RAG2 = RAGPretrainedModel.from_index(index_path = transcript_path)\n",
    "RAG = RAGPretrainedModel.from_index(index_path = combined_path)\n",
    "\n",
    "# Get metadata for both models and convert to DataFrame\n",
    "# df_rag1 = pd.read_json(index_path+'docid_metadata_map.json').T.reset_index()\n",
    "# df_rag2 = pd.read_json(transcript_path+'docid_metadata_map.json').T.reset_index()\n",
    "df_rag = pd.read_json(combined_path+'docid_metadata_map.json').T.reset_index()\n",
    "\n",
    "# Helper to identify relevant documents for retrievers\n",
    "def filter_pids(df, search_term):\n",
    "    return list(df['index'][df.course_number==search_term])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c81e82-cc39-4dd6-9ccc-c484faf755c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = {\n",
    "    \"501\": \"Being a Data Scientist\",\n",
    "    \"502\": \"Math Methods I\",\n",
    "    \"503\": \"Data Science Ethics\",\n",
    "    \"505\": \"Data Manipulation\",\n",
    "    \"511\": \"SQL and Databases\",\n",
    "    \"515\": \"Efficient Data Processing\",\n",
    "    \"516\": \"Big Data: Scalable Data Processing\",\n",
    "    \"521\": \"Visual Exploration of Data\",\n",
    "    \"522\": \"Information Visualization I\",\n",
    "    \"523\": \"Communicating Data Science Results\",\n",
    "    \"524\": \"Presenting Uncertainty\",\n",
    "    \"532\": \"Data Mining I\",\n",
    "    \"542\": \"Supervised Learning\",\n",
    "    \"543\": \"Unsupervised Learning\",\n",
    "    \"571\": \"Business SQL\",  # No syllabus for this one :(\n",
    "    \"593\": \"Milestone I\",\n",
    "    \"601\": \"Qualitative Inquiry for Data Scientists\",\n",
    "    \"602\": \"Math Methods II\",\n",
    "    \"611\": \"Database Architecture & Technology\",\n",
    "    \"622\": \"Information Visualization II\",\n",
    "    \"630\": \"Causal Inference\",\n",
    "    \"631\": \"Experiment Design and Analysis\",\n",
    "    \"632\": \"Data Mining II\",\n",
    "    \"642\": \"Deep Learning I\",\n",
    "    \"643\": \"Machine Learning Pipelines\",\n",
    "    \"644\": \"Reinforcement Learning Algorithms\",\n",
    "    \"652\": \"Network Analysis\",\n",
    "    \"655\": \"Applied Natural Language Processing\",\n",
    "    \"673\": \"Cloud Computing\",\n",
    "    \"680\": \"Learning Analytics and Educational Data Science\",\n",
    "    \"681\": \"Health Analytics\",\n",
    "    \"682\": \"Social Media Analytics\",\n",
    "    \"685\": \"Search and Recommender Systems\",\n",
    "    \"687\": \"Introduction to Sports Analytics\",\n",
    "    \"688\": \"Data Science for Social Good\",\n",
    "    \"696\": \"Milestone II\",\n",
    "    \"699\": \"Capstone\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9972be7-c2b7-428f-a75c-9585e2598bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-09 20:29:19 INFO semantic_router.utils.logger local\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build semantic routes for each class\n",
    "routes = []\n",
    "for num, name in zip(courses.keys(), courses.values()):\n",
    "    route_name = \"SIADS \" + str(num)\n",
    "    route_utterances = [route_name.lower(), route_name.lower().replace(\" \",\"\"),\n",
    "                        name.lower(), name.lower() + \" class\", name.lower() + \" course\",\n",
    "                       \"who teaches \" + route_name.lower(), \"who teaches \" + name.lower()]\n",
    "    routes.append(Route(name=route_name, utterances=route_utterances))\n",
    "\n",
    "# Select local encoder and build route layer\n",
    "encoder = HuggingFaceEncoder(str=\"/Users/arnewman/.cache/huggingface/hub/models--sentence-transformers--UAE-Large-V1/\", device=\"mps\")\n",
    "rl = RouteLayer(encoder=encoder, routes=routes)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2e01927-a956-4a28-b6d0-7a5785658019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e77f34f950d4c08a8d7eef38c85cbc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 78.95%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78603b86562e45d388f43858662f2fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866d9c2520ee4ea6a55fd59bd7713b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ef40c01d494db98f64a7ee844132a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised Accuracy: 89.47%\n"
     ]
    }
   ],
   "source": [
    "# Use evaluation questions to test accuracy\n",
    "# From: https://github.com/aurelio-labs/semantic-router/blob/main/docs/06-threshold-optimization.ipynb\n",
    "\n",
    "test_data = [\n",
    "    (\"Which class involves time series analysis?\", \"SIADS 632\"),\n",
    "    (\"Who teaches the SQL and Databases class?\", \"SIADS 511\"),\n",
    "    (\"What are the prerequisites for Data Science for Social Good?\", \"SIADS 688\"),\n",
    "    (\"When are the office hours for the Math Methods course?\", \"SIADS 502\"),\n",
    "    (\"Are there any weekly readings for Milestone II?\", \"SIADS 699\"),\n",
    "    (\"What are the outcomes of Qualitative Inquiry?\", \"SIADS 601\"),\n",
    "    (\"What textbook is required for SIADS 505?\", \"SIADS 505\"),\n",
    "    (\"What textbook is required for Data Manipulation?\", \"SIADS 505\"),\n",
    "    (\"Which week of unsupervised learning covers DBSCAN?\", \"SIADS 543\"),\n",
    "    (\"How many credits are required to complete the MADS program?\", None),\n",
    "    (\"How long do students have to complete the MADS program start to finish?\", None),\n",
    "    (\"How many points is the comprehensive oral exam worth in SIADS 593?\", \"SIADS 593\"),\n",
    "    (\"What is the penalty for late submission in SIADS 630?\", \"SIADS 630\"),\n",
    "    (\"How do I get accommodations for a class?\", None),\n",
    "    (\"What is a backpack?\", None),\n",
    "    (\"When is the latest I can drop a course?\", None),\n",
    "    (\"How do I get an override to take a class?\", None),\n",
    "    (\"How do I take a leave of absence from the MADS program?\", None),\n",
    "    (\"What are the prerequisites for Search and Recommender Systems?\", \"SIADS 685\")\n",
    "]\n",
    "\n",
    "# unpack the test data\n",
    "X, y = zip(*test_data)\n",
    "\n",
    "# evaluate using the default thresholds\n",
    "accuracy = rl.evaluate(X=X, y=y)\n",
    "print(f\"Original Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Check defaults\n",
    "# route_thresholds = rl.get_thresholds()\n",
    "# print(\"Default route thresholds:\", route_thresholds)\n",
    "\n",
    "# Call the fit method\n",
    "rl.fit(X=X, y=y)\n",
    "\n",
    "# Updated thresholds\n",
    "# route_thresholds = rl.get_thresholds()\n",
    "# print(\"Updated route thresholds:\", route_thresholds)\n",
    "\n",
    "# evaluate using the new thresholds\n",
    "accuracy = rl.evaluate(X=X, y=y)\n",
    "print(f\"Revised Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c787d69-574d-489a-9ae8-a8f0e065b8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "llm_open = OpenAI(openai_api_base = \"http://localhost:7999/v1\",\n",
    "                  model = \"mistral-7b-instruct-v0.2\",\n",
    "                  openai_api_key = \"hello\",\n",
    "                  temperature = 0.1,\n",
    "                  top_p = 1,\n",
    "                  max_tokens = 1024,\n",
    "                  callback_manager = CallbackManager([StreamingStdOutCallbackHandler()]))\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\", return_messages=True,\n",
    "                                  output_key = \"result\")\n",
    "\n",
    "\n",
    "# Set prompt template\n",
    "\n",
    "template = '''\n",
    "Use only the following pieces of context to answer the question at the end. \n",
    "Keep your answers concise and do not provide additional explanations or interpretations. \n",
    "If the answer cannot be deduced from the context, just say that you don't know the answer, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e5a99cd-1db9-4353-8efc-cf7e494fbbe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match\n"
     ]
    }
   ],
   "source": [
    "# Select relevant documents based on query and create retrievers\n",
    "# If relevant documents cannot be identified, build retrievers on all documents\n",
    "# Separate retrievers from the documents index and the transcripts index\n",
    "\n",
    "#query = \"Who teaches SIADS 511?\"\n",
    "#query = \"Does he teach any other courses?\"\n",
    "query = \"Who is Graham Hukill?\"\n",
    "r = rl(query)\n",
    "print(r.name if r.name else \"No match\")\n",
    "\n",
    "# if r.name:\n",
    "#     doc_list = filter_pids(df_rag1, r.name)\n",
    "#     if len(doc_list) > 0:\n",
    "#         retriever1 = RAG1.as_langchain_retriever(doc_ids=doc_list)        \n",
    "#     trans_list = filter_pids(df_rag2, r.name)\n",
    "#     if len(trans_list) > 0:\n",
    "#         retriever2 = RAG2.as_langchain_retriever(doc_ids=trans_list)\n",
    "# else:\n",
    "#     retriever1 = RAG1.as_langchain_retriever() # Could set k if desired\n",
    "#     retriever2 = RAG2.as_langchain_retriever()\n",
    "\n",
    "# retriever = EnsembleRetriever(retrievers=[retriever1, retriever2], weights=[0.5, 0.5])\n",
    "\n",
    "if r.name:\n",
    "    doc_list = filter_pids(df_rag, r.name)\n",
    "    if len(doc_list) > 0:\n",
    "        retriever = RAG.as_langchain_retriever(doc_ids=doc_list) # Set k if desired\n",
    "    else:\n",
    "        retriever = RAG.as_langchain_retriever()\n",
    "else:\n",
    "    retriever = RAG.as_langchain_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21765aca-43b1-406b-b772-7f84f1be008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define processing chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm_open,\n",
    "    chain_type=\"stuff\",\n",
    "    memory=memory,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": PromptTemplate(\n",
    "            template=template,\n",
    "            input_variables=[\"context\", \"question\"])},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84339208-d2eb-441b-8296-79ffebf3dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display results\n",
    "def process_llm_response(llm_response):\n",
    "    print(f\"\\nQuestion: {llm_response['query']}\")\n",
    "    print(f\"\\nAnswer: {llm_response['result']}\")\n",
    "    print(\"\\n\\nSources:\")\n",
    "    for i, source in enumerate(llm_response[\"source_documents\"]):\n",
    "        m = source.metadata\n",
    "        try:\n",
    "            print(f\"{i + 1}. {m['course_title']} ({m['course_number']}): {m['heading']}\")\n",
    "        except:\n",
    "            print(f\"{i + 1}. {m['course_title']} ({m['course_number']}): {m['source']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4467a7f-13f0-4135-9dfb-d0e87ce8ec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "Loading searcher for index combined for the first time... This may take a few seconds\n",
      "[Apr 09, 20:31:02] #> Loading codec...\n",
      "[Apr 09, 20:31:02] #> Loading IVF...\n",
      "[Apr 09, 20:31:02] Loading segmented_lookup_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:126: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 20:31:02] #> Loading doclens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 1023.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 20:31:02] #> Loading codes and residuals...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 20:31:03] Loading filter_pids_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Apr 09, 20:31:03] Loading decompress_residuals_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "Searcher loaded!\n",
      "\n",
      "#> QueryTokenizer.tensorize(batch_text[0], batch_background[0], bsize) ==\n",
      "#> Input: . Who is Graham Hukill?, \t\t True, \t\t None\n",
      "#> Output IDs: torch.Size([32]), tensor([  101,     1,  2040,  2003,  5846, 15876, 15872,  1029,   102,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "          103,   103])\n",
      "#> Output Mask: torch.Size([32]), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnewman/miniconda3/envs/rag/lib/python3.12/site-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Question: Who is Graham Hukill?\n",
      "\n",
      "Answer: Graham Hukill is an Instructor for Database Architecture & Technology (SIADS 611) and SQL and Databases (SIADS 511) courses at the University of Michigan. He is also an intermittent lecturer in the School of Information.\n",
      "\n",
      "\n",
      "Sources:\n",
      "1. Database Architecture & Technology (SIADS 611): Instructor And Course Assistants\n",
      "2. SQL and Databases (SIADS 511): Instructor And Course Assistants\n",
      "3. SQL and Databases (SIADS 511): Office Hours\n",
      "4. Database Architecture & Technology (SIADS 611): Course Schedule\n",
      "5. Data Science Ethics (SIADS 503): 12_guest-speaker-introduction-j-m-porup.en.txt\n",
      "6. Visual Exploration of Data (SIADS 521): 06_bonus-interview-with-damian-avila.en.txt\n",
      "7. Data Science for Social Good (SIADS 688): 01_social-identity-for-social-good-theory-part-1.en.txt\n",
      "8. Being a Data Scientist (SIADS 501): 02_getting-the-data-right-lecture.en.txt\n",
      "9. Data Science Ethics (SIADS 503): 12_guest-speaker-introduction-j-m-porup.en.txt\n",
      "10. Math Methods I (SIADS 502): 01_w1-1-welcome.en.txt\n"
     ]
    }
   ],
   "source": [
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ed8b6e-c338-4493-b387-e5c778a6751a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
