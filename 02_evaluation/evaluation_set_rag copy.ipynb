{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":186239,"status":"ok","timestamp":1710981102917,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"pZou7KwCCYpO","outputId":"cbf26867-f692-45c2-ea44-4a34cd0fb72d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain\n","  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/810.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/810.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-cpp-python\n","  Downloading llama_cpp_python-0.2.57.tar.gz (36.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting chromadb==0.4.14\n","  Downloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentence_transformers\n","  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (2.6.4)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb==0.4.14)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb==0.4.14)\n","  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb==0.4.14)\n","  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting posthog>=2.4.0 (from chromadb==0.4.14)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (4.10.0)\n","Collecting pulsar-client>=3.1.0 (from chromadb==0.4.14)\n","  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb==0.4.14)\n","  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m101.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (0.15.2)\n","Collecting pypika>=0.48.9 (from chromadb==0.4.14)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m469.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (4.66.2)\n","Collecting overrides>=7.3.1 (from chromadb==0.4.14)\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (6.3.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (1.62.1)\n","Collecting bcrypt>=4.0.1 (from chromadb==0.4.14)\n","  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (0.9.0)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (1.25.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n","  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n","  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n","  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb==0.4.14)\n","  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\n","Collecting packaging>=20.9 (from huggingface-hub>=0.15.1->sentence_transformers)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.14)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (24.3.7)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (1.12)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.14) (1.16.0)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.14)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.14)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.14) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb==0.4.14) (2024.2.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.4.14) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.4.14) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.14) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.14) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.14) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.4.14) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m85.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.14)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.14) (1.3.0)\n","Building wheels for collected packages: llama-cpp-python, pypika\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.57-cp310-cp310-manylinux_2_35_x86_64.whl size=2872735 sha256=abc5fb9df040aff387a24dd3e81e3fe261d92ed9af54a61e73fe87626f1aa75d\n","  Stored in directory: /root/.cache/pip/wheels/7e/c0/00/e98d6e198f941c623da37b3f674354cbdccfcfb2cb9cf1133d\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=68993a4e823cdea1321a8af87e6ecf077534980ca3c6e699df41f4cc74d499f6\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built llama-cpp-python pypika\n","Installing collected packages: pypika, monotonic, websockets, uvloop, python-dotenv, pulsar-client, packaging, overrides, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, jsonpointer, humanfriendly, httptools, h11, diskcache, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, typing-inspect, starlette, posthog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, llama-cpp-python, jsonpatch, coloredlogs, onnxruntime, nvidia-cusolver-cu12, langsmith, fastapi, dataclasses-json, langchain-core, chromadb, sentence_transformers, langchain-text-splitters, langchain-community, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.14 coloredlogs-15.0.1 dataclasses-json-0.6.4 diskcache-5.6.3 fastapi-0.110.0 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 llama-cpp-python-0.2.57 marshmallow-3.21.1 monotonic-1.6 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.17.1 orjson-3.9.15 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 sentence_transformers-2.5.1 starlette-0.36.3 typing-inspect-0.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"]}],"source":["!pip install langchain llama-cpp-python chromadb==0.4.14 sentence_transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":925,"status":"ok","timestamp":1710981103835,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"QwOjhhrmC2Ln"},"outputs":[],"source":["from langchain_community.document_loaders import UnstructuredHTMLLoader, BSHTMLLoader, TextLoader, JSONLoader\n","from langchain.document_loaders import DirectoryLoader\n","from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, MarkdownTextSplitter\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA, ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n","from langchain.memory import ConversationBufferMemory\n","from langchain_community.llms import LlamaCpp\n","import pickle"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3154,"status":"ok","timestamp":1710981438228,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"MtoLMrlTCszn","outputId":"06c86c60-b245-4a42-9a08-65c5ce9415f4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","ls: cannot access './drive/MyDrive/Capstone': No such file or directory\n"]}],"source":["from google.colab import drive\n","import os\n","\n","\n","drive.mount('/content/drive', force_remount=True)\n","# os.chdir('/content/drive/MyDrive/Capstone')\n","!ls ./drive/MyDrive/Capstone"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9614,"status":"ok","timestamp":1710981480332,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"-wIDl75YDHrS"},"outputs":[],"source":["persist_directory = \"/content/drive/MyDrive/Capstone/embeddings\"\n","\n","with open(f\"{persist_directory}/embeddings.pickle\", 'rb') as handle:\n","    embeddings = pickle.load(handle)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2962,"status":"ok","timestamp":1710981486734,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"Z07d-i9mFhN0"},"outputs":[],"source":["vectordb = Chroma(\n","    \"embeddings\",\n","    embedding_function=embeddings,\n","    persist_directory=persist_directory,\n","    collection_metadata={\"hnsw:space\": \"cosine\"},\n",")"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710981486735,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"EugAMdnjFlj4"},"outputs":[],"source":["retriever = vectordb.as_retriever(\n","    search_type=\"mmr\",\n","    search_kwargs={\"k\": 5, \"fetch_k\": 20},\n",")"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108136,"status":"ok","timestamp":1710981617241,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"aG_eNdSIGxwD","outputId":"faf777f1-7a80-4b26-a452-9c493a6a5f47"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! stream is not default parameter.\n","                stream was transferred to model_kwargs.\n","                Please confirm that stream is what you intended.\n","  warnings.warn(\n","llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /content/drive/MyDrive/Capstone/models/llama-2-7b.Q4_K_M.gguf (version GGUF V2)\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  10:                          general.file_type u32              = 15\n","llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type q4_K:  193 tensors\n","llama_model_loader: - type q6_K:   33 tensors\n","llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n","llm_load_print_meta: format           = GGUF V2\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = SPM\n","llm_load_print_meta: n_vocab          = 32000\n","llm_load_print_meta: n_merges         = 0\n","llm_load_print_meta: n_ctx_train      = 4096\n","llm_load_print_meta: n_embd           = 4096\n","llm_load_print_meta: n_head           = 32\n","llm_load_print_meta: n_head_kv        = 32\n","llm_load_print_meta: n_layer          = 32\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 1\n","llm_load_print_meta: n_embd_k_gqa     = 4096\n","llm_load_print_meta: n_embd_v_gqa     = 4096\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: f_logit_scale    = 0.0e+00\n","llm_load_print_meta: n_ff             = 11008\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: causal attn      = 1\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 10000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_yarn_orig_ctx  = 4096\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: model type       = 7B\n","llm_load_print_meta: model ftype      = Q4_K - Medium\n","llm_load_print_meta: model params     = 6.74 B\n","llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n","llm_load_print_meta: general.name     = LLaMA v2\n","llm_load_print_meta: BOS token        = 1 '<s>'\n","llm_load_print_meta: EOS token        = 2 '</s>'\n","llm_load_print_meta: UNK token        = 0 '<unk>'\n","llm_load_print_meta: LF token         = 13 '<0x0A>'\n","llm_load_tensors: ggml ctx size =    0.11 MiB\n","llm_load_tensors:        CPU buffer size =  3891.24 MiB\n","..................................................................................................\n","llama_new_context_with_model: n_ctx      = 4096\n","llama_new_context_with_model: n_batch    = 8\n","llama_new_context_with_model: n_ubatch   = 8\n","llama_new_context_with_model: freq_base  = 10000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\n","llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n","llama_new_context_with_model:        CPU  output buffer size =     0.98 MiB\n","llama_new_context_with_model:        CPU compute buffer size =     4.63 MiB\n","llama_new_context_with_model: graph nodes  = 1060\n","llama_new_context_with_model: graph splits = 1\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n","Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n","Using fallback chat format: None\n"]}],"source":["llm_open = LlamaCpp(\n","    model_path=\"/content/drive/MyDrive/Capstone/models/llama-2-7b.Q4_K_M.gguf\", # https://huggingface.co/TheBloke/Llama-2-7B-GGUF\n","    n_ctx=4096,  # 4096 for Llama, 32*1024 for Mistral\n","    n_gpu_layers=50,\n","    temperature=0.15,\n","    top_p=1,\n","    top_k=40,\n","    repeat_penalty=1.1,\n","    max_tokens=1024,\n","    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n","    stream=True,\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1710981617242,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"7BBRKwL7GoFY"},"outputs":[],"source":["def process_llm_response(llm_response):\n","    print(\"\\n\\nSources:\")\n","    for i, source in enumerate(llm_response[\"source_documents\"]):\n","        m = source.metadata\n","        print(f\"{i + 1}. {m['course_title']} ({m['course_number']}): {m['heading']}\")"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1710981617242,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"llNw6QC1GsLa"},"outputs":[],"source":["qa_chain = RetrievalQA.from_chain_type(\n","    llm=llm_open,\n","    chain_type=\"stuff\",\n","    retriever=retriever,\n","    return_source_documents=True,\n","    verbose=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZ-zQaIZ_5kQ"},"outputs":[],"source":["import pandas as pd\n","\n","class ResponseFormatter:\n","    def __init__(self):\n","        self.responses = {\n","            \"question\": [],\n","            \"contexts\": [],\n","            \"answer\": [],\n","            \"ground_truth\": [],\n","        }\n","\n","    def add_response(self, llm_response, ground_truth):\n","        self.responses[\"question\"].append(llm_response[\"query\"])\n","        self.responses[\"contexts\"].append(\n","            [doc.page_content for doc in llm_response[\"source_documents\"]]\n","        )\n","        self.responses[\"answer\"].append(llm_response[\"result\"])\n","        self.responses[\"ground_truth\"].append(ground_truth)\n","\n","    def get_responses(self):\n","        return self.responses\n","    \n","    def get_dataframe(self):\n","        pd.DataFrame(self.responses[[\"question\", \"answer\", \"ground_truth\"]])"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7739,"status":"ok","timestamp":1710981502743,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"p1a4TXYwUlfm","outputId":"4d9a7455-7207-4ccd-d075-2290ed82998f"},"outputs":[{"data":{"text/plain":["[(Document(page_content='Context from MADS Student Handbook, Grade of Incomplete (I): If a MADS student needs to drop a course, effort should be made to do so within the first week (or seven days) from when the course starts, before the MADS drop/add deadline. However, when extenuating circumstances prevent completion of coursework by the end of the MADS session, and the student participated in the course past the standard MADS drop/add deadline, a grade of incomplete (“I”) may be assigned.\\n\\nTo request an “I” grade for a course that has not been awarded a letter grade or course withdrawal (W), students must complete the [MADS Incomplete Request Form](https://docs.google.com/forms/d/e/1FAIpQLSccjy5cRpEN5eljekRqiTJg_CK1ihFvvMa3y-BPj-82zXHH4g/viewform?usp=sf_link) as soon as possible, and no later than the last day of the MADS session (11:59 PM Eastern Time). After the request is submitted, an academic advisor will partner with the student to create a plan for resolution of the incomplete, typically through placement and participation in the course in a future session. Students with an active incomplete from a previous session are also required to meet with an academic advisor when requesting an incomplete.\\n\\nThe MADS Academic Advising team will notify the course instructor when a student’s request for an incomplete is approved so that an “I” can be submitted as the student’s final course grade.\\n\\nAn “I” grade is not calculated into the student’s term or cumulative GPA. The grade point average is based on credit hours of completed work.\\n\\nAn “I” grade can be changed to a letter grade only if the incomplete is resolved within one year (12 months) from the end of the term in which the course was started, regardless of the student’s subsequent enrollment status. If an “I” remains on a student’s record after that point, it becomes a lapsed incomplete, or a permanent “I” grade, and credit can only be earned by retaking the course under a new registration. Students planning to resolve the incomplete through placement and participation in a future session may be manually enrolled in the course one (1) time (within one year from the end of the term in which the course was started).\\n\\nAn incomplete has one of three statuses:\\n\\n- Active Incomplete: The “I” grade is within the resolution deadline (within one year from the end of the term in which the course was started) and may be able to be changed to a letter grade and counted toward degree requirements.\\n- Resolved Incomplete: This status refers to a course that previously had an “I” grade, but has been subsequently completed and received a letter grade. The letter grade replaced the “I” grade.\\n- Lapsed Incomplete: An “I” grade that has passed the resolution deadline (one year from the end of the term in which the course was started) and is not eligible to be resolved. The lapsed incomplete remains on the transcript but will be excluded from the Degree Audit in Wolverine Access, as it does not count toward degree requirements.\\n\\nFor more information about requesting an “I” grade, please refer to the [MADS Incomplete Policy Student Guide](https://docs.google.com/document/d/1j3vnEdnP8KyZR7delogoXGi2CTytSuFg03G53c5DYWM/edit#heading=h.9d2d25mpldb).', metadata={'course_date': '', 'course_number': '', 'course_title': '', 'document': 'https://www.patricksollars.com/umich/[PUBLIC]_MADS_Student_Handbook.pdf', 'heading': 'Grade of Incomplete (I)', 'section': '19', 'source': 'handbook.md'}),\n","  0.907795250415802),\n"," (Document(page_content='Context from MADS Student Handbook, Waitlists: MADS courses are delivered in such a way that waitlists are generally not necessary. However, if you are unable to register for a course that you have all necessary prerequisites for, please email the UMSI Registrar Team at [umsi.registrar@umich.edu](mailto:umsi.registrar@umich.edu) for assistance with registration. If you cannot register for a course due to missed prerequisites, please contact the MADS Academic Advising Team at [umsi.advising.mads@umich.edu](mailto:umsi.advising.mads@umich.edu) for assistance with your academic plan.', metadata={'course_date': '', 'course_number': '', 'course_title': '', 'document': 'https://www.patricksollars.com/umich/[PUBLIC]_MADS_Student_Handbook.pdf', 'heading': 'Waitlists', 'section': '9', 'source': 'handbook.md'}),\n","  1.0862213373184204),\n"," (Document(page_content='Context from MADS Student Handbook, Leave of Absence: If you decide to take a leave of absence and have not yet used the online course registration, you do not need to submit any paperwork, but should notify the MADS Academic Advising Team at [umsi.advising.mads@umich.edu](mailto:umsi.advising.mads@umich.edu) of your intentions. If you have already registered for classes you will need to submit a term withdrawal form available from the UMSI Registrar Team (umsi.registrar@umich.edu).\\n\\nTo register for classes following a term in which you were not enrolled, you will need to contact the Office of the Registrar by email at [ro.registration.questions@umich.edu](mailto:ro.registration.questions@umich.edu), or phone 734.764.6280 / 734.647.3507, to request a registration appointment assignment. If using email, please include name, UM ID number, term, and school or college in which you wish to register.\\n\\nStudents not enrolling within a year (12 months) will have to apply for readmission to UMSI.', metadata={'course_date': '', 'course_number': '', 'course_title': '', 'document': 'https://www.patricksollars.com/umich/[PUBLIC]_MADS_Student_Handbook.pdf', 'heading': 'Leave of Absence', 'section': '15', 'source': 'handbook.md'}),\n","  1.178361177444458),\n"," (Document(page_content='Context from MADS Student Handbook, Petition for Modification or Waiver of Policy: The \\u200b\\u200bSchool\\u200b of Information policies\\u200b are detailed in this student handbook. \\u200b\\u200bAll\\u200b\\u200b School policies \\u200b\\u200bhave \\u200b\\u200bbeen \\u200b\\u200bformulated \\u200b\\u200bwith \\u200b\\u200bone \\u200b\\u200bobjective:\\u200b\\u200b the \\u200b\\u200bpursuit \\u200b\\u200bof \\u200b\\u200bacademic\\u200b \\u200bquality.\\u200b\\u200b This \\u200b\\u200bgoal requires\\u200b\\u200b that\\u200b\\u200b the \\u200b\\u200bpolicies \\u200b\\u200bbe \\u200b\\u200bequitably \\u200b\\u200band \\u200b\\u200buniformly \\u200b\\u200bapplied\\u200b \\u200bto \\u200b\\u200beveryone.\\u200b \\u200bHowever, the School of Information does recognize the infrequent occurrence of extenuating circumstances that warrant individual consideration. School of Information students may petition the school for a modification or waiver of any UMSI policy by submitting a [UMSI Petition Form](https://forms.gle/F6oxKLBQUXPEBhX5A). \\u200b\\u200bIn completing the form, state in writing all facts that have a bearing on the case you wish to present. If the petition involves a course, it must also be endorsed by the instructor. \\u200bPlease note that a reduction in time to degree, a reduction in tuition, or a reduction in final term enrollment are not extenuating circumstances for a modification or waiver of policy. If you’d like to submit a [UMSI Petition Form](https://forms.gle/F6oxKLBQUXPEBhX5A), please first contact the MADS Academic Advising Team at [umsi.advising.mads@umich.edu](mailto:umsi.advising.mads@umich.edu) to discuss your petition request with an advisor.', metadata={'course_date': '', 'course_number': '', 'course_title': '', 'document': 'https://www.patricksollars.com/umich/[PUBLIC]_MADS_Student_Handbook.pdf', 'heading': 'Petition for Modification or Waiver of Policy', 'section': '13', 'source': 'handbook.md'}),\n","  1.2041091918945312)]"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["query = \"Where can I find the MADS Incomplete Request Form?\"\n","\n","vectordb.similarity_search_with_score(query)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":842611,"status":"ok","timestamp":1710982459850,"user":{"displayName":"Patrick Sollars","userId":"12439928852339899354"},"user_tz":300},"id":"6jSlOi4WHCKI","outputId":"785327bc-0dc8-4e5b-a2a8-eb2c88d7a3a1"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"," [MADS Incomplete Request Form](https://docs.google.com/forms/d/e/1FAIpQLSccjy5cRpEN5eljekRqiTJg_CK1ihFvvMa3y-BPj-82zXHH4g/viewform?usp=sf_link)\n"]},{"name":"stderr","output_type":"stream","text":["\n","llama_print_timings:        load time =    3534.89 ms\n","llama_print_timings:      sample time =      44.81 ms /    80 runs   (    0.56 ms per token,  1785.44 tokens per second)\n","llama_print_timings: prompt eval time =  782292.66 ms /  1668 tokens (  469.00 ms per token,     2.13 tokens per second)\n","llama_print_timings:        eval time =   58518.98 ms /    79 runs   (  740.75 ms per token,     1.35 tokens per second)\n","llama_print_timings:       total time =  842020.27 ms /  1747 tokens\n"]},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","\n","Sources:\n","1.  (): Grade of Incomplete (I)\n","2.  (): Waitlists\n","3.  (): Petition for Modification or Waiver of Policy\n","4. Communicating Data Science Results (SIADS 523): Letter Grades, Course Grades, And Late Submission Policy\n","5.  (): Eligibility\n"]}],"source":["# query = \"Tell me what I need to turn in for the capstone project.\"\n","\n","llm_response = qa_chain(query)\n","process_llm_response(llm_response)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1710536315291,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"},"user_tz":300},"id":"ekdFiQnQHEKV","outputId":"dc8c5344-6f2b-414d-eb60-9884f2274c5c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","Sources:\n","1. Capstone (SIADS 699): Course Syllabus For SIADS 699\n","2. Milestone I (SIADS 593): 14.0 Student Mental Health And Well-Being\n","3. Capstone (SIADS 699): Instructor And Course Assistants\n","4. Milestone II (SIADS 696): Project Component\n","5. Capstone (SIADS 699): Grading\n"]}],"source":["process_llm_response( llm_response)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2mWEVGVDAaGK"},"outputs":[],"source":["capstone_requirements_llm_response = llm_response\n","\n","capstone_requirements_ground_truth = \"\"\"\n","Final Project Submission including:\n","    A report that tells the story of your project, which can be formatted as a blog, a scientific manuscript, or something else.\n","    A GitHub repository full of the code required to reproduce your analysis and figures, documented with an informative README.\n","    One of the following high-level overviews of your work designed to be shared:\n","    A 3-5 minute video from your team about what you made.\n","    A poster appropriate for a data science conference, such as the MIDAS Data Science Symposium.\n","Weekly Mini-Deliverables: There will be weekly mini-deliverables throughout the course, as outlined in the grading section of the syllabus.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qC8HbRBHAdAQ"},"outputs":[],"source":["formatter = ResponseFormatter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZ-puexzBFXu"},"outputs":[],"source":["formatter.add_response(capstone_requirements_llm_response, capstone_requirements_ground_truth)\n","\n","with open(f\"./evaluation_set_rag_formatter.pickle\", 'wb') as handle:\n","    pickle.dump(formatter, handle)\n","\n","with open(f\"./evaluation_set_rag_responses.pickle\", 'wb') as handle:\n","    pickle.dump(formatter.get_responses(), handle)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gHl5R-TPCyyg"},"outputs":[],"source":["prompts = [\n","    {\n","        \"question\": \"Which class involves time series analysis?\",\n","        \"ground_truth\": \"Data Mining II, SIADS 632\",\n","    },\n","    {\n","        \"question\": \"Who teaches the SQL and Databases class?\",\n","        \"ground_truth\": \"The primary instructor for SQL and Databases is Graham Hukill. Additional course assistants include, Derek Bruckner, Emily Schemanske, Jungseo Lee, and Toby Kemp.\",\n","    },\n","    {\n","        \"question\": \"What are the prerequisites for Data Science for Social Good?\",\n","        \"ground_truth\": \"SIADS 630, 631, and 694\",\n","    },\n","    {\n","        \"question\": \"When are the office hours for the Math Methods course?\",\n","        \"ground_truth\": \"Office hours for Math Methods are held at the following times: Alex McLeod: Monday at 11:45 am EST, Saurabh Budholiya: Friday at 9:00 am EST, Alexis Castellano: Thursdays at 7:00 pm EST\",\n","    },\n","    {\n","        \"question\": \"Are there any weekly readings for Milestone II?\",\n","        \"ground_truth\": \"There is introductory material during the first week of the course, but generally speaking, no weekly readings in this course.\",\n","    },\n","    {\n","        \"question\": \"What are the outcomes of Qualitative Inquiry?\",\n","        \"ground_truth\": \"Upon successful completion of this course, students will be able to:1.  Collect, represent, and analyze qualitative data about a quantitative data set, by…2.  Conducting semi-structured interviews;3.  Processing interview notes into discrete pieces of qualitative data; and 4. Analyzing qualitative data using affinity walls.4.  Develop a narrative about qualitative findings that support later quantitative analysis.5.  Communicate qualitative findings in written form.\",\n","    },\n","]"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv(\"./evaluation_set.csv\")"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0 Which class involves time series analysis?\n","1 Who teaches the SQL and Databases class?\n","2 What are the prerequisites for Data Science for Social Good?\n","3 When are the office hours for the Math Methods course?\n","4 Are there any weekly readings for Milestone II?\n","5 What are the outcomes of Qualitative Inquiry?\n","6 What textbook is required for SIADS 505?\n","7 What textbook is required for Data Manipulation?\n","8 Which week of unsupervised learning covers DBSCAN?\n","9 How many credits are required to complete the MADS program?\n","10 How long do students have to complete the MADS program start to finish?\n"]}],"source":["for _, row in df.iterrows():\n","    print(row[\"question\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2JXodnOCj-d","outputId":"3da8e4e2-ada8-493f-e7ee-5f9dbcc7f1db"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["Llama.generate: prefix-match hit\n"]},{"name":"stdout","output_type":"stream","text":[" Data Mining II - SIADS 632"]},{"name":"stderr","output_type":"stream","text":["\n","llama_print_timings:        load time =    3589.85 ms\n","llama_print_timings:      sample time =       6.98 ms /    13 runs   (    0.54 ms per token,  1862.20 tokens per second)\n","llama_print_timings: prompt eval time =  376111.82 ms /   842 tokens (  446.69 ms per token,     2.24 tokens per second)\n","llama_print_timings:        eval time =    7726.96 ms /    12 runs   (  643.91 ms per token,     1.55 tokens per second)\n","llama_print_timings:       total time =  384185.60 ms /   854 tokens\n","Llama.generate: prefix-match hit\n"]},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","\n","Sources:\n","1. Health Analytics (SIADS 681): No Required Textbooks\n","2. Data Mining II (SIADS 632): Weekly Office Hours Via Zoom (Ann Arbor, Michigan Time):\n","3. Big Data: Scalable Data Processing (SIADS 516): Instructor And Course Assistants\n","4. Math Methods I (SIADS 502): Course Syllabus Mads 502: Math Methods For Data Science Course Overview\n","5. Communicating Data Science Results (SIADS 523): Course Schedule\n","\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"," The instructor for this class is Graham Hukill (gshukill@umich.edu). The course assistants are Derek Bruckner (dbrucknr@umich.edu), Emily Schemanske (landise@umich.edu), Jungseo Lee (jungseo@umich.edu), Toby Kemp (tobyk@umich.edu).\n"]},{"name":"stderr","output_type":"stream","text":["\n","llama_print_timings:        load time =    3589.85 ms\n","llama_print_timings:      sample time =      47.83 ms /    88 runs   (    0.54 ms per token,  1839.73 tokens per second)\n","llama_print_timings: prompt eval time =  333765.50 ms /   744 tokens (  448.61 ms per token,     2.23 tokens per second)\n","llama_print_timings:        eval time =   58223.68 ms /    87 runs   (  669.24 ms per token,     1.49 tokens per second)\n","llama_print_timings:       total time =  392760.85 ms /   831 tokens\n","Llama.generate: prefix-match hit\n"]},{"name":"stdout","output_type":"stream","text":["\n","\u001b[1m> Finished chain.\u001b[0m\n","\n","\n","Sources:\n","1. SQL and Databases (SIADS 511): Course Syllabus Course Overview And Prerequisites\n","2. SQL and Databases (SIADS 511): Course Outcomes\n","3. SQL and Databases (SIADS 511): Textbooks\n","4. SQL and Databases (SIADS 511): Instructor And Course Assistants\n","5. Learning Analytics and Educational Data Science (SIADS 680): SIADS 680: Learning Analytics Course Syllabus Course Overview And Prerequisites\n","\n","\n","\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"]}],"source":["for prompt in prompts:\n","  llm_response = qa_chain(prompt[\"question\"])\n","  process_llm_response(llm_response)\n","\n","  formatter.add_response(llm_response, prompt[\"ground_truth\"])\n","\n","  # Save after each response\n","  with open(f\"./evaluation_set_rag_formatter.pickle\", 'wb') as handle:\n","      pickle.dump(formatter, handle)\n","\n","  with open(f\"./evaluation_set_rag_responses.pickle\", 'wb') as handle:\n","      pickle.dump(formatter.get_responses(), handle)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zq_7_dEIEzO8"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}
