{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227414,"status":"ok","timestamp":1710543186207,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"},"user_tz":300},"id":"pZou7KwCCYpO","outputId":"77b0ac74-f0da-4f71-fe5a-29be3ba31657"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain\n","  Downloading langchain-0.1.12-py3-none-any.whl (809 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting llama-cpp-python\n","  Downloading llama_cpp_python-0.2.56.tar.gz (36.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting chromadb==0.4.14\n","  Downloading chromadb-0.4.14-py3-none-any.whl (448 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m448.1/448.1 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentence_transformers\n","  Downloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (2.31.0)\n","Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (2.6.4)\n","Collecting chroma-hnswlib==0.7.3 (from chromadb==0.4.14)\n","  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb==0.4.14)\n","  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb==0.4.14)\n","  Downloading uvicorn-0.28.0-py3-none-any.whl (60 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting posthog>=2.4.0 (from chromadb==0.4.14)\n","  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (4.10.0)\n","Collecting pulsar-client>=3.1.0 (from chromadb==0.4.14)\n","  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb==0.4.14)\n","  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (0.15.2)\n","Collecting pypika>=0.48.9 (from chromadb==0.4.14)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (4.66.2)\n","Collecting overrides>=7.3.1 (from chromadb==0.4.14)\n","  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (6.3.0)\n","Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (1.62.1)\n","Collecting bcrypt>=4.0.1 (from chromadb==0.4.14)\n","  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (0.9.0)\n","Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.4.14) (1.25.2)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n","  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n","Collecting jsonpatch<2.0,>=1.33 (from langchain)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Collecting langchain-community<0.1,>=0.0.28 (from langchain)\n","  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.31 (from langchain)\n","  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n","  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.26-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n","Collecting diskcache>=5.6.1 (from llama-cpp-python)\n","  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.3)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb==0.4.14)\n","  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.5)\n","Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n","  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n","Collecting packaging>=20.9 (from huggingface-hub>=0.15.1->sentence_transformers)\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.4.14)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (24.3.7)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.4.14) (1.12)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.14) (1.16.0)\n","Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.4.14)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.4.14)\n","  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.4.14) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pulsar-client>=3.1.0->chromadb==0.4.14) (2024.2.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.4.14) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb==0.4.14) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.14) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.14) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb==0.4.14) (2.0.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers)\n","  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (2023.12.25)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence_transformers) (0.4.2)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.4.14) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.4.14)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n","Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.14)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.14) (1.3.0)\n","Building wheels for collected packages: llama-cpp-python, pypika\n","  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.56-cp310-cp310-manylinux_2_35_x86_64.whl size=2831700 sha256=647fcb6652c975652e79eafcc3ccea246edfabe8274b7f0f7882529c3cfb62b1\n","  Stored in directory: /root/.cache/pip/wheels/e5/09/9d/c413053f6258cb2546cc792418c595e276f9efd5db31a80377\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=47ed0673deebf4d0b08dd6c2f79f13fb6e118db11181ea4c0b829b2bb84397a9\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","Successfully built llama-cpp-python pypika\n","Installing collected packages: pypika, monotonic, websockets, uvloop, python-dotenv, pulsar-client, packaging, overrides, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, jsonpointer, humanfriendly, httptools, h11, diskcache, chroma-hnswlib, bcrypt, backoff, watchfiles, uvicorn, typing-inspect, starlette, posthog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, llama-cpp-python, jsonpatch, coloredlogs, onnxruntime, nvidia-cusolver-cu12, langsmith, fastapi, dataclasses-json, langchain-core, chromadb, sentence_transformers, langchain-text-splitters, langchain-community, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 24.0\n","    Uninstalling packaging-24.0:\n","      Successfully uninstalled packaging-24.0\n","Successfully installed backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.14 coloredlogs-15.0.1 dataclasses-json-0.6.4 diskcache-5.6.3 fastapi-0.110.0 h11-0.14.0 httptools-0.6.1 humanfriendly-10.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.12 langchain-community-0.0.28 langchain-core-0.1.32 langchain-text-splitters-0.0.1 langsmith-0.1.26 llama-cpp-python-0.2.56 marshmallow-3.21.1 monotonic-1.6 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 onnxruntime-1.17.1 orjson-3.9.15 overrides-7.7.0 packaging-23.2 posthog-3.5.0 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 sentence_transformers-2.5.1 starlette-0.36.3 typing-inspect-0.9.0 uvicorn-0.28.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"]}],"source":["!pip install langchain llama-cpp-python chromadb==0.4.14 sentence_transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"QwOjhhrmC2Ln","executionInfo":{"status":"ok","timestamp":1710543188469,"user_tz":300,"elapsed":2266,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"outputs":[],"source":["from langchain_community.document_loaders import UnstructuredHTMLLoader, BSHTMLLoader, TextLoader, JSONLoader\n","from langchain.document_loaders import DirectoryLoader\n","from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, MarkdownTextSplitter\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain.callbacks.manager import CallbackManager\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","from langchain.vectorstores import Chroma\n","from langchain.chains import RetrievalQA, ConversationalRetrievalChain, RetrievalQAWithSourcesChain\n","from langchain.memory import ConversationBufferMemory\n","from langchain_community.llms import LlamaCpp\n","import pickle"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16414,"status":"ok","timestamp":1710543239900,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"},"user_tz":300},"id":"MtoLMrlTCszn","outputId":"6438cf46-8807-4e2c-8fb5-069e77a8971b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","'02-19 - Literature Review Mini-Deliverable.gdoc'\t     evaluation_set_rag.ipynb\n","'02-26 - Capstone Project Proposal.gdoc'\t\t     evaluation_set_rag_responses.pickle\n","'03-04 - Software Tools Mini-Deliverable.gdoc'\t\t     llama-2-7b.Q4_K_M.gguf\n","'03-11 - Data Leakage Plan Mini-Deliverable.gdoc'\t    'LLM Inference Test.ipynb'\n","'03-11 - First Slack Stand-up Reports and Responses.gdoc'    models\n","'03-17 - Mentor Check-In.gdoc'\t\t\t\t     original_syllabi\n","'03-18 - Report Outline Mini-Deliverable.gdoc'\t\t     package_installation.ipynb\n","'03-25 - Second Slack Stand-up Reports and Responses.gdoc'   packages\n","'03-25 - Visuals Mini-Deliverable.gdoc'\t\t\t     Pipfile\n","'04-01 - Revised Outline Mini-Deliverable???.gdoc'\t    'Pipfile (1)'\n","'04-08 - GitHub Repository Mini-Deliverable.gdoc'\t     Pipfile.lock\n","'04-15 - Capstone Project Pre-Flight Checklist.gdoc'\t    'Project Tracker.gdoc'\n","'04-16 - Third Slack Stand-up Reports and Responses.gdoc'    syllabus_loader_embeddings\n","'04-22 - Final Report.gdoc'\t\t\t\t     syllabus_loader_embeddings_ORIGINAL\n","'Capstone Project Specifications Checklist.gdoc'\t     SyllabusLoader.ipynb\n"," chromadb\t\t\t\t\t\t     transcripts\n"," evaluation_set_llm.ipynb\t\t\t\t     updated_syllabi\n"," evaluation_set_rag_formatter.pickle\t\t\t     venv\n"]}],"source":["from google.colab import drive\n","import os\n","\n","\n","drive.mount('/content/drive')\n","os.chdir('/content/drive/MyDrive/Capstone')\n","!ls ."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"aG_eNdSIGxwD","outputId":"886d4cb2-f71b-4edf-8a60-8175b4e8f5b5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710543318491,"user_tz":300,"elapsed":69309,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! stream is not default parameter.\n","                stream was transferred to model_kwargs.\n","                Please confirm that stream is what you intended.\n","  warnings.warn(\n","llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from ./llama-2-7b.Q4_K_M.gguf (version GGUF V2)\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  10:                          general.file_type u32              = 15\n","llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type q4_K:  193 tensors\n","llama_model_loader: - type q6_K:   33 tensors\n","llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n","llm_load_print_meta: format           = GGUF V2\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = SPM\n","llm_load_print_meta: n_vocab          = 32000\n","llm_load_print_meta: n_merges         = 0\n","llm_load_print_meta: n_ctx_train      = 4096\n","llm_load_print_meta: n_embd           = 4096\n","llm_load_print_meta: n_head           = 32\n","llm_load_print_meta: n_head_kv        = 32\n","llm_load_print_meta: n_layer          = 32\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 1\n","llm_load_print_meta: n_embd_k_gqa     = 4096\n","llm_load_print_meta: n_embd_v_gqa     = 4096\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: n_ff             = 11008\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: pooling type     = 0\n","llm_load_print_meta: rope type        = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 10000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_yarn_orig_ctx  = 4096\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: ssm_d_conv       = 0\n","llm_load_print_meta: ssm_d_inner      = 0\n","llm_load_print_meta: ssm_d_state      = 0\n","llm_load_print_meta: ssm_dt_rank      = 0\n","llm_load_print_meta: model type       = 7B\n","llm_load_print_meta: model ftype      = Q4_K - Medium\n","llm_load_print_meta: model params     = 6.74 B\n","llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n","llm_load_print_meta: general.name     = LLaMA v2\n","llm_load_print_meta: BOS token        = 1 '<s>'\n","llm_load_print_meta: EOS token        = 2 '</s>'\n","llm_load_print_meta: UNK token        = 0 '<unk>'\n","llm_load_print_meta: LF token         = 13 '<0x0A>'\n","llm_load_tensors: ggml ctx size =    0.11 MiB\n","llm_load_tensors:        CPU buffer size =  3891.24 MiB\n","..................................................................................................\n","llama_new_context_with_model: n_ctx      = 4096\n","llama_new_context_with_model: freq_base  = 10000.0\n","llama_new_context_with_model: freq_scale = 1\n","llama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\n","llama_new_context_with_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n","llama_new_context_with_model:        CPU input buffer size   =     0.28 MiB\n","llama_new_context_with_model:        CPU compute buffer size =     4.50 MiB\n","llama_new_context_with_model: graph splits (measure): 1\n","AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n","Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n","Using fallback chat format: None\n"]}],"source":["llm_open = LlamaCpp(\n","    model_path=\"./llama-2-7b.Q4_K_M.gguf\", # https://huggingface.co/TheBloke/Llama-2-7B-GGUF\n","    n_ctx=4096,  # 4096 for Llama, 32*1024 for Mistral\n","    n_gpu_layers=50,\n","    temperature=0.15,\n","    top_p=1,\n","    top_k=40,\n","    repeat_penalty=1.1,\n","    max_tokens=1024,\n","    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n","    stream=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7BBRKwL7GoFY"},"outputs":[],"source":["def process_llm_response(llm_response):\n","    print(\"\\n\\nSources:\")\n","    for i, source in enumerate(llm_response[\"source_documents\"]):\n","        m = source.metadata\n","        print(f\"{i + 1}. {m['course_title']} ({m['course_number']}): {m['heading']}\")"]},{"cell_type":"code","source":["class ResponseFormatter:\n","    def __init__(self):\n","        self.responses = {\n","            \"question\": [],\n","            \"contexts\": [],\n","            \"answer\": [],\n","            \"ground_truth\": [],\n","        }\n","\n","    def add_response(self, llm_response, ground_truth):\n","        self.responses[\"question\"].append(llm_response[\"query\"])\n","        self.responses[\"contexts\"].append(\n","            [doc.page_content for doc in llm_response[\"source_documents\"]]\n","        )\n","        self.responses[\"answer\"].append(llm_response[\"result\"])\n","        self.responses[\"ground_truth\"].append(ground_truth)\n","\n","    def get_responses(self):\n","        return self.responses"],"metadata":{"id":"zZ-zQaIZ_5kQ","executionInfo":{"status":"ok","timestamp":1710544139264,"user_tz":300,"elapsed":3,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6jSlOi4WHCKI","outputId":"606f56df-40a5-435b-f0ae-6d19a847dbd8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710544139112,"user_tz":300,"elapsed":819518,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n"]},{"output_type":"stream","name":"stdout","text":[" hopefully, it will be a paper and presentation.\n","I am not sure if you are asking about the Capstone Project or the Capstone Paper. If you are asking about the Capstone Project, then you should contact your instructor. If you are asking about the Capstone Paper, then you can find information on how to write the paper by clicking on the link below:\n","https://brainmass.com/health-sciences/health-care-management/capstone-project-559841\n","The Capstone Project is an opportunity for students to demonstrate their ability to integrate their knowledge of health care management into practice. The project is designed to provide students with an opportunity to apply their knowledge of health care management to real-world situations. The project is also designed to help students develop their critical thinking skills and their ability to analyze and synthesize information. The Capstone Project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 3"]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =    4067.96 ms\n","llama_print_timings:      sample time =     679.04 ms /  1024 runs   (    0.66 ms per token,  1508.01 tokens per second)\n","llama_print_timings: prompt eval time =    7761.08 ms /    15 tokens (  517.41 ms per token,     1.93 tokens per second)\n","llama_print_timings:        eval time =  802815.61 ms /  1023 runs   (  784.77 ms per token,     1.27 tokens per second)\n","llama_print_timings:       total time =  819321.36 ms /  1038 tokens\n"]}],"source":["query = \"Tell me what I need to turn in for the capstone project.\"\n","\n","llm_response = llm_open(query)"]},{"cell_type":"code","source":["llm_response"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":330},"id":"TH3qp5puW-sE","executionInfo":{"status":"ok","timestamp":1710544139558,"user_tz":300,"elapsed":7,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}},"outputId":"3be9afa8-10f0-456c-edb7-720126da1cc6"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["' hopefully, it will be a paper and presentation.\\nI am not sure if you are asking about the Capstone Project or the Capstone Paper. If you are asking about the Capstone Project, then you should contact your instructor. If you are asking about the Capstone Paper, then you can find information on how to write the paper by clicking on the link below:\\nhttps://brainmass.com/health-sciences/health-care-management/capstone-project-559841\\nThe Capstone Project is an opportunity for students to demonstrate their ability to integrate their knowledge of health care management into practice. The project is designed to provide students with an opportunity to apply their knowledge of health care management to real-world situations. The project is also designed to help students develop their critical thinking skills and their ability to analyze and synthesize information. The Capstone Project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 30% of the final grade. The project is worth 3'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["capstone_requirements_llm_response = {\"query\": query, \"result\": llm_response, \"source_documents\": []}\n","\n","\n","capstone_requirements_ground_truth = \"\"\"\n","Final Project Submission including:\n","    A report that tells the story of your project, which can be formatted as a blog, a scientific manuscript, or something else.\n","    A GitHub repository full of the code required to reproduce your analysis and figures, documented with an informative README.\n","    One of the following high-level overviews of your work designed to be shared:\n","    A 3-5 minute video from your team about what you made.\n","    A poster appropriate for a data science conference, such as the MIDAS Data Science Symposium.\n","Weekly Mini-Deliverables: There will be weekly mini-deliverables throughout the course, as outlined in the grading section of the syllabus.\n","\"\"\""],"metadata":{"id":"2mWEVGVDAaGK","executionInfo":{"status":"ok","timestamp":1710544319641,"user_tz":300,"elapsed":3,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["formatter = ResponseFormatter()"],"metadata":{"id":"qC8HbRBHAdAQ","executionInfo":{"status":"ok","timestamp":1710544321739,"user_tz":300,"elapsed":132,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["formatter.add_response(capstone_requirements_llm_response, capstone_requirements_ground_truth)\n","\n","with open(f\"./evaluation_set_llm_formatter.pickle\", 'wb') as handle:\n","    pickle.dump(formatter, handle)\n","\n","with open(f\"./evaluation_set_llm_responses.pickle\", 'wb') as handle:\n","    pickle.dump(formatter.get_responses(), handle)"],"metadata":{"id":"RZ-puexzBFXu","executionInfo":{"status":"ok","timestamp":1710544325269,"user_tz":300,"elapsed":148,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["prompts = [\n","    {\n","        \"question\": \"Which class involves time series analysis?\",\n","        \"ground_truth\": \"Data Mining II, SIADS 632 includes a particular focus on time series analysis.\",\n","    },\n","    {\n","        \"question\": \"Who teaches the SQL and Databases class?\",\n","        \"ground_truth\": \"The primary instructor for SQL and Databases is Graham Hukill. Additional course assistants include, Derek Bruckner, Emily Schemanske, Jungseo Lee, and Toby Kemp.\",\n","    },\n","    {\n","        \"question\": \"What are the prerequisites for Data Science for Social Good?\",\n","        \"ground_truth\": \"SIADS 630, 631, and 694\",\n","    },\n","    {\n","        \"question\": \"When are the office hours for the Math Methods course?\",\n","        \"ground_truth\": \"Office hours for Math Methods are held at the following times: Alex McLeod: Monday at 11:45 am EST, Saurabh Budholiya: Friday at 9:00 am EST, Alexis Castellano: Thursdays at 7:00 pm EST\",\n","    },\n","    {\n","        \"question\": \"Are there any weekly readings for Milestone II?\",\n","        \"ground_truth\": \"There is introductory material during the first week of the course, but generally speaking, no weekly readings in this course.\",\n","    },\n","    {\n","        \"question\": \"What are the outcomes of Qualitative Inquiry?\",\n","        \"ground_truth\": \"Upon successful completion of this course, students will be able to:1.  Collect, represent, and analyze qualitative data about a quantitative data set, by…2.  Conducting semi-structured interviews;3.  Processing interview notes into discrete pieces of qualitative data; and 4. Analyzing qualitative data using affinity walls.4.  Develop a narrative about qualitative findings that support later quantitative analysis.5.  Communicate qualitative findings in written form.\",\n","    },\n","]"],"metadata":{"id":"gHl5R-TPCyyg","executionInfo":{"status":"ok","timestamp":1710544418146,"user_tz":300,"elapsed":134,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["for prompt in prompts:\n","  result = llm_open(prompt[\"question\"])\n","\n","  llm_response = {\"query\": prompt[\"question\"], \"result\": result, \"source_documents\": []}\n","\n","  formatter.add_response(llm_response, prompt[\"ground_truth\"])\n","\n","  # Save after each response\n","  with open(f\"./evaluation_set_llm_formatter.pickle\", 'wb') as handle:\n","      pickle.dump(formatter, handle)\n","\n","  with open(f\"./evaluation_set_llm_responses.pickle\", 'wb') as handle:\n","      pickle.dump(formatter.get_responses(), handle)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j2JXodnOCj-d","outputId":"61c84943-72a8-47ed-fcb5-6e7cc71913ac","executionInfo":{"status":"ok","timestamp":1710546694360,"user_tz":300,"elapsed":2199669,"user":{"displayName":"Patrick Sollars","userId":"17760862217283224903"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Llama.generate: prefix-match hit\n"]},{"output_type":"stream","name":"stdout","text":["\n","What is the difference between time series and cross sectional data?\n","How do you analyze a time series?\n","What are the types of time series?\n","What is the best way to forecast time series?\n","What is time series in statistics?\n","What is time series analysis in finance?\n","What is time series analysis in economics?\n","What is time series analysis in finance with example?\n","What is time series analysis in economics with example?\n","What is time series analysis in economics with example?\n","Time Series Analysis is a branch of econometrics that deals with analyzing time-series data. It is used for analyzing economic, financial, or other time-series data. Time-series data can be used for predicting future values, analyzing trends, or identifying patterns.\n","Time Series Analysis is a branch of econometrics that deals with analyzing time-series data. It is used for analyzing economic, financial, or other time-series data. Time-series data can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis is used for analyzing economic, financial, or other time-series data. It is used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used for predicting future values, analyzing trends, or identifying patterns. Time Series Analysis can be used"]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =    4067.96 ms\n","llama_print_timings:      sample time =     617.22 ms /  1024 runs   (    0.60 ms per token,  1659.05 tokens per second)\n","llama_print_timings: prompt eval time =    3955.29 ms /     7 tokens (  565.04 ms per token,     1.77 tokens per second)\n","llama_print_timings:        eval time =  804518.08 ms /  1023 runs   (  786.43 ms per token,     1.27 tokens per second)\n","llama_print_timings:       total time =  817318.73 ms /  1030 tokens\n","Llama.generate: prefix-match hit\n"]},{"output_type":"stream","name":"stdout","text":["\n"," surely, it is not a question of who but what.\n","I'm sure you can find a good book on the subject.\n","> Who teaches the SQL and Databases class?"]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =    4067.96 ms\n","llama_print_timings:      sample time =      32.30 ms /    42 runs   (    0.77 ms per token,  1300.27 tokens per second)\n","llama_print_timings: prompt eval time =    7555.68 ms /    11 tokens (  686.88 ms per token,     1.46 tokens per second)\n","llama_print_timings:        eval time =   32800.77 ms /    41 runs   (  800.02 ms per token,     1.25 tokens per second)\n","llama_print_timings:       total time =   40730.44 ms /    52 tokens\n","Llama.generate: prefix-match hit\n"]},{"output_type":"stream","name":"stdout","text":["\n"," nobody is perfect, but you should have a good understanding of statistics and probability.\n","What are the prerequisites for Data Science for Social Good?\n","You need to be able to write code in Python or R.\n","You need to know how to use SQL.\n","You need to know how to use Tableau.\n","You need to know how to use Excel.\n","You need to know how to use PowerPoint.\n","You need to know how to use Word.\n","You need to know how to use Google Docs.\n","You need to know how to use Dropbox.\n","You need to know how to use Slack.\n","You need to know how to use Skype.\n","You need to know how to use Zoom.\n","You need to know how to use Google Hangouts.\n","You need to know how to use Facebook Messenger.\n","You need to know how to use WhatsApp.\n","You need to know how to use Instagram.\n","You need to know how to use Twitter.\n","You need to know how to use LinkedIn.\n","You need to know how to use YouTube.\n","You need to know how to use Google Maps.\n","You need to know how to use Google Earth.\n","You need to know how to use Google Street View.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Search.\n","You need to know how to use Google Images.\n","You need to know how to use Google News.\n","You need to know how to use Google Scholar.\n","You need to know how to use Google Books.\n","You need to know how to use Google Patents.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate.\n","You need to know how to use Google Translate."]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =    4067.96 ms\n","llama_print_timings:      sample time =     312.46 ms /   470 runs   (    0.66 ms per token,  1504.18 tokens per second)\n","llama_print_timings: prompt eval time =    8008.16 ms /    14 tokens (  572.01 ms per token,     1.75 tokens per second)\n","llama_print_timings:        eval time =  351631.71 ms /   469 runs   (  749.75 ms per token,     1.33 tokens per second)\n","llama_print_timings:       total time =  363334.42 ms /   483 tokens\n","Llama.generate: prefix-match hit\n"]},{"output_type":"stream","name":"stdout","text":["\n"," surely you can't be serious.\n","I am not sure if I am allowed to answer this question, but I will anyway.\n","The office hours for the Math Methods course are 10:30-12:30 on Mondays and Wednesdays in room 444 of the Mathematics building.\n","If you have any other questions about the course, please feel free to email me at john@math.ubc.ca."]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =    4067.96 ms\n","llama_print_timings:      sample time =      63.81 ms /    99 runs   (    0.64 ms per token,  1551.38 tokens per second)\n","llama_print_timings: prompt eval time =    7062.81 ms /    12 tokens (  588.57 ms per token,     1.70 tokens per second)\n","llama_print_timings:        eval time =   71821.89 ms /    98 runs   (  732.88 ms per token,     1.36 tokens per second)\n","llama_print_timings:       total time =   79646.44 ms /   110 tokens\n","Llama.generate: prefix-match hit\n"]},{"output_type":"stream","name":"stdout","text":["\n"," nobody has posted anything yet.\n","I'm not sure if this is the right place to post, but I thought it would be a good idea to have some sort of discussion about our milestones and how we are doing on them.\n","I think that we should all try to post something every week so that we can keep track of each other's progress.\n","If you don't know what your milestones are or what you need to do to complete them, please ask your instructor or TA."]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =    4067.96 ms\n","llama_print_timings:      sample time =      69.16 ms /   109 runs   (    0.63 ms per token,  1576.17 tokens per second)\n","llama_print_timings: prompt eval time =    6762.83 ms /    12 tokens (  563.57 ms per token,     1.77 tokens per second)\n","llama_print_timings:        eval time =   77684.95 ms /   108 runs   (  719.31 ms per token,     1.39 tokens per second)\n","llama_print_timings:       total time =   85273.17 ms /   120 tokens\n","Llama.generate: prefix-match hit\n"]},{"output_type":"stream","name":"stdout","text":["\n"," surely, you can't just say \"I am a qualitative researcher\" and then go on to do quantitative research.\n","The outcomes of qualitative inquiry are not limited to the data that is collected but also include the process of collecting it. The process of collecting data in qualitative research is often more important than the actual data itself. This is because it allows for a deeper understanding of the subject matter being studied.\n","Qualitative researchers often use interviews or focus groups as their primary method for collecting data. These methods allow for in-depth conversations with participants which can provide valuable insights into their thoughts and feelings about a particular topic or issue. Additionally, these methods allow for open-ended questions which allow participants to share their experiences in their own words rather than having them respond to predetermined questions set by the researcher. This allows for more nuanced understanding of complex issues than would be possible through traditional survey methods such as questionnaires or polls which only provide binary answers (yes/no).\n","Qualitative researchers often use multiple methods when conducting their studies in order to get as much information as possible about their subject matter before drawing any conclusions about it based solely on quantitative evidence alone (e.g., survey results). For example, they may use both interviews and focus groups in order to get different perspectives from different groups within society about an issue or topic being studied; this helps them understand how different groups view things differently from one another which could lead them down different paths when trying to solve problems related to said issue or topic being studied by them respectively..\n","What are the strengths of Qualitative Inquiry?\n","What are the strengths of Qualitative Inquiry? The strengths of qualitative inquiry are its ability to provide in-depth understanding of complex issues, its ability to capture nuanced perspectives from multiple sources, its ability to generate new insights through open-ended questions, its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an issue or topic being studied by them respectively., its ability to provide multiple perspectives from different groups within society about an"]},{"output_type":"stream","name":"stderr","text":["\n","llama_print_timings:        load time =    4067.96 ms\n","llama_print_timings:      sample time =     709.87 ms /  1024 runs   (    0.69 ms per token,  1442.51 tokens per second)\n","llama_print_timings: prompt eval time =    8591.27 ms /    12 tokens (  715.94 ms per token,     1.40 tokens per second)\n","llama_print_timings:        eval time =  795203.09 ms /  1023 runs   (  777.32 ms per token,     1.29 tokens per second)\n","llama_print_timings:       total time =  812791.47 ms /  1035 tokens\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zq_7_dEIEzO8"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":0}