Hi everyone, this is tutorial six
of the PyTorch Tutorials series and in this tutorial we'll learn,
transport learning for computer vision. And this notebook is also adapted
from the official PyTorch tutorial with the same title,
transfer learning for computer vision. So what is transfer learning, right? So transfer learning basically means, we pre train a neural network
model based on one task for example, maybe we have a very large
data set with images and labels. We can pre train this this huge
neural network on this data set, by doing a classification problem. But later on we can transfer
this model to another different task with a new data set but
keep all the existing weights. That's actually a very useful technique
for solving a lot of problems, especially in computer vision but
now definitely in other domains. This method is also getting
a lot of popularity right now. So in this tutorial we will learn
how to train a convolutional neural network CNN for image classification
using transfer learning. Meaning we already have a pre
trained neural network that trained on some other data set, but we want to
transfer this model to our data set. You can read more about the concept of
transport learning following this link, but here is a little bit of motivation for
transport learning, right? You may ask why we want to
do this transport learning? So far from the previous tutorials we have
learned the essentials of PyTorch for example, tensors and their operations. How to load data in PyTorch,
how to build a model in PyTorch, how does the autograph work in PyTorch and
so on. Those are very important steps you should
take when you're learning PyTorch, but in reality when in practice
you almost never build a neural network from scratch using
your own data in that way. Because one reason could be,
it's very unlikely that you'll have a data of sufficient size to
train a neural network sufficiently so that it can achieve great performance. Or you may not have the patience
to training neural network, because training a new network
from scratch is an art. There are a lot of things you
need to consider and to adjust so you may not have the patience
to train something from scratch. So rather it's very common to like I said, pre trained model on a very large data
set, maybe based on some other tasks, but later on transfer this
model to our task at hand. So that's the moderation for
transfer learning. So in general,
such a neural network pre trained on a large data set is now
known as a foundation model. And there's a paper introducing
the concept of foundation model you can follow the link and
read the paper if you're interested. And one prominent example,
not from the computer vision domain, but from the natural language
domain is the Bert model for a lot of natural language tasks. So what people do with
the Bert model is that, they train Bert model on large
sort of text dataset and then transfer the Bert model
to some new tasks, right? So if we have a foundation model, we can do two tasks among
many other tasks, but we'll consider those two
tasks in this tutorial. So we can either finetune the model,
meaning instead of training a new completely new model
randomly initialized model. We can start training the whole model but
with the weights provided by the foundation model, meaning we just
take the foundation model as it is. And start to train this foundation
model using our data set and lost function and so on. That's called a finetuning or
instead of training the entire foundation model or
pre trained model, we can use the foundation model
as a fixed feature extractor, which means that we'll turn off autograd. Remember autograd is the part of
network that supports automatic differentiation, If we turn off
autograd for all of the models, that means we're no longer
training those part of the model. Right, well we're going to turn off
autograd for all parts of the model but maybe the last layer, so
that we can train the last layer only. So that's called EUS model, EUS the foundation model as
a fixed feature extractor. Because all the previous parts are fixed, they're not changing their
not being trained so they are fixed, but
only maybe the last layer is flexible. We're still trying to adjust the last
layer so that it works well for our task. And in either case we often
need to replace the last layer, which is usually a linear layer,
a fully connected layer with all features equal
to the number of classes. If we're talking about classification
problems, if we're talking about regression problems, then the all
features is usually one, right? As we have seen in one of
the previous tutorials. So we need to replace that
with the correct new linear layer that has the correct
number of other features. Because in the pre trained task
there may be 10 classes, but in our task there could be
1,000 classes or vice versa. The task where the model was
pre trained on the number of classes in that task may not be the same
as the number of classes in our task. And also the last layer is usually
considered as the classifier and all the previous layers
are considered as feature extractor. So the classifier should be different for
different tasks, right? So we usually will have to replace
the last layer with a new layer, with the correct number of features. That's generally true, not only for
computer vision tasks, but also true for natural language tasks. And so I think when people
are dealing with Bert model, they also keep the most part of the Bert,
but maybe replace the last layer
depending on what their tasks is. Okay, but for this tutorial,
we will look at transfer learning for
computer vision by the same concept or even the same procedures
to play with the foundation model would be the same for other domains. So let's try to import
necessary libraries. In this case, in addition to PyTorch,
we also have this torchvision, which is the official PyTorch support for
computer vision tasks. So now let's try to load our dataset. So in the official tutorial, they used part of the ImageNet I believe, a few classes from the ImageNet. But here, we're going to use
the classic CIFAR-10 dataset instead. So CIFAR-10,
you could consider that as a kind of lower resolution version of
the ImageNet dataset. So each image is 32 by 32 color image,
three channels, RGB. And of course,
it's a very classic dataset. And due to its importance in
the development of deep learning, CIFAR-10 definitely has
earned a spot in torchvision, the official PyTorch package for
computer vision tests. And all that words means to us is
that we can just load CIFAR-10 from the torchvision library very easily. So let's see how we can load this dataset,
right? Actually, the code for loading this
dataset is only in the last two lines. As you can see it's very easy. So CIFAR-10 is a class
from torchvision dataset. You just need to pass in the route,
whether it's train set or test set, whether you need to
download those dataset or not. Because if you set it true,
PyTorch will download the dataset for you if the data set
does not already exist. One interesting part
is the transform part. So we're loading those preloaded
datasets from torchvision. It allows you to pass in
a parameter called transform. Which basically represents some sort
of image pre-processing for those data. And in this case, we have all
the transforms are collected in a dictionary here actually,
because we have different transforms for training set and for the test set. If you look at here, for
training set, we basically have three sort of pre-processing steps or
three transforms. We have, for example,
a RandomHorizontalFlip, so that's considered as a data augmentation. So at the train time,
PyTorch will randomly horizontally flip the image
with certain probability. I think by default is maybe 0.5. Another transform is ToTensor,
which basically means that's going to convert whatever data
that is to PyTorch tensors. And also normalize. So this normalize is kind of similar to, if you use Sklearn similar to
the StandardScaler, I guess. Which basically will do a main
standard deviation normalization. But in this case,
because we're dealing with images, this actually means channel-wise
data normalization. We know for
color image we have three channels, right? And I think these are the mean for
each of the channels and standard deviation for
each of the channels. I think people just pre-calculate those
means and standard deviations for this CIFAR-10 dataset or
it could be based on the ImageNet dataset. And similarly for tests, the only difference that we don't
do data augmentation for test data. Because that will ensure consistency for the performance on the test set, right? Because we have to eliminate
any randomness from the test set by not adding any
random data argumentation. Okay, so
that would allow us to load those data. As you can see,
it helps me to download those data. And actually there are many other more
transforms in the torchvision library, so you can try to check that out
yourself and learn what the options are. Okay, so pretty smooth. Dataset already downloaded and verified. Now we can try to understand this object,
right? We have this CIFAR-10 train object. Now I'll tell you that it's actually
nothing special but a dataset object. We have seen dataset in previous tutorial. It's basically a way for
us to manage our data, right? So the CIFAR10_train is
an instance of dataset. And because of that, we can compute
the length of our dataset, right? By using the length operator. So you can see that we have 50k
training images and 10k test images. And now we can even do a validation and
test split. We take half of the test set as validation
set, the other half as the test set. So you can do all this
by using random split. Which I have shown to you
in the previous tutorial. Okay, so
once we have those three datasets, we can put them into
dataloaders right away. So create three dataloaders. It's kind of nice to put
them into a dictionary so that you don't have to create
like three variables for those. If you need any other day loaders,
you can just index into the dictionary. And we keep a record of
the length of each dataset, pretty standard stuff. Now let's try to visualize
a few training images so that we can understand maybe
the effect of data augmentations or just try to give us a picture of
what pictures we're dealing with, what images we're dealing with, right? So import the library,
remember we can use next and either to grab a batch of training data. In this case,
because the batch size is 128, so the size of the input is this. Remember it's three channels,
32 verse 32 for each channel. And the label is just just a vector of
128, actually, we can print out labels. They're basically integers
representing the classes. But if you just look at this alone, it's kind of unclear which class
those numbers are referring to. So there is a very nice
map from the classes to the labels provided by the data set. So if say for 10 train is the data set
we preloaded from torch vision and it actually has an attribute
called class to index, which will show you a mapping
from the class names to the cost labels, numerical labels. And of course,
it's also the other way around. It's also a mapping from
the labels to the class names. So those are the 10 categories that we're
trying to differentiate from, right? Okay, so now this function will help us to visualize a few images. So I'll just print out images here so we can see those are the class names and those are the images. Because we have done, there could be a random horizontal flip, so some of the mages
could have been flipped. So for that with this car could have been,
maybe it's sort of facing left but we flip it around so
it's facing right right now. So that's the effect of horizontal flip. So after understanding the data now,
let's try to train our model, let's first try to write
a function to train our model. And in doing so will also illustrate
scheduling the learning rate and also saving the best model. So here is a function that's provided
by the official tutorial but I sort of modified it a little bit. So this is actually a pretty good
function that in the sense that it provides a good structure for
you to follow. You can if you if you were
to write your own train model function you can
basically follow this tablet. So basically it accepts
inputs like the model, the loss function,
the optimizer scheduler, and the number of epochs to run. As usual, we define the device,
send model to the device, and optionally you can have
a timer to time how much time does it use to train the model. And here is an interesting way
of saving the best models. Actually, we haven't really
talked about how to save a model. And here is actually one way, so we can, actually all the ways all the model ways, all the state of the model
can be accessed through this attribute called state dictionary. So it's a dictionary
containing all the weights and all other permanent buffers in intermodal. So by saving the model we're
really trying to save this state dictionary because that's what
defines the model, right? Different models, I mean
the architecture could be the same but they could have different states. So those are the variables that
we're interested in saving. So we'll just have
a variable that's always hold the best, the ways of the best model, the state dictionary of the best model. And I have another variable that's
always hold the best accuracy because we're doing classification in this case. So the best model is defined as
the best model that achieved the best accuracy on the validation set. So those are the two variables and now we begin the training loop. So for each during issue park,
we have two phases trained validation, if it's trained,
then we set the model to training mode. If otherwise, we set model two evaluation mode which I
have explained in the previous module. So we have another variable to
keep track of the running loss and also the running correct, which means the number of correct
predictions for our model. So under this phase, Under those two phases we just
iterate over the data, right? Input labels, data loader and
send those to device. And here comes the forward. Here is an interesting structure here, this torch set grade enabled
allows you to enable and disable gradient computation based
on some bullying conditions, in this case is whether phases trained. So that means if it faces trained if
we're in the training phase then or enable grad gradient calculation,
but if not, we'll disable gradient computation. So well, we just run our inputs through
our model to get the outputs and compute the loss using the loss function,
right? Loss function, outputs, and labels. And we do those for both trained
validation, but we only do backward and optimization only for
the training phase, right? So if faces trained then we
just do the routine here. Optimizer, zero regret, lost backward, computer gradient,
optimizer step take optimization step. Okay, so, I mean, it's just a pretty standard stuff we
have discussed in a previous tutorial. So here are some interesting ways
of keeping track of some stats. For example, we can compute
the predictions of our model. For a classification problem,
you can think of the outputs as the unnormalized probability for
each class. So basically they're kind
of probabilities, but unnormalized meaning they do
not necessarily sum up to one, but they do represent sort of
the likelihood of each class. So by having our model
to make a prediction, it means we just take whatever index that has the highest output activation. Right, so we're taking the argmax,
which means the index of the output where we have the largest
activation, the output, right? Along dimension one because dimension
zero is the batch dimension, dimension one is the sort of for
each class. That's how we generate
the predictions using our model. And running laws,
we have probably have seen this before. So it's basically the laws for
this iteration times the batch size, the size of the current batch
because this loss has been averaged. So we want to sort of recover
to the total loss of the batch. And later,
only after training will compute sort of the average loss or the entire data set. And for classification problems, we can also compute sort of
the cumulative running corrects, basically it's the number
of correct predictions. So it's just simply,
predictions is also array of integers, labels is also array of integers. So, the torch sum over
this boolean tensor will basically give you the number
of positions where the prediction actually equals to labels, which is just a number
of correct predictions. So those are for under each batch, right? And after iterating the data set, you may have to adjust
your learning rescheduler. So scheduler here is really
just a learning rescheduler which adjust your learning rate
possibly based on some conditions or possibly based on some
predetermined formula. And in this case if you want
to adjust your learning rate, every epoch,
then this is a place where you should place your scheduler step, right? So here is actually under, it's not
under each batch, but it's under each, Each epoch actually. And we said that it's in the training
phase will just scheduler. So we'll skip for the validation phase. So this is useful if
when we want to adjust your learning rate every epoch. But sometimes you may want to adjust
your learning rate every batch. After every batch,
you may have to adjust your learning rate. If that's the case,
then you just need to indent this piece of code inside by one because then it
will be under the batch loop, right? But currently it's sort
of under the epoch loop. Okay, anyway, and then finally we
can compute the average loss for the entire epoch over entire data set and the average accuracy over
the data set as well and print out those stats. And we do those accuracy and loss calculation for
both training and validation. But if it's in the validation phase and the current epoch accuracy is
better than our existing accuracy, then we're going to update our record and also update the best model weights. We just do a deep copy of
the latest static from our model. Okay, so
that's pretty much the training loop and I guess all the rest is basically compute
time and printing out the best accuracy. And finally, we load our model
with the best weights because the best weights may not necessarily
happen at the very last epoch, right? So it could be somewhere in the middle for
example. So, we basically reload our model with the
best model weights and return the model. So that's a pretty long
train model function, but it's a very good template that you could
base your own train model function. Okay, just another function to visualize the predictions, I'll not go into details. It's kind of similar to
the train model function except that it only works
with the validation data. So we'll just run the cell and we can move on to find training component. So, remember by fine training a model, we start training with the waste
provided by the model and probably reset the last fully
connected layer to suit our problem. And we can easily load a popular
pre-trained vision model from torch vision models. If you follow this link, you'll see a bunch of a list
of other pretrained models. But in this case as a demonstration, we'll just lower this resnet18 model, is one of the pre training model. So if you do this, you will download
the model for you, just like for the data sets and load the weights
that's provided by the model. Okay, we can actually print out this
model just a sees architecture. Well, it's kind of long here, but basically it's a resnet architecture. It starts with some convolution,
batch norm, relu,maxpool, to reduce the dimension,
followed by a bunch of blocks. bunch of standard blocks. So you can see layer one, layer 2 and
all the way I believe, since it's called. Okay, layer four. and each layer actually, I think
the reason it's called resident 18, is that it probably really contained
roughly 18 convolution layers, I believe. Okay, so basically followed
by four standard blocks. Right? And then we have an average
pulling in the end and finally, here is what we should
pay attention to finally, we have a fully connected layer. Fc does a linear is n linear
module within features 150, sorry, 512 and all features equal to 1000. So, all features equal to a 1000
means when pre-training this model, It was trained on classification
problem with the 1000 classes. But in our case we only have 10 classes. So we definitely need to
reset this last layer. So, as I'm also showing here,
the last layer is a linear classifier. Then maps some hidden
features of 512 Dimensions. That's the in features to the out
normalized probabilities for each of 2000 classes. That's out features. We can't really change the dimension of
the hidden features because that number is based on all the previous layers and
we cannot change all the previous layers. But in this case, we should replace
the final layer with the new one. that has the correct out features,
which is 10 in this case. The replacement is also,
it can be easily done. Those layers are basically a tribute on this model. So we can just model ft. Model fine tuning is our model dot fc, we can access our attributes in that way, just reassigned to a new layer. Then we're done with replacement. So we re-assign fc. To be in a linear with the old in features which is 512. But now the out features is just 10
because we know we have 10 classes. So this is very easy replacement step. Finally, our model is now up to date,
we can define the loss function for classification, we have CrossEntropyLoss, the optimizer,
we use the SGD optimizer but because we are fine-tuning
a pre-training model, so usually the learning
rate should be that small. We started to the small
number in this case we have a exponential decay
learning rate schedule. Basically your decay learning
rate by a factor of gamma, which is 0.1 every seven epochs. But of course, for different problems, you may want to fine-tune this
learning reschedule for your problems. We can define those variables and
then finally we can train our model, because for the purpose of demonstration, I only train the model for
five epochs just to show you the progress. And of course we're training on Gpu
because I'm having a Gpu around time. It should be pretty fast, except for the initial right,
take a lot of your time. You can see that we're printing out
the stats for each epoch, right? The loss and also accuracy for
both training and validation. [SOUND] We can see that
the training loss and also the validation losses declining, which is a good sign. And they're sort of still in sync rather. The validation loss is better
than the training loss for now, but not for
the case when the 3rd epoch is finished. We can see that the training loss now is lower than the validation loss and accuracy, sort of increasing. You could change the number of epochs and to run more epochs, but I think we are probably seeing some early signs of or fitting because, the training loss is kind of a little bit out of sync with the validation loss and I'll leave it to you to
investigate further, but we can visualize our
model predictions, I think. And here,
the pictures are definitely not of great resolution because there are only 32 x 32,
but we can roughly see the shape here, right? For example, for the shape here, this rather look like
a shape of an automobile, It looks like a car, right? So looks like we're making
the correct predictions, this is another shape,
bird ,and is airplane? But it looks looks like a car or
something. Or look at that deer. Okay, prediction deer, anyway, you can play with this yourself more now. Let's move on to using component
as a fixed feature extractor. So here we need to freeze all parts of
the network except for the last layer. And more specifically,
we need to set that requires grad attribute to false for
all the parameters in our model so that no gradients will be computed for
them during loss backwards. You can read more about,
freezing the model. From this link here. So basically, we'll load the pre
trained model as before but give it a new name, and
then we'll free the parameter. So the way we do this is very simple, basically one way is that you can
just iterate over all the parameters. We have seen this in a previous tutorial. And then for each parameter you
just set the attribute to false or you could just do the model
that requires grad false. Those two ways, you can do either one. Again, we had to reset the last layer,
right, the last linear layer to a new layer
with the correct odd features so this is the same as before. So we can run this and load the model,
and everything else is the same and the loss function optimizer and
scheduler, everything's the same. So we'll just run this. So remember this is using the model as a fixed feature extractor which is different from fine tuning the cargo net. So let's see how the train laws and
validation laws behave in this case. As you can see, since in this case we're
only training the last layer, right? Where we have freezed all the layers
before but only trained last layer. So you can see the initial
accuracy is not great, right? It's only like 35 for training. We have 10 classes, random gas
will give you like 10% accuracy. So we start in the low thirties and gradually improving to 40 and 45. But remember back in
the fine training case, we started right off at 59 and then 70, 80, right, quickly. But here we sort of, it's kind of slower because we're only
training the last layer. We're not training all the previous
layers, only the last layer. So is understandable that the training progress will be relatively slower. But in this case,
probably we have not seen an early sign of overfitting just yet. The train laws and
validation laws sort of stay in sync. So we need to maybe train a little more to
see whether we have or fitting or not, but it doesn't look like we have
over fitting at this stage. Okay, so that maybe one
advantage of using the model as a fixed feature extractor instead
of training the whole model, fine training the whole model
which can lead to overfitting. Okay, we can also
visualize the prediction. In this case,
you can actually check yourself that, I don't think the predictions
are very accurate because, as I said, we're only training the last layer. So we shouldn't expect accurate
model after just 5 epochs. So for example, it predicts a car as a ship and so on, right? We definitely need more epochs
to achieve greater accuracy. Okay, I think that's all for this tutorial
transfer learning for computer vision. So I have demonstrated
one of the more likely workflow in your future career in pytorch,
right? Which is to fine tuning the model or use a pre training model as
a fixed feature extractor. The techniques discussed here are not
limited to only in the computer vision tasks. It also transferrable to other
tasks like natural language tasks, and for that,
especially those bird models, I highly recommend you to
read the documentation or the tutorial from
the hugging face website. So hugging face is a,
since the start up as a company that works on providing a lot of NLP
natural language models for practitioners to use and
they have great tutorials on how to use birds
provided by their company. Okay, thank you for watching.