Hi everyone, this is
Paramveer Dhillon. Now that we have studied several architectural
details of CNNs, including their
end-to-end training, let's see some of
the success stories and some applications of CNNs. Before we look at any of the successful applications
of CNNs to imaging data, we need to look at one
of the major reasons for this revolution in computer
vision over the last decade. As we discussed earlier, one of the reasons deep-learning
models have gained so much attention from
academics, industry, and media over the last decade is due to the availability of large datasets on
which we can train these deep models with
lots of parameters. It is hard for us to find a better example of such
a dataset than ImageNet. ImageNet is a large-scale, hand annotated visual dataset. In fact, it is a
knowledge ontology with over 14 million images belonging to more than
20,000 categories. Images in the dataset contain a highly
diverse set of images. For example, the snapshot
on the slide shows the images with a tag courtyard
in the ImageNet database. As you can see, the
various images have significant variation in images due to varying angles, lighting, illumination, occlusions,
etc, which makes correct image classification on this ImageNet dataset
a very hard problem. After the dataset was collected, the creators ran an
annual ImageNet, image classification challenge, in which researchers
from all over the world competed to build highly accurate models
for this dataset. Perhaps one of the first
successful applications of CNN to ImageNet dataset
that highlighted a significant improvement in
state of the art and drew everyone's attention
was the model called AlexNet due to Krizhevsky et. al at NIPS 2012. AlexNet gave a
significant reduction in error over its competitor, but still did not reach
human-level accuracy on ImageNet. As we have seen, one of
the shortcomings of CNNs can be that they're
slow to run and computationally
expensive in general. A group of researchers
proposed a variant of CNNs called region-based
CNNs or R-CNNs, that gave the almost real-time
object classification. Real-time object classification
is of utmost importance in tasks such as autonomous
driving and surveillance. The key novelty in
this work by Re et. al in 2015, was to share convolutional layers
with state of the art object
detection networks. By sharing convolutional
layers at test time, the marginal cost for
object detection is small, hence leading to almost
real-time object detection. CNN architectures also led to significant improvement
in scene labeling tasks, where the goal is to segment the scene into various objects. In fact, real-time
scenes segmentation is a key requirement for several tasks such as autonomous driving
and surveillance. Another compelling
application of CNNs to image data is by
combining image data with text data to generate
captions for images by performing what's called a
visual semantic alignment. The application of CNNs
to images are not just limited to routine image
labeling tasks that we just saw. There is also an insignificant
interests in using CNNs for health-related
applications. For example, the slide shows a healthcare application where
CNNs were used to extract visual facial features
of patients which were subsequently used to
detect genetic disorders. This application is
quite remarkable as it beat clinicians in three
initial experiments and shows the promise of CNNs in extracting new health
features that are correlated with
important target labels such as genetic
disorders in this case. We saw several successful
applications of CNNs to imaging data
and believe me, this is just the
tip of the iceberg. There has been staggering
progress in the field of computer vision in
the last few years, leading to several successful
practical applications of those advances. A natural question arises as to what do these visual features
extracted by CNNs capture? It turns out that CNNs learn hierarchy of features at
different levels of abstraction. For instance, it
has been seen that the lower layers of CNNs capture more genetic features and
higher layers capture more specific features
pertaining to the object class that
is being classified. I encourage you all to view this interactive demo
and play around with it. It uses a CNN for digit
classification and shows the type of visual features extracted by the different
layers of a CNN.