Hi everyone, this
is Paramveer Dhillon. In the last video, we learned about several
architectural details of the convolutional
neural networks. We will build upon those
ideas in this video and we will study how to
train the CNNs. The training of CNNs proceeds in a similar fashion
as we discussed in week 1 for feedforward neural networks
and multi-layer perceptrons. In fact, this is a common
theme throughout this course. As we will see, the
training details of various neural network
architectures are very similar. In order to train CNNs, we incorporate
non-linearities via activation functions
such as ReLU or sigmoid. We control model
complexity by dropout, early stopping, and
data augmentation. Data augmentation, in fact is a very popular choice for
CNNs since as we saw earlier, there are several transformations
which make a lot of sense for image data
such as rotation, cropping, mirroring,
which preserve the semantic content of the image and hence
the class level. Loss minimization for CNNs
is again performed via backpropagation and
batch normalization is used to stabilize
the training procedure. The gradient-based
optimization is typically performed via one of the adaptive gradient methods that we saw earlier
such as Adam, or Adagrad, or RMSProp. Here we can see the
end-to-end pipeline for image classification
via CNNs. As we saw earlier, CNNs consists of several
convolutional layers with non-linearities and
an occasional pooling. If our final goal
is classification, then we flatten the
final activation map of our CNN from a matrix
to a long vector, which is then input to a
fully connected layer. Finally, we minimize the multi-class
cross-entropy loss for our multi-class
classification problem via backpropagation using
gradient descent with adaptive learning rates. I encourage you all to check
out this really neat demo showing CNN-based
digit classification. The demo also allows you to
change the architecture of the CNN and see its impact on the visual features
learned by CNN, as well as on test set
prediction accuracies.