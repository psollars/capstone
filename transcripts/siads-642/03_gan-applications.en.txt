Hi everyone. This is
Paramveer Dhillon. In this video, we
will learn about some applications of the GAN or the Generative
Adversarial Network model that we just learned
in the previous video. As was stated earlier, one of the reasons behind using generative
models to generate new data was to increase the diversity or the variety
of the existing data. Here we can see that if you
look at the nearest neighbors of the digits and facial
images generated by GANs, that there is variety in results, and that the GANs just don't copy the input images in
the training dataset. These images are taken from the original
GAN paper which is by Ian Goodfellow at al and it appeared at Newreps in 2014. One of the really
cool extensions of GANs is what's
called the CycleGAN, which essentially learns
a transformation between two images based on optimizing
an adversarial loss. CycleGANs can be
used to transform input images into
so called styles. As you can see from the examples, CycleGANs can be
used to transform an image of horse
into an image of zebra and could transform an image into the style
of Monet or Van Gogh. Researchers have taken
this idea a step further, where they morph one
image into the style of another by proposing the new generator
for image synthesis. I encourage you all to go to the website linked
from the slide that contains images of people who do not
exist in reality, you'd be blown away by how
realistic the images are. There has been a big
spike in research in GAN-related papers since
the inception in 2014, as you can see from the
histogram shown on the slide. There are two main themes
in GAN-related research. The first type is the set of papers that propose
various novelties in the generator and
discriminator architectures could generate different
styles of images. We saw examples of these
work in the previous slides. The second types of
papers are those that borrow the idea of
adversarial learning, that is a two player
minimax game and apply it to train other types
of deep learning models.