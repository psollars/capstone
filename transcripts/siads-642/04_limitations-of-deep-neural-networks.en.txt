Hi, everyone. This is Paramveer Dhillon from the School
of Information at the University of Michigan. Till now, we have seen several different neural
network architectures in this course. Particular we have seen feed
forward neural networks. We have seen the multi layer perceptron,
convolutional neural networks and RNNs. So next, we will study some of
the limitations of deep neural networks. Hornik et al in 1989 proved
a universal approximation theorem, which showed that a feedforward neural
network with just a single hidden layer is sufficient to approximate to any arbitrary
precision, any continuous function. Though the theorem states a strong
statement regarding the representation and strength of neural networks,
it unfortunately says nothing about the learnability of those parameters from
the data, or how wide a neural network, that is, how many neurons in
that hidden layer do we need. It turns out that the parameters in that
hidden layer could be infeasibly large. Further, the theorem says nothing about
the generalization power of the neural network to new data. Deep learning has undoubtedly had a golden
decade as you can gather from the success it has enjoyed in so many different
domains such as text, speech, and vision. Unfortunately, it has led to
widespread hype in popular media in terms of depiction of
the capabilities of AI. However, this is not the first
time that AI has been hyped. There was huge hype around AI and
neural networks in the 1950s and 60s, and then again around mid 1980s. This has been followed by
periods of AI Winter or bursting of a bubble in the mid 1970s and
mid 1990s. As we have seen throughout this course, neural networks are an excellent
functional approximators, but only when they have access to
lots of data such as image net. And even then, they can be fooled and
led astray, which has led to an active area of research on robust
deep learning on robust neural networks. One of the most glaring shortcomings of
neural networks and one that has received a lot of interest lately is regarding
adversarial attacks on neural networks. Essentially, it means that
we can add some small imperceptible noise to an input image and
totally mislead the neural network. As you can see on the slide, we add
small noise to the image of a panda and the neural network now classifies
it as an image of a gibbon. Let's try to get some intuition
regarding how a simple looking noise could constitute an adversarial
attack on a neural network. In order to appreciate what's happening,
recall that neural networks are trained via
gradient descent with the model weights being updated by backpropagation as shown
in the update equation on the slide. And as we know, model learning happens
by changing the model parameters in the equation while holding fixed the image
and the labels, that is the x and the y. Let's see how we can modify
the model update equation to generate adversarial images. Essentially, we just modify
the image to increase the loss of the model by keeping fixed
the model parameters theta and the labels y by changing the image
pixel or Input features x. And we keep on changing the image
pixels till we can maximize the loss of the model. Now that we have seen the skeleton
of adversarial attacks on images, it is worth mentioning that there has
been research on mounting defenses against such kind of adversarial
attacks on neural networks. But we'd want the neural networks to be
robust to a variety of adversarial attacks if we are to deploy them in some
important domain such as driverless cars, or surveillance, where there is a real
high cost of committing an error. And as we all know, there are incentives
for malicious components in our society to mount such adversarial
attacks on such systems. So this research paper by Athlaye et al, in 2018 is a good example of
generating robust adversarial examples. In particular,
this paper generated examples that are adversarial over
distribution of transformations. Finally, let's summarize, though neural
networks have seen much success and fanfare in the last decade, but
they also have several limitations. First, neural networks require lots
of training data in order to output high performing models. And state of the art neural networks
these days have millions of parameters. Second, the trend in recent years has
been to make the neural networks deeper as it allows us to learn more flexible,
nonlinear representations of data. But this has a downside, that deeper neural networks can be
computationally very expensive to train. Third, as we just saw, neural networks
are susceptible to adversarial attacks. Finally, neural networks require lots
of expert knowledge to train and fine tune the different architectures. And some of it might seem like a dark art.