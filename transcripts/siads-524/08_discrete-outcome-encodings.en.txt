Welcome back. This lecture is entitled
Discrete Outcome Encodings. Now so far, we've discussed
continuous uncertainty encodings, which have included cumulative
distribution function plots or CDFs, and density plots which we make from
probability density functions. These representations of uncertainty are
called continuous uncertainty encodings because they involve encoding and
uncertainty using a continuous distribution rather than
a discrete distribution. In this lecture, we're going to explore
a second type of uncertainty plot, the discrete outcome encoding. In discrete encoding, we represent
the underlying distribution not as a continuous function,
but as discrete values. Let's take a look at
the example on the screen, we have miles per gallon from
the empty cars, dataset. The encoding we're using to represent this
distribution of miles per gallon is called a quantile dot plot, that's a specific
kind of discrete outcome encoding. In this lecture, we discuss the general
use of discrete outcome encodings and look at examples where we apply them
to binary and continuous outcomes. I want to start this lecture with a view
into why we discuss these techniques which will hopefully motivate the need for
learning about discrete outcome encodings. Now one of the ways we evaluate the
quality of an uncertainty representation is to ask the question, how easy is it for
users to ignore the uncertainty? For example, let's take one of the most
popular uncertainty representations we've discussed, the single confidence interval. Now if we look at this empirically, perception tests reveal that users
often focus on the point estimate, the value in the middle, and
they ignore the uncertainty around it. Another way in which
uncertainty can be ignored is by replacing quantities that express
some underlying uncertainty with dichotomies that essentially
ignore the uncertainty. This is sometimes referred
to as dichotomania, the compulsion to replace quantities with
dichotomies, black-and-white thinking, even when such dichotomization unnecessary
and even misleading for inference. A good example of dichotomania is
found in how we respond to predictive probabilities. In 2016, many people were surprised
that Republican Donald Trump won the US presidential election. Indeed, Donald Trump was a clear
underdog heading into that election. The most reliable model produced by
the political website FiveThirtyEight, only gave Trump a 28% chance of
winning heading into the election. While I like sharing
predicted probabilities, dichotomania can be a problem,
as was the case in 2016. People tend to take these probabilities
and arrange them to a decision point. The US public tended to round down that
28% probability of Trump winning to essentially zero, thinking that the models were saying
that Trump would definitely lose. The cognitive bias at play
here is that we tend to equate unlikely events
with impossible events. And actually, in this case, 28% is not
that unlikely as we will soon see. A more precise way to help
build an intuition around a predicted probability is something
called a risk characterization theater. To illustrate this,
let's compare two election predictions. We've already mentioned FiveThirtyEight's
prediction that Trump had a 28% chance of winning heading into election. We'll contrast that with
the New York Times Upshot poll, which estimated Trump's likelihood
of success at only 15%. The idea of risk characterization theater
is that you have purchased a ticket and get assigned a random seat in a theater or
as in the example on screen, you're purchasing
a random seat on a plane. Now if you end up on a colored seat,
Trump wins the election, if you end up in a white seat,
Trump does not win the election. These maps give a stronger visual
representation of the underlying probabilities than
the probabilities themselves. You can see that you'd be far less
surprised to sit in a red seat in FiveThirtyEight's plane than
the New York Times plane. This provides a nice intuitive display of
the differences between a 28% probability of winning and
a 15% probability of winning. Certainly, views like these
are preferred to a simple translation of winning or
losing a dichotomization of the data. We find these types of views increasingly
in the world of uncertainty communication. Note that we're not mapping a probability
on a continuous encoding like position or area, we're mapping probabilities onto
these special frequencies using count statistics. They're particularly popular when we
work with a dichotomized outcome. Now, in the case on the screen, we're
comparing medical risk associated with two types of a heart procedure, a Balloon
Angioplasty, and a Bypass Surgery. These visualizations,
sometimes called an icon array, help convey the overall risk
associated with each procedure. Essentially, this is a visualization
of the success rate for two competing medical procedures. And in case we think dichotomization
is just a problem with consumers of statistics and not they're creators,
Andrew Gelman notes that often, the continuous outcomes of experiments
are translated into simple binaries, the results are either significant or not. He says this, one of the big themes of
statistics is that we should be more comfortable admitting what we don't know,
and one of the big problems with
many statistical methods as they are applied in practice is that they're
taken as a way of denying uncertainty. For example, you conduct an experiment,
analyze your data, and conclude the results are statistically
significant, or not. The implied and
often explicitly stated conclusion is that the effect is real, or it is not. So Gelman is just saying and again, that dichotomization impacts
even how we create statistics. This introduction has been meant
to reinforce two main lessons. Number one,
people are good at ignoring uncertainty, especially if we provide
ineffective representations of it. One form of that is dichotomania, but
there are many others like deterministic control errors which we'll
discuss in other lectures. The kinds of views we have examined thus
far in this deck to help communicate the uncertainty more effectively are
called discrete outcome visualizations or sometimes called frequency framings. The question we should consider is, how to apply these discrete
techniques to continuous data? To answer this question, we're going to
return to the paper that Kay and others wrote, When (ish) is My Bus. Again, the paper explores methods for presenting uncertainty using
a transportation example. Suppose once again,
you're living in Seattle, Washington in the United States, the bus
company displays on a digital board, the approximate time the bus
will arrive at each stop. So for example, it notes that bus 120 should be at
the Downtown Center in 11 minutes. But remember, there is uncertainty. So recall that the bus is
arriving in about 11 minutes. We might want a predictive distribution
shown here as a density plot, that provides a high level picture of
the distribution of bus arrival times. We can use the density plot to create
a one sided prediction interval that gives us a 90% chance of catching the bus if
we arrive in the next eight minutes. And we've already talked
about in other lectures, we're not very good at area perception. So just relying on a density
plot may not be a great idea. So one of the things we talked
about before was using a CDF. A CDF has the advantage of explicitly
mapping the probability and not probability density, so we don't need to read areas to
determine a probability value. But what we'd like to do is use a discrete
outcome type of visualization here, rather than a continuous visualization. Well, the nice thing here is we can use
this cumulative distribution function to actually construct a discrete
analog to the density plot, that allows me to read off probabilities
using frequency of elements. How can we do this? So what we're going to do is we're
going to take a range of probabilities, and we're going to map that back
onto my probability density function using something
called the inverse CDF. Then we're going to stack up
all of these observations or potential outcomes into something
called a quantile dot plot. This is just a dot plot of quantiles
from this predictive distribution. The nice thing is when we do this,
interval estimation now reduces down to a simple counting procedure that one
would hope is intuitive in the same way icon arrays are an intuitive encoding
of probability using frequencies. So for example, if I show up at
the bus eight minutes from now and I miss two of the 20 of these hypothetical
buses, that means I catch 18 of the 20 hypothetical buses, that corresponds
directly to an 18 out of 20 chance or a 90% chance that the bus comes
after me and I catch the bus. The other interesting thing here is we've
chosen a relatively low denominator for these dot points, and there are only
20 dots in this particular dot plot. If all the intervals that I tend to want
to estimate for this particular task or in the tales of the distribution
which they probably are, because most of the time you actually
want to catch the bus, right? So you probably want like an 80 to
95% chance of catching the bus. Then it's actually really easy for me to estimate those intervals because
I don't have to count every single dot. I can use something called subitizing, to
quickly and accurately estimate the number of elements in a small collection without
having to explicitly count all of them. So even if you're not familiar
with the term subitizing, at some point in your life you've probably
used it, for example, in rolling a die. Here are the faces of a die. Now you'll notice they don't have
any numbers on the faces, but it's still really easy for us to
instantly recognize the number of dots without having to explicitly count them. This rapid cognition of number
value is called subitizing. And it's something we can exploit when
we're making discrete outcome encodings. Now, a question we should consider is,
does this work? Do discrete outcome encodings work better
than continuous uncertainty encodings? Once again, we return to the research
of Matthew Kay and his colleagues. Kay and
team looked at an important question, do better perceptual representations of
uncertainty lead to better decisions? because that's ultimately
what we're after, right? If we're going to put all this time and
effort in creating these representations of uncertainty, do they actually
lead to better decision making? To answer this question, Kay and team ran an experiment where they gave
their users both a density plot and dot plot representation of uncertainty
of the bus arrival times, and asked them to make a decision about when they would
leave to catch a bus to go to a meeting. To incentivize good decision making, the
researchers gave a little bit of money for every minute people were staying at home,
and took away a little bit of money for every minute that they were
hanging out at the bus station. And they also rewarded those subjects
who made it to the meeting on time, they caught the bus. What they found was that the subjects in
the study made better decisions initially, actually about 90% of optimal,
with the dot plot, and actually those, that subset of of users
got better over time. This was not the case
with the density plot. This makes sense because we know
it's hard to read area accurately to get a probability from a density plot. So that's it for discrete outcome
encodings for this lecture. But before we finish,
I want to make one final comment, we've learned about continuous and
discrete outcome encodings. We've contrasted their strengths and
weaknesses of each, but I don't mean to suggest you always
have to pick one over the other. Another strategy is to use various
uncertainty encodings together. Doing so can make the uncertainty more
difficult to ignore, which is again, one way we evaluate the effectiveness
of a uncertainty representation. We can combine continuous uncertainty and discrete outcome visualizations in
ways that accentuate the uncertainty. For example, in the graphs on screen, we
take a very common continuous uncertainty encoding, the confidence interval, and
we combine it with other continuous and discrete encodings that might be
less familiar to the audience. This should make it more difficult
to simply ignore the uncertainty. But again, the downside of
this approach is that it can add complexity to
the overall visualization. So let's sum up. Discrete outcome encodings are a class
of uncertainty encoding that maps the uncertainty to
a discrete number of icons. Discrete outcome encodings have
the potential to improve inferences users make from uncertain encodings,
as we saw in the Kay research. If we use a small number of marks,
icons or dots, the visualizations can be read without
counting, which we call subitizing. That's it for this lecture,
we'll see in the next one.