Welcome back. This is predictive and confidence intervals
in regression. One of my favorite lectures.
Let's get started. Confidence interval is not
a new idea at this point. We've discussed confidence
intervals around a point and actually
spent quite a bit of time to talk about how to interpret a confidence
interval in this context. In this lecture, we'll look at confidence intervals
for regression models, as well as discuss
the construction of uncertainty in a
predictive context. That is, how do we make a predictive interval
around the regression line? On screen is what we'll
be building toward. This is the data we'll
be working with, and you can see the
scatter plot of the data. There's a regression line
and then the orange band, there's the confidence interval around the regression line, and then we have a
predictive interval also associate with
the regression line. What are the differences,
how do we make those? That's the subject
of the lecture. We're going to work with
the fictitious dataset dealing with the
game of basketball. Suppose we collect
data from the NBA, the National Basketball
Association, which is the premier basketball league in the United States. The data we track is how
much the home team is winning or losing at half-time. Then how much the
home team has won or lost by at the
end of the game. For example, if we have
a data point, -8,-6, this would mean the home team was losing by eight points at halftime and ended up losing
the game by six points. A scatter plot of our
data set looks like this. On the x-axis is the number
of points the home team is up or down at halftime. On the y-axis is a result of the game for the perspective
of the home team, how many points did
they win or lose by. The scatter plot reveals a generally positive
correlation between how the home team
is performing at half-time and end
result of the game, put differently, a large
lead or deficit at halftime typically
yields a similar result at the conclusion of the game. If we want to quantify
this relationship, we build a regression model
to generalize the trend. In this case, we're using the point differential
before halftime to predict or explain the
point differential at the conclusion of the game. Now the general form of
this equation is 天 equals Beta_1* X_1 plus Beta naught. In this case, X_1 equals the point differential
at halftime, and 天 equals the win
point differential. Again, all from the
perspective of the home team. Let's use some
statistical software to estimate these parameters. Let's assume we actually fit this simple linear regression. Using software like Python, R, maybe even Microsoft Excel, we can find the coefficients for our linear model to
describe this relationship. Let's say the
coefficient of x is 0.86 and the y-intercept
for the equation is zero. Which means that when
the halftime lead of the home team is zero, the estimate for the win
differential is also zero. Now, we can also consider the interpretation
of x coefficient, 0.86. What does this mean? Well, it means for each additional point
in half-time lead, the end score differential
increases by 0.86. Leads in deficits
created at halftime tend to shrink by the
end of the game, which probably matches
our intuition. If you have a large
lead at halftime, you may take it a
little easier in the second half and know
you're still going to win. Likewise, if you're in a
large deficit at halftime, the other team may take a little easier knowing that they're
probably going to win. Let's say the coach
of the home team is working on a game strategy. The coach wants to know
how we think the game will end if there's a
10-point lead at halftime. Let's use our regression model
to estimate this quantity. We can use the graph to
explore this equation. We know there's a 10-point
halftime leads, so x=10. We can draw a line up from 10 to intercept the
line of best-fit. That's our regression line. We then look to see the corresponding y-axis
value associated with x=10, we find that 天 is estimated
to be 8.6 points. That is a 10-point
lead at halftime for the home team should yield an end game differential
of 8.6 points. That is victory by 8.6 points. Now we could also just use our regression model and plug in 10 for x and get 8.6 for 天. The value 8.6 points is
a statistical estimate. We use the data and the
model to estimate it. Because it is a
statistical estimate, we know there is
some uncertainty. We need to consider how to
represent that uncertainty. How we model this
uncertainty depends on the inference associated
with our estimate. There's two ways to
think about this. Are we estimating the mean
final win differential for all teams that have a
10-point lead at halftime? Or are we predicting the
final when differential for a single team with a
10-point lead at halftime? If we're estimating the
mean final win differential for all teams that have a
10-point lead at halftime, we're estimating a
parameter, the mean. Thus, this is
parametric uncertainty. If we're predicting the
final win differential for a single team with a 10
point lead at halftime, then we have predictive
uncertainty. Another way to say this is, are we estimating the mean
value for y given an x value? If so, this is
parametric uncertainty. Are we estimating the
next unknown single point of y given x? Well, then it's
predictive uncertainty. In scenario 1, where inferences for the
mean final win differential, we would just use a
confidence interval to represent the uncertainty, just like we did for
the other parameters we have discussed
in this course. If we're predicting the
final win differential for a single game, then this prediction is for
the next unknown data point. To express the uncertainty
around a prediction, we need a predictive interval. Depending on our inferences, mean values versus
single values, the uncertainty
expression will either be a competence interval or
a predictive interval. Well, the calculation
of uncertainty differs for option
1 and option 2, the point estimate is identical. Whether we're estimating
the mean value for all teams with a
single 10 point lead, or estimating the
final win differential for a single team with a
10 point lead at halftime, the point estimate is 8.6. In summary, the point estimates for these two
scenarios are the same. The uncertainty around
their inferences is different as
we're about to see. Let's start by
unpacking the math for the confidence interval for a
regression line scenario 1. On screen, we have a formula. It looks far more complicated
and really what it is. Let's take it term by term and to find really
what's going on here. First, we have our
regression estimate y-hat. In the context of our problem, this is the win differential
at the end of the game for all teams given some value of x. This is a point
estimate around which we want to build the
confidence interval. After the addition
subtraction operator is the confidence interval term. These sets of values
help us define the width of the confidence interval
around our point estimate. The first term is the
critical value for our confidence interval taken
from the t distribution. As you may recall, our critical value
varies depending on the size of the
confidence interval we want, 66%, 90%, 95%, maybe some other value. It also varies on the number
of degrees of freedom. The generic form for the
degrees of freedom is n-k-1. N is the number of
observations in the data, and k is the number of
variables in the model. S sub y is the standard
deviation of the residuals, which we can easily get
from the regression output. Notice, we're taking
each observation of y and subtracting
our estimate of y. That's the basic
idea of a residual. The rest of the calculation is the standardization
of the residuals. The last term there's
a lot going on in it. We have 1 over n, which is one over the sample
size of our data. X star is the x value for which we're estimating
the confidence interval. In our case, it was a halftime
score differential of 10. X-bar is the mean of the x's. This value is divided by the product of the
sample size minus 1 times the standard deviation of the explanatory
variable. That's it. That's all there is to the
confidence interval formula. Let's take a look at
what it produces. Suppose we pulled from
our stats package the degrees of freedom, the
standardized residuals, etc and we use that to calculate the confidence interval
around our estimate of 8.6. We can plot the estimate and the confidence interval that
surrounds it on our graph. This is the confidence
interval for a single point. To plot the confidence interval
for the regression line, we could repeat this process, producing a point
estimate and then calculating the confidence
interval around each one. If we continue the process, we build the full
confidence interval around the regression model. It's a continuous uncertainty
visualization that expresses uncertainty
through the full range of x. You may notice
something curious. The regression models confidence
interval gets narrower towards the centroid or center
of the regression line. Now, why is this? Is it because there's more
data in the center of the regression so we're more certain in the
middle of regression? Actually, not. The explanation is found within the
formula itself. On screen, we have
the formula for the confidence interval for a simple linear
regression model. The numerator inside the radical is the key
to understanding why the confidence interval increases the farther away from the center of the data are. Let's take a look at a few values to
illustrate this point. The formula for the confidence interval is in the upper right. Again, for these data, let's assume the
mean of x is zero. If we're calculating an
error term at the mean, the term x star
minus x-bar is 0-0. So that entire term cancels out. This means that error
term is essentially the square root of 1
over n, the sample size. Let's contrast this
with the value that's far from the mean. Let's say we want
to evaluate x=25, meaning a 25 point
lead at halftime. Now, X star minus X bar
is 25 minus zero or 25. This adds width to the
uncertainty calculation. Because rather than that
whole x star minus x bar term turning to zero as it did
at the center of the data, now it's 25 and increases
the size of uncertainty, which makes the band wider. We can also note that
the regression lines always go through the mean
of X and the mean of Y. Sometimes we call this
point the centroid. This also provides
some intuition as to why the
confidence interval, being an expression of
the regression models parametric uncertainty would
be narrower near the mean. If the regression line must
pass through the centroid, then there is more certainty
in that region of the graph. The interpretation of
the confidence interval in this context is similar to what we've discussed with the confidence interval
of a point estimate. If we repeat the
statistical process of sampling in building 95%
confidence intervals, then 95% of those confidence
intervals will contain the true population parameter or the true regression line. Of course, this is not to suggest that we're 95% confident that this individual
confidence interval contains the true
population parameters. However, we can say that the
confidence interval we have represents a reasonable range for the true regression line. We explore the competence
interval as our expression of uncertainty when
estimating a mean value. In the remainder of the lecture, we'll look at the
predictive uncertainty associated with predicting
a single value. Here's the basic formula
for a confidence interval, we've already covered this. Let's contrast this formula with the formula for a
predictive interval. The predictive
interval formula is very similar to the
confidence interval formula. It begins with a
point estimate y hat. We have the same plus
or minus operator and a critical t value and a
standard deviation of residual. The error term is even
identical with one exception. We add in one into
the error term. Adding one to the error
term ensures that the predictive
interval is always bigger than the
confidence interval. Here we have a picture of a predictive interval
for our data, and there's a few
things to notice. First of all, it's wider. This is due to the one
added into the error term. It keeps the predictive
interval from minimizing as much
at the center. Now, it's harder to see but the predictive intervals
do vary in width, just not as much as the
confidence interval. Let's discuss the
interpretation of a predictive interval with a certain level of confidence, let's say 95% again. If we repeat the
study of obtaining a regression dataset many times, each time forming a 95%
confidence interval at x and wait to see what the
future value of y is at x, then roughly 95% of the
prediction intervals will contain the corresponding
actual value of x. Again, I admit this
interpretation is clunky but is consistent with the frequentist
traditional statistics. Again, my shortcut and
the situation is the same as what we've described with
the confidence intervals. This 95% predictive
interval represents a reasonable range
for future values. Finally, I want to summarize when you use a
confidence interval and regression and when you
use a predictive interval. For parametric uncertainty, and making inferences
about the uncertainty in the overall relationship
between y and x, in other words, how
certain am I in the model, you would use a
confidence interval. For predictive
uncertainty and making inferences about
the uncertainty in a single new data point, a prediction, how certain
am I in that prediction, you would use a
predictive interval. In conclusion, let's return to the view of the
confidence interval and predictive interval together with the underlying
regression model. The confidence interval
is our confidence in the mean value of y given x for our competence
in the model. The predictive interval
is our confidence in an individual prediction
of y given x. The point estimates are the same in both of these scenarios. But what differs is our
confidence in the estimates. One is parametric, confidence in the mean, the other is predictive, confidence in a prediction. Both the CI and PI narrow
towards the middle, but much more so with the CI. This is because of
how we construct the error term for a
confidence interval. We choose the predictive
interval when we are estimating the uncertainty
in the next data point, we choose the confidence
interval when we are estimating the uncertainty
in the regression line. That's it for this overview of confidence intervals and
predictive intervals in regression. I
hope you enjoyed it.