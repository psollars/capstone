Welcome to presenting
uncertainty. I'm your instructor,
Nick Shawl Tran. Now, anytime I teach a course, I like to start with why
you should take the course. In this first lecture, I want to discuss with you why you should study uncertainty. Uncertainty is fundamental to the field of data
science and statistics, and in this lecture,
we'll explore what it is, where it is, and what
you can do about it. Let's begin. Let's start by defining what we
mean by uncertainty. The best source I know to
learn about the meaning of English words is the
Oxford English Dictionary, which you can actually access through University of
Michigan's library. OED offers five definitions
for uncertainty. But here's the first. Now as I look at it, it's the second half of
the definition, I think is particularly
instructive for our purposes. It reads also the
quality of being indeterminate as to the
magnitude or value, the amount of variation in a numerical result that is
consistent with observation. Let's translate that into
more accessible terms. Uncertainty, statistically
speaking, is when we're unsure about a value
that we're interested in. That happens all the time. This value is often estimated
through statistics, but with uncertainty as to what the true value actually is. Let's look an example
of how this works. Now imagine the MADS program
seeks to understand how much programming experience
math students have prior to the program. Now you can see how this
could be helpful for the program in terms of
planning it's instruction. What this means is that
we're interested in a population parameter Mu, which represents
the mean here's of programming experience
for the population of interest, math students. Now if you don't happen
to know terms like population parameter
Mu, things like that. We'll define all of that in the next lecture on
statistics of uncertainty. For now, just hang
with the example. We can't know Mu or the population mean directly
because let's assume we can't get responses from all
math students present and future about their prior
programming experience. Instead, we're going to use a common technique
in statistics. We're going to sample
the population. In this case, let's
say I can only get a sample of three students. I ask three students, how many years of Python
programming experience did they have prior
to joining math? The values for this
sample are zero, two, and three years. The mean of the sample is 1.7. We represent the
sample mean as x bar. X-bar is our sample
statistic that is meant to estimate the
population parameter Mu, which we can't know directly. Now as you're probably
thinking a sample three, that's not very large. How confident are we that the sample statistic is close to the
population parameter? That is a question
of uncertainty. The statistics of
uncertainty is about our effort to quantify that uneasy feeling
you have about how confident we are in
our sample statistics. Anytime we share statistics
insights inferences, we're estimating. If we could know with
absolute certainty, we really wouldn't
need statistics. Uncertainty is
fundamentally involved everything we do and
everything we communicate, which is why it's
important to study. Now, in the case
I just described, we were discussing the error
in an estimate of a mean, which is a parameter
we're interested in. But uncertainty is common in almost every part
of data science. I'm going to talk a
little bit about three examples that are very common, all of which we'll actually
tackle in this course. The first one which
we've already discussed, is estimating parameters. That's what we did
for our example, finding the sample mean. We also can estimate
parameters like beta weights through
building models. Those all have a form of uncertainty
associated with them. The next one that
you may be even more familiar with is
uncertainty in prediction. Certainly predictive
analytics is a big part of data science
and it can take many forms. As pictured, we're showing uncertainty in
forecasting outcomes. Really this predictive
uncertainties around our uncertainty around new data and what we can know about it, and really what we can't
know about new data. It's the uncertainty that's fundamental to much of the
data that we work with. The last area of uncertainty is the uncertainty that comes from all the design choices we make when we work with data. This is my favorite uncertainty, as I probably say several times in this lecture
and in this course. It's a focus of the latter
part of the course. Those were a few
examples of where uncertainty manifests
itself in data science. Just to further
illustrate the point that this is a really important
topic for you to study, I love this quote
by Claus Wilke, who notes that uncertainty
is everywhere. He says, "Nearly every dataset we work with
has some uncertainty, and whether and how we choose to represent this
uncertainty can make a major difference
in how accurately our audience perceives
the meaning of the data." I love that quote
because it's very action-oriented and
it's very applied. This is an applied program, and as Claus is telling us here, if we choose to ignore uncertainty or
we represent it poorly, we might hurt the
decision-making process, so we need to take
this topic seriously, which is why we have a
course for you to study. If we know uncertainty
is important, and if we know it's everywhere, then how should we approach tackling this
thing of uncertainty? We have to define uncertainty, we have to describe it. I'm going to talk about three high-level ways we can approach uncertainty to illustrate
the approaches we can take. Consider a teenager who lets her parents know what
time she'll be home. At the time of this filming, I actually have two
teenage daughters. So this example, all
too real for me. In the first example, what I call ignoring
uncertainty, the teenager says she'll
be home at 11 O'clock. This provides a point estimate, 11 O'clock with no expression or consideration of uncertainty. On its face, when you
receive the information it says that she'll be home
precisely at 11 O'clock. Ignoring uncertainty is a surprisingly common
practice in data science. This is true because
data scientists are not always seriously
trained in uncertainty, how to calculate it,
how to communicate it. But also because
sometimes those we share data with, the audience, the recipients of our work don't always appreciate conversations
about uncertainty. It reminds me of a
story that I read once about a US President
named Lyndon B Johnson, who was president in the 1960s. The story might not be true, but this is what I read in a book that I'd like
to share with you. A perhaps apocryphal story
about Lyndon Johnson illustrates the
pressure economists can feel to draw
strong conclusions. The tale has an
economist describing the uncertainty of
his forecast to LBJ, that's what people
called Johnson, in offering a range
of values rather than an unsupported precision. Ranges are for cattle, Johnson is said to have
replied, "Give me a number." The reason why that resonates is that Johnson was from
the State of Texas, and Texas is known for
having lots of cattle, and he was a plain talker and very direct individual
was his reputation. You can see how this could have happened even
if the story isn't true. But the story
whether true or not, resonates with my
experience sometimes in sharing data science insights that include
uncertainty estimates. People don't always
appreciate the uncertainty, they confuse that with the model's wrong or you don't
know what's happening. And they much prefer just point estimates
with false precision. I think this is in part due to the expectations that are
associated with math. Math is fundamental to what we do in data science
as our statistics. It seems like math should produce the answer,
a single answer. As US comedian, Chris Rock once said, there's math and everything
else has an opinion. In the second example,
I want to share, the teenager is a little more
nuanced in what she shares. She implies uncertainty,
which is what I call the second overall strategy,
implying uncertainty. She implies it by
saying she'll be home around 11 O'clock. It gives the audience
the sense that while 11 O'clock is the best estimate, we wouldn't be surprised
if the teenager came a little earlier or
a little later than that. But the problem here is we
still don't have a solid sense of how good of an
estimate 11 O'clock is. Does a round mean that
she'll be home at 10 O'clock or as
late as 12 O'clock? We just don't know.
The last approach and the one that you'll learn in this course is to express
uncertainty directly. In this scenario, the
teenager says that she'll be home anywhere between, let's say 10:45 and 11:15. This range of time gives the
audience, or in this case, her parents, a sense of the possible times that
she might be home. In the middle of the
range is 11 O'clock, which might be the most likely
estimate of arrival time. But we wouldn't be surprised
if the teenager arrived anywhere from 15 minutes before
that to 15 minutes later. What does this look like? All this uncertainty stuff in actual practice of
statistics and data science. Here's a table from
an article that considers some of the issues we'll examined in this course. At the left we have traditional statistical
data science table. It offers coefficients of a regression model
examining the relationship between individual
authoritarianism and the economic perceptions, ideology, and
demographic variables in six Latin American countries. Now if that doesn't
make a lot of sense to you, not a big deal. The details of this are not what I'm really
trying to highlight. It's how we're
expressing uncertainty. Traditionally speaking,
we really focus in and share a point estimate
and then maybe next to it, the standard error,
if we're lucky, the standard error is a statistic that actually
quantifies the amount of certainty associated with the point estimate
will define again all these terms later in
this course but for now, the representation is what I really want you
to focus in on. That's traditionally how
this is done and it's done in a table and it's fine, but it definitely is not
front and center in terms of how the user reads and
interprets the data. Let's look at an alternative. The figure on the
right in the red box is a visualization of a regression coefficient
surrounded by an expression of uncertainty,
a confidence interval. The graph easily reveals that the coefficients vary in
magnitude and certainty. Hopefully you can see
by looking at this, that's a more robust way to share uncertainty than just maybe putting numbers in tables. It helps calf the
uncertainty along with the magnitude of
the point estimates together in one visualization. Even so I think it's
important to note that while this views
in improvement, maybe on the table that we're sharing and how it
represents uncertainty, it still has some
significant limitations. Researchers and uncertainty
visualization focus on really two fundamental errors in uncertainty visualizations. One is how we read uncertainty for something
that is deterministic. That's called the
deterministic construal error. A class we'll get to
later in the course. The second is how easily it is for us to ignore uncertainty individualization both of these will be discussed in future
lectures but in this view, you can see how easy it
is to ignore uncertainty. The users can focus in
on the point estimates, which I have in red boxes here, rather than considering the uncertainty
that surrounds it. By virtue of just having
that dot in the middle, often we find is that
people focus in on the dot and ignore the
confidence interval around that. What strategies
can we use to work around that limitation
in human perception? We'll talk about that
again in the course. Let's discuss how
we're going to develop you as a communicator
of uncertainty. We have three fundamental
goals in this course. The first is to learn the
statistics of uncertainty. I call this the
statistical fundamentals. We're going to cover the
concepts that you have to learn in order to
mathematically calculate uncertainty and we'll do that
in some level of detail. The second course
goal is to learn the communication fundamentals for presenting uncertainty. Visual communication
strategies include some techniques we can employ
to express uncertainty. Some you may have heard of
already or even use like confidence intervals others may be new to you, like
spaghetti plots. The third major course goal is in the writing of uncertainty. We want to practice the
writing fundamentals for describing uncertainty
in statistical results. Clear writing is clear
thinking and so we're going to practice how we write about uncertainty because it's
useful to practice, but also because it's one
of the best ways you can demonstrate your understanding
of the course concepts. Wrapping up this first lecture, I just want to note again,
uncertainty is everywhere. We see it in our data, our statistical outputs, our modeling choices, in papers, books,
even statistical cartoons like this
one from XKCD. Uncertainty is fundamental
to statistics. Learning about it is a wise
investment of your time. In review, anytime we cannot
be certain, by definition, we have uncertainty because statistics is all
about estimation. Uncertainty is fundamental to everything we do in statistics. Surprisingly, though,
uncertainty is underrepresented in the field
of statistical education. This class is a four-week
crash course on the fundamentals of
statistical uncertainties and I really hope you enjoy it.