Okay, so now we're going to
move on to the next topic, which is different ways of randomization. We're going to talk about two
specific randomization techniques. One is called blocking,
the other one is called clustering. They're both very useful, and we're going to use some examples
to show how to use these. So the two types of randomization that
we often see, in addition to simple randomization, and complete randomization
that we mentioned in week one is blocking. Sometimes we call it stratifying, you probably hear that term
actually more often than blocking. And so
what you want to remember is blocking or stratifying increases power,
whereas clustering can decrease power. And we're going to show
why that's the case. So let's first go through blocking,
with some sometimes say block random assignment or
stratified random assignment. So this is essentially a procedure whereby
subjects are partitioned into subgroups, they are sometimes called blocks or
strata. And then you go into each subgroup and you use complete random
assignment within each subgroup. So when do you want to do that? Let's take a look at one example. So this is a very simple example. Suppose we have 20 subjects in our
experiment, we have 10 men and 10 women. And our experiment design calls for 10 subjects to be placed into
the treatment condition. So you could use complete random
assignment or simple random assignment. In that case, you cannot guarantee
that there are exactly the same number of men and women in the treatment and
the control conditions. But block random assignment
will enable you to do that. So what does block random assignment do? Now you have 10 men, and so
within the block of 10 men, you randomly assigned half of
them into the treatment, and half of them into the control condition. So that gives you five
men in each condition. Then you go into the block of women,
again, you randomly assigned half of them into the control condition and
half into the treatment condition. So if you do block random assignment or
stratified random assignment, that guarantees that the number of men and women will be equal in each
experimental equation. So that's how operationally, we do that. What about some advantages of blocking? Some of them are obvious. For instance, sometimes there
are administrative requirements which says that, the treatment
condition has to have a certain proportion of each type of subjects. It could be gender, or
it could be ethnic groups. Blocking would make sure if
the requirement is gender, that you have to have 50/50. Blocking on gender will
enable you to ensure that there are 50% men 50% women
in the treatment group. If it's blocking or ethnicity or race, if the requirement is that you
have to have a certain proportion of each race in the treatment,
blocking will also guarantee that. In that case, you want to block on
the race and then within each race you assign the required proportion
to the treatment condition. What if you do a complete
random assignment? If you go back,
sometimes if there's a minority group, when you do complete a random assignment, sometimes it can easily happen that
you don't get any observations. You don't have any minority members
assigned to the treatment condition. So it also helps with what's
called a subgroup analysis. Sometimes we also call
heterogeneous treatment effects. So we can block on the subgroup,
so the subgroup again, can be demographic groups such as race or
gender. If you block you can make sure that you
actually have the desired subgroups, in your treatment. And the last point is less
obvious at this point, and we're going to use a numerical
example to illustrate this. Which is that if you block on
prognostic variables, that can improve the precision with which the average
treatment effect is estimated. So statistically,
this is a preferred practice because it reduces essentially,
the standard error of the estimate. All right, so
now we're going to use an example, okay? So this is a cooked-up example. So let's say the tables gives us
the schedule for potential outcomes for public works projects when they're
audited, versus when they're not audited. So recall that in the first week,
we defined potential outcomes. So that's the ideal framework
where you can observe each unit, both under the treatment and
the control condition. So Y0 denotes the outcome under
the control condition, and Y1 denotes the outcome under
the treatment condition. So, in this case, the treatment is
heightened financial oversight by government officials,
let's say maybe more frequent auditing. And the outcomes will be the amount
of money that's unaccounted for, and let's say, in this case,
it's stolen by the bureaucrats. And we have two regions,
in this case, region A and region B. Let's say because of resource constraints, each region has the capacity to
audit only two of its projects. So now let's look at the first
two columns which is all subjects, and
next we see block A subjects, the last two columns is block B subjects. What you see here is just by
eyeballing this data table, you realize that the outcome,
which is the amount of money stolen, on average is a lot higher in
block B compared to block A. So block A subjects are a lot
more similar to each other, so there's a lot of
within-block similarity, where as block B subjects are also
a lot more similar to each other. But there's a fair amount of difference
between block A and block B subjects. So the bottom of this
table calculates the mean, of the outcome variable, and the variance, as well as the covariance. What you see here is that, for
instance, the mean when you have all the subjects here is 9.14,
if they're not in the control condition, when there isn't heightened
financial oversight. And Y1, is when there is
heightened financial oversight. So it's 9 and 5,
whereas block A is respectively 4 and 1. And block B is 16, it generates 16 and 11, so there's a lot within-block similarity. Now if we calculate the average
treatment effect, for region A,
the treatment is going to be essentially, what is the mean under the treatment
minus the mean under the control? So for Region A is going to be 1 minus 4,
that's minus 3, for region B is minus 5. If you have both regions combined,
you're going to weigh the mean by the proportion of subjects in
each experimental condition. So there are 14 subjects in total,
8 in region A and 6 in region B. So you weigh the average treatment
effecting each region by its proportion. So you get -3.86. So this is the first point,
which is, when you have blocks, you can calculate the overall
average treatment effect as a function of the within block
average treatment effect. Which is essentially the sum
of the weighted average treatment effect within each block, okay. So this is how you calculate the average
treatment effect when you have block random assignment. And this part talks about
the standard errors. How do you calculate the standard
error under blocking. So the first part is if you have complete
random assignment without blocking. Then the standard error of the average
treatment effect is going to be 3.50. Under block random assignment, what we are
going to do is to calculate the standard error within each block, which we
have done in the previous table, and then weigh it by the block level, the
number of observations within each block. So we have NA over N,
which is the proportion of treatment subjects in block A, squared. And then the standard error in
block B is weighed similarly. That would produce the standard error for
the average treatment effect, the estimated average treatment effect,
to be 1.36 in this example. And compared to the complete random
assignment, this is much smaller. So this is what we mean by
blocking reduces the variance, or the noise in the estimation,
and increases precision. So statistically, blocking is desirable. So here are some of the,
I'm going to summarize the advantages and also what to watch for
when you do block random assignment or stratified random assignment. First of all,
when we make the design change, we improve the precision with which we
estimate the average treatment effect. In the previous numeric example, the
standard error plummets from 3.5 to 1.36. However, you have to be very careful. Which is,
a common error is to ignore blocking. When you calculate
the average treatment effect, you went back as if it is
a complete random assignment. If it is a block random assignment,
you have to weigh the average treatment effect by the proportion
of subjects within each block. So remember, after block random
assignment, don't forget to compute the average treatment effect and
also the standard error accordingly. Okay, so this is something that's
potentially a downside for blocking. But if you are careful as an analyst, you
just remember that you need to calculate the average treatment effect and
its standards errors accordingly. The next one is clustered
random assignment. Remember clustered random assignment is,
when all subjects in the same cluster are placed as
a group either into the treatment or the control condition,
and it decreases power. This should not be done
unless you have to. Most of the times, experimenters use cluster random
assignment because they have to. So we're going to use a couple of
examples to illustrate that point. So you should remember as an experimenter
that clustered assignment is oftentimes a compromise, because assignment at a lower level is
not possible or causes problems. So we're going to use
the Uber tipping experiment that we talked about in week two. In week two, we used this experiment to
illustrate the idea of a phase-in design. This experiment has a lot
of interesting features. The other interesting feature is,
of course, they use clustered random assignment. They also use blocking. So after we cover block random
assignment and clustering, we're going to revisit this experiment. Okay, remember prior
to the summer of 2017, Uber does not have in-app tipping,
whereas Lyft did. And so in their PR campaign, which is dubbed 180 Days of Change,
they enabled in-app tipping. The company, they naturally wanted to see,
what's the effect of that? And the reliable way of doing that is
actually to run it as an experiment, which is to enable treatment and
control groups. So the way they did it was essential
to start the tipping feature, enable the tipping feature,
in half of its cities for ten days, and then phase in the other
half of the cities. So in these ten days, the early group
becomes the treatment group, right? And the later group
becomes the control group. So they're interested in a number of
outcomes that's not quite the point of mentioning the tipping experiment here. But let's take a look, sort of a deep
dive, into their experiment design. So at that point they
randomized the launch across 209 operating cities in the US and
Canada. So one can think of randomization
as either complete randomization at the driver level or
cluster randomization at the city level. What did they do? They actually clustered at the city level. So there are two features, two more features,
in addition to the phase-in design. The cluster random assignment says that
each city is clustered either into, as a cluster, is randomized into either
the treatment or the control condition. So one question is,
why didn't they randomize at the driver level instead
of the city level? Think about it, and it will be a good idea
to actually write down some notes, and then we'll discuss it. So the main reason that
they cluster is because if you randomize at the driver level, there will be potentially
a lot of spillover effects. So imagine I drive a Uber,
my neighbor also drive for Uber. And I saw this app,
this new feature on my app, which says that now you can accept tips. And I ran into my neighbor and
asked my neighbor, isn't that interesting? Now we can accept tips. And the neighbor is in the control group. The neighbor will be surprised and say, gee,
I didn't I don't have that on my phone. So that would cause contamination between
the treatment and the control group. And we'll talk about the problems
in the last week of this class. So because of this, primarily because
of a concern for the spin over effects, they made a compromise and
used clustered random assignment. The other part is they actually also used
blocking within the same experiment. So how do they do that? Here's how they used blocking. So a 110 cities were assigned to
treatment by matched pairs, so which means that they stratified on
whether a city has UberPOOL and UberEats. The cities with these two
features are in one block. The cities without are in another block. Then within each block, they form
matches by minimizing the Euclidean difference across normalize city size,
driver earnings demographics and so on, which essentially the match
pairs are as similar as possible. Once they do this, they will randomize each pair into
the treatment or the control group. Okay, so that's the blocking part. So then the remaining cities are randomly
assigned to treatment or control. So in the end, they have 105 control
cities and 104 treatment cities. So this example shows that within the same
experiment, you can use multiple features. You can use blocking,
you can use clustering and you can use a phase in design. Now we're going to take a look at another
scenario where clustering often happens, which is that is politically
infeasible to actually randomize at a lower level,
at the individual level. So this is an educational
education setting. So we have classrooms,
we have four schools, schools A, B, C and D, and
each school has three classrooms. And we denote it by A11,
A-2, A-3 and so on. And let's say that
the treatment is to have an additional teacher in the classroom. So in this case,
you can imagine that there are two levels, potentially two levels for randomization. One is at the classroom level. The other one is at the school level. What's the problem of randomizing
at the classroom level? It will give us more power because
then that will be more independent observations, right? The problem again could
be spill over effects or it could more likely you're going
to run into political feasibility. So imagine that A-1 has an additional
teacher, where as A-2 and A-3 are randomized into
the control condition. The parent's would know that somehow for
some reason, one of the classrooms has an additional
teacher, so they might complain. In that scenario, oftentimes in field
experiments in the education setting, they experiment to often
randomize the entire school as a cluster into the treatment or
the control condition. Again, we can look at classroom
level potential outcomes and the school level or
the cluster level potential outcomes. So in this case, the experiment can randomly assigned two
of the four schools into the treatments. How many possible random
assignments can you have? It's going to be four choose two, which is four factorial over two
factorial times two factorial. So, there's six different ways of randomly
choosing two out of four schools. Across all randomization,
this is something that you can calculate. You can compute the average
treatment effect as well as the standard deviation across
all possible randomization. But then,
we can look at the alternative scenario which is complete randomization at
the classroom level at the lower level. In this case,
there will be a lot more randomizations. So it's 12 classrooms in total and
you choose 6 out of 12. And so how many different
randomizations can you have is going to be 12 factorial over 6 factorial
times 6 factorial, which is 924. And then you compute the standard
errors across all of these different randomization. This is going to be 1.6, in this case. So clustering, in this case,
led to an 81% increase in the standard error, which means
that the standard error goes up. It's becoming a lot less precise. So that's the trade off. That's, for political feasibility, you're randomizing at a higher
level at the school level, and the resulting standard error
is going to be a lot larger. So what are the implications for estimation when you have
clustered random assignment? When you have clustered random assignment,
this affects the sampling distribution. And if you have clusters of unequal size, it presents a problem for
difference in means estimation. So this problem goes away as
the number of cluster increases.