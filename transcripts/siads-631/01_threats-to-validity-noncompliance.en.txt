Hi everyone. Welcome
to Lecture Four. So today we'll talk about
threats to validity, which is what can go wrong
in a field experiment, and method for data analysis called
instrumental variables. So we're going to
have three units. The first unit is the threats to validity where we'll
define noncompliance, different kinds of noncompliance when you run a field experiment. Then we'll talk about
the design and analysis, essentially to deal with
the noncompliance problem. We'll use the idea of instrumental variables to
deal with noncompliance. Lastly, we're going to use an example of a field
experiment where we encountered noncompliance and we used instrumental
variable regressions. So that's the eye at all paper. So let's go through the first topic which
is threats to validity and essentially all
sorts of things can go wrong when you
run an experiment. So for noncompliance, we
differentiate between one-sided versus
two-sided noncompliance. We might also have attrition or spillovers or
evaluation-driven effect. So lots of these effects
are very intuitive, and we're just going to go
through them one by one. Hopefully, when you design experiments and
analyze experiments, you'll remember these
threats to validity. So let's take a look at the noncompliance or
failure to treat issue. The one that's often
encountered by experimenters when you work in the field is one-sided
noncompliance, sometimes is called
the failure to treat. That occurs when some of
the subjects assigned to the treatment group do not actually receive the treatment. An old example is
when you send out, let's say fundraising letters, and these letters contain, some of them have the
treatment versions, some of them have
the control version inside the envelope. Your potential subjects receive the envelope and they
didn't even open it, so they just toss
it into the trash. Well then, they're not
treated because they did not read what you
intend them to read. The other type of noncompliance is called
two-sided noncompliance. This occurs when some subjects in the assigned treatment
group go untreated, and some subjects in the
assigned control group actually receive the treatment. So we'll go through
examples of both, but let's go ahead and define assigned versus
actual treatment. Sometimes it's also called intent to treat for
assigned treatment, and actual treatment
is called treated. So we're going to
use the same set of notations that we've always used. So we're going to let the experimental assignment of subject i be denoted as z_i. So z_i is an indicator variable. When z_i equals one, the subject is assigned
to the treatment group. When z_i equals 0 the subject is assigned
to a control group. So in the previous lectures, we say that d_i equals z_i. Remember, we use d_i to indicate treated versus
control subjects. So basically that assumes that all subjects assigned to the
treatment group are treated. In other words, when you
send out the letters, everybody actually open
the letter and read it. Also we assume that no subjects assigned to the control
group are treated. So the household that
receive your letter, who's assigned to the
control group actually just read the treatment letter. In other words, they don't wander into their neighbor's
house and say, "You received the same letter. Let me read you a letter." If the neighbor happen to
be in the treatment group then the subject in the control group
will be contaminated. So we assume that
whatever you assign them to they stay in that group. Now we add some reality
you to our set up. So now we're going to use
d_iz to represent whether subject i actually is treated when the treatment
assignment is z. So if a subject will be
treated if assigned to the treatment group then we say d_i as a function of z equals 1, which means that the subject is assigned to the
treatment group, and then we can simplify
that as d_i of 1 equals 1. So if a subject is assigned
to the treatment group, this subject is actually treated. So using this notation, we can also capture
the situation where a subject is assigned to the treatment group but
did not receive treatment. So in this case, we use d_i of 1 equals 0, or in other words, d_i of z equals 1, equals 0. So this is the case when
you send out a letter, a treatment letter and
the subject actually just tossed it into the trash. Or you send out an email and the subject actually
did not open the email. So that's the situation why a treatment subject actually
did not receive treatment. So that's our notation. So now we're going to define two types of subjects
which will be important in the understanding of the instrumental
variable unit. So we look at subjects in the experiment
with one-sided non-compliance, and we can divide them into
basically two latent groups. They're called compliers
and never-takers. So this is the case
when sometimes the subjects assigned to the treatment group actually
did not receive treatment. So who are compliers? Compliers meet two
conditions, that is, if they're assigned
to treatment group, they actually receive
the treatment. In other words, d_i of 1
assigned to treatment equals 1, and they do not receive the treatment if they are assigned to
the control group. In other words,
d_i of 0 equals 0. So these are your ideal subjects, they never actually deviates
to the other group. The never-takers are the
one who will never take the treatment regardless
of whether they're assigned to the treatment
group or the control group. So these are d_i of one equals 0. So if you assign them
to the treatment, they are not treated, and d_ i of 0 equals 0. If you assign them to the control group
they're not treated. So if you are thinking of the control group as the
people you don't touch, so when you send out letters, a subset of your subjects, a random subset of your subjects
do not receive letters. These are people who receive the letters
but don't read them, and if they are assigned
to the control group, by definition of your design, they don't read the letter, so they don't actually
receive the letter. So these are the two types. So a big question we
have is how would we estimate the average treatment
effect with noncompliance? The wrong approach
which actually is often seen in the published literature is you just ignore
the compliance issue. You compare the compliers
to the control condition. That is when the
treatment group consists of compliers and never-takers, what you have is you
observe the compliers, but you actually don't observe
the never-takers actions. So the wrong approach
is we ignore the fact that some people actually toss their letters or don't
open their emails, they're never treated
and we just look at those who are treated and compare them to
the control group, that would cause biased estimates for the average
treatment effects. So one way to fix this, we can think of that as the optimal design option
under low rates of compliance, is to deploy two versions
of the treatment, one with the active ingredient, and the other one that
functions merely as a placebo. When you look at those
who actually receive the treatment or the placebo, you can compare the treated
and the untreated compliers. So in the third part when
we talk about applications in the Ai et al paper
2016 experiment, we created a placebo group where everybody in the treatment and the placebo group
receive an email. So telling them that their
existence of lending teams, but the treatment
group also receive team recommendations which is the treatment in this experiment, whereas the placebo group
only receive the e-mail but do not receive information
or recommendation of teams. So that's one way of handling
the non-compliance issue, and we'll go into more detail when we move to the third unit. Now, I'm going to go
through a number of commonly observed issues with implementation of
field experiment, and the first type is
the spillover effects. So the spillover effect
is an indirect effect of a program on subjects who are not being treated
by the experiment. So for example, in the
previous lectures, we talked about the
level of randomization. We know that clustering
reduces power. But sometimes you have to cluster to avoid the
spillover effects. So for instance, when you want to evaluate whether school lunch improves student
learning outcomes, you can randomize at
the school level or you can randomize at the
individual student level. But if you do randomize at
the individual student level, then it's very easy to actually get the
spillover effects. So for instance, there
are two friends. One is treated and therefore
gets free school lunch. The other one is not treated and might not have
brought lunch with her. Then the treated
friend decided that she wants to share her
lunch with a friend, and if they do this
on a regular basis, your control students
will also be treated, will also have spillovers
of the treatment. So this is one of the
main reasons that we want to actually cluster
in our random assignment. There are also a number
of well-known effects. They're called the
evaluation-driven effects. So we're going to go
through them one by one. The first one is called
the Hawthorne effects. So this refers to a situation. In the 1920s, there was an
illumination experiment conducted at Western
Electric Hawthorne Plant near Chicago in the 1920s. So the idea behind the experiment is
that they will change the lighting situation
in the factory and look at how that lighting
situation changes productivity. However, the treatment group
is aware of being selected and they feel special of
being in the treatment group. Therefore, they work extra hard during the
observation periods. So they actually even when the experimenters
change the lighting to the original status quo, you still get this
increased productivity, and so this is the situation
where the participants knew that they were being
treated and they actually change their behavior as a
result of being selected. So how would you reduce
the Hawthorne effect? One way to do that is
to make the treatment as discreet as possible. So that if possible, you do not reveal that you are actually conducting
an experiment. Another effect that's
fairly well known is called the John Henry effect
which is the situation where a control participant is aware of their
status as members of the control group and is able to compare their performance with
that of a treatment group. So they might actually
work harder to overcome the disadvantage of being in the control group that would attenuate your treatment effect, and it's called the John
Henry effect because John Henry was a legendary
American steel driver. His output at the time was being compared to
that of steam drill. When he knew that,
he worked so hard to outperform the machine that
he died in the process. So that's why this is called
the John Henry effect. Again, when you reveal that participant is in a
field experiment, when they are aware they're either in the treatment
or the control group, they might change their behavior. There's another effect
which is fairly prevalent is called
experimenter demand effect, and the often cited example is the Stanford
Prison Experiment. So this is the case when
Dr. Phillip Zimbardo, Social Psychologist at
Stanford at the time, put participants into, he randomized the
participants into two roles. The prisoners or the guards. So during the experiment, the participants change
their behavior to fit what they believe the
experimenter is trying to test. So this is when subjects anticipate or trying
to guess what the experiment is trying
to test and change their behavior to conform
to the experimenters, their expectation of the
experimenter's demand. So in this particular experiment, both size took the roles far too seriously and conform
to the stereotype of prison guards versus prisoners and the experiment had to be cut short
after only six days. So another criticism of the
Stanford Prison Experiment is that is a demonstration rather than a
well-designed experiment. That aside, experimenter
demand effect is actually prevalent in both
lab and field experiments. So for instance, in a
lab experiment if you as the experimenter
walk around and lab and watch what each
subject is doing and perhaps even give signals
of approval or disapproval, that would influence the
results of the experiment. So that's called the
experimenter demand effect. Another effect is called
the anticipation effect. You might recall that sometimes we have
the facing design. So in the Uber
tipping experiment, half of the drivers received the tipping function in their app about 10 days
before the other half. When you run these experiments when the comparison group or the control group
changed their behavior because they think they'll receive the program
in the future. So let's say that
the control drivers knew that in 10 days, they will also receive
the treatment, what they might be doing is
perhaps improve their service to the customers anticipating that they might receive
tipping very soon. That would change the difference between the treatment
and the control. Sometimes there's
not much you can do. So in the Uber tipping
experiment for example, the company actually
had announced to the entire population
of drivers that this is a new feature that
they're going to push out but they're
going to face in the feature pushing
out of the feature. So this is Muhammad Yunus who was the managing director of Grameen Bank who piloted though group lending and microfinance
programs in Bangladesh. So in loss of
development experiments, we also have used the
facing design which is a fraction of the villagers who would
receive a treatment or a program before the other half, and in that case if they anticipate that they're
going to be treated, they might be changing
their behavior before the treatment starts. So that's something to be aware of when you
design an experiment. Especially when you release information about the
timing of the treatments. Another effect is called
the survey effect. This is particularly
worrisome when you try to combine a survey
together with an experiment. Generically, this is
a very good idea. But sometimes people might change their behavior just as a
result of being surveyed. So a well-known example is a method used in social
psychology called priming. So for instance, if you use
a set of questionnaires, if that somehow prime the participants' gender
identity, for instance, they might change their
behavior subsequently in the experiment to conform
with gender stereotypes. The same is true with we know effects on
ethnicity and so on. So subsequent measures
of performance might have changed
because of the survey. So if the survey has
to be conducted before an experiment assuming that the experiment is what you
are primarily interested in, a good practice is always to conduct the survey after
the experiment so you do not contaminate or change people's behavior for the
main part of your study. If you have to conduct the
survey before the experiment, then be aware of the
survey effects and make sure that your
questionnaires do not have or try to minimize the likelihood
that people's behavior might have changed as a
result of taking the survey. So here is a summary of the
effects that we talked about. So we looked at the
evaluation driven effects. Sometimes people perform
better or do better. If this happens in
the treatment group, then we call it the
Hawthorne effects. If the control group subjects
are motivated to do better, that's called the
John Henry effect. Something else that is really important regardless
of whether you conduct a lab experiment or a
field experiment is the experimenter
demand effect which is this is something that
you want to minimize. That refers to the
situation where subjects try to anticipate what the experimenter wants
them to do and change their behavior in conformity
to their expectations. When you conduct a facing
design in your experiment, if subjects anticipate that they will be receiving
treatment soon, they might change their behavior before the treatment
even started. So that's called the
anticipation effect, and lastly a survey might
affect what people do, and that could affect
the treatment group or the control group subjects. Here again, a good practice is to always conduct the survey after the experiment
if that's possible. If you have to conduct the
survey before they experiment, think about the survey
effect and think about wordings that try to
minimize the survey effect.