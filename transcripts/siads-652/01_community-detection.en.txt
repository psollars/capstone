One of the features
of networks that we haven't talked about
so much in this course is the tendency for networks
to form groups of nodes that have lots of edges within the groups and not a
lot of edges across. This is known as
community structure. Community detection
is the task of finding these groups from the
structure of the network. Community detection has
lots of applications, and we will talk about some of them at the end of the week. But to give you a taste, it has applications in
biology, for example, it can help identify
the function of molecules in molecular networks. Communities also impact information
diffusion and epidemics, and they can also be useful in the link prediction problem. Let's begin by looking at some example networks and some of these we
have seen before. Let's look at this network, the friendship network
in a karate club. If you remember the story here, is that we have
node number 1 here, who is the instructor
of the club, and node 34, who
is the assistant. The two of them have a fight, and the assistant decides to open their own group, their own club, and the students or the members of the club have
to decide if they want to go with the assistant or if they want to stay
with the old instructor. If you look at the
structure of that network, there's sort of a
natural division around here where you can guess that the nodes who are in this group are going to
go with the assistant, whereas the nodes who are in this group are going to
go with the instructor. In this case, the structure of the network itself can tell us how to define the groups in such a way that we can
make that prediction. Let's look at the
second network now. This is a network
of friendship in a town's middle school
and high school, and the colors
represent ethnicity. Here you can see that this network has a clear
community structure. It has these four
clusters of nodes and they're clustered by
age and by ethnicity. A lot of the edges are
within the clusters and not a lot of the edges
go across the cluster. This is another
example of a network that has a very clear
community structure. Another network with a
clear community structure that we've seen before, is this network of blogs that are connected by their hyperlinks. The nodes are colored
by their ideology, whether they're
left-wing or right-wing. The way they're clustered is that the left-wing mostly connect to other left-wing blogs and the right-wing blogs mostly connect to other
right-wing blogs, and there aren't a lot of edges that connect across
the two ideologies. These are all examples
of networks that have clear community structure and we've tried to guess what
the groups might be. But more generally, if you
have very large networks, how can we find the groups
of nodes in those cases? Can we identify an algorithm such that if you give me a network, I can give you back
the network and some partition of the
network that makes sense. Well, what do we mean
by it makes sense? Here's a basic intuition. What we want to do,
is we want to find sets of nodes or communities such that there are many edges within the sets but few edges
across the sets. However, the problem with this basic definition is that it can be achieved
by trivial communities. Let me give you an
example of that. Here is the karate
club network again, and imagine I give you
this network and told you, "Give me two groups
such that we don't have that many edges that
go across the groups." Well, one thing you
can do is you can say, "Okay, I can do that." How about we put node number 23, this one in one group, and then the rest of the nodes we'll put them in
the other group. Now we only have two edges
that cross the groups. That's very few
edges, we're done. Well, of course, this is
not really what we want. What we want is a partition that is not
so trivial like this. One of the problems that we have with this partition is that, imagine I were to regenerate this network
completely at random, but maybe I control for
the degrees of the nodes. Maybe I made this network
completely random, but I fixed the
degrees of the nodes. Well, even in that
random network, I'm going to have
that the number of connections between the group of nodes where I put
23 in one group and the rest of the nodes in the other group, is
going to be two. There's still only going to
be two edges going across those two groups because
node number 23 has degree 2, and so there's nothing
special about this partition. It could work even
with a random network. Somehow we want to control for the expected number of edges
across the communities, when we decide whether a particular partition of the network is of
high-quality or not. Our goal is to find a way of splitting these networks
into partitions. But let's start with
a simpler problem. Let's say what we want to do is, I gave you a network
and a partition. Now all you have to do is tell me whether this is a
good partition or not, or maybe you want to
score that partition. You want to quantify how
good of a partition that is, again taking into
account this idea of expected number of
edges across communities. This is going to be the
main topic for the rest of this video and it's a
measure called modularity. Again, given a network
in a set of communities, we want to measure the quality of the communities while
controlling for random chance. In order to build
up to this measure, let me start by defining
I to be the fraction of edges within the communities
that we have identified. Then let I_EXP be the
expected fraction of edges within the communities under random edge assignment while
controlling for degrees. I'll tell you exactly
how we're going to do a random assignment
in a way that we can control for degrees in a second but this will be I_EXP. Modularity is going to
be Q or I minus I_EXP. So we're simply going
to take the difference between the actual
fraction of edges within communities and subtract the expected fraction
of edges within communities under these
random assignments. Okay, let's write down I in a fancy notation that's
going to be useful later on. We can write down I. Again, this is the fraction
of edges within communities. We're going to sum up all pairs of nodes and
then inside the sum, we have these two terms. The first term is A_ij, which is an adjacency matrix. This is going to take on one if the two nodes are connected
by an edge and 0 otherwise. We're only going to be
adding up things when the pairs of nodes are
actually connected by an edge. Then the second term
is Delta function. Here is going to be one
if the two nodes i, j are in the same
community and 0 otherwise. So as you can see,
we're only adding up one whenever the pair
of nodes are one connected by an edge into the same groups or in
the same communities. Then since we want the
fraction of edges, not the number of edges, we're going to divide it
by m. We're also going to divide by two because
as you can see here, each pair of nodes is
going to show up twice. For example, nodes 1 and 2 are going to show up when
I is 1 and J is 2, but also when J is 2 and I is 1. So that's why we also
have to divide by two. One of the things that I
should say here is that we're only going to be doing this
for undirected networks. So whenever i is connected to j, j is connected i and that's
why we have these two here. Okay, so this is I, the actual fraction of
edges within communities. Now let's compute the
expected fraction of edges within communities. For that, let's fix a particular
node i with degree k_i, and let's ask the
following question. If the edges of this network
were placed at random, but maintaining the degree
of the node is fixed, what is the expected number
of edges between the node i and a node j that
has degree k_j? Here's where I finally have to tell you how
we're going to define our random model because
this will depend on exactly the details
of the random model. How do we place the
edges at random? How is it that we actually control for degree? So
let me show you that. The way we do that
is first we're going to put all of our edges here. These are all our edges. Let's assume there are m edges, but they don't have nodes yet, so we don't know
which are going to be the endpoints of
each of these edges. To define the endpoint what we're going to
do is we're going to look at all of our nodes. So let's imagine we have n nodes. So here's n_1 and 2 and all
the way through and n_N. We're going to look
at their degree. So imagine n_1 has degree 2, n_2 has degree 3, and so on. What we're going to do
is we're going to fill in these edges by taking
each of the nodes and placing them at random in one of these endpoints of these edges
that are currently empty. So it we'll take, for example, n_1 and n_1 has degree two. So we'll place it in
two of those endpoints, let's say here and here. Then we'll take n_2, which has degree three, and we'll place it in
three different places, here, here, and here. We'll do the same thing for
the next node and three, only one, and so on. In that way we'll
fill in the network, we'll define our edges, and we'll make sure
that the nodes have the same degree as they
did in the original network. One of the things to keep in mind here is that it is possible that we're going to put the same node in the
same two endpoints, so this does allow for
self-loops, and also, it is possible that
we are going to have multiple edges connecting
the same pairs of nodes, so these does allow
for multigraphs. Now, let's go back
to our question. If the edges of this network
were placed at random, now we know exactly what
we mean by at random, what is the expected number
of edges between this node i and some other node
j with degree k_j. Well, let's consider a
single edge connected to node i. I claimed that the chance that the node
j is on the other side of this edge is going to
be k_j divided by 2m, so k_j is the degree of j and m here is the
number of edges. Let me show you why this is. Let's go back to our model
for random assignment. We have our m edges here and we're taking
one of these nodes, i, and one of the edges of
node i and we're asking, what is the chance that a node j shows up exactly
on this endpoint? Well, what we do in our model
is we take node j here, we look at its degree and it has degree k_j and we're
going to place j in exactly k spots out of all
of these available spots. The chance that we're
actually going to put it in this particular
spot is going to be k_j divided by the
number of available spots, which is 2m; we have m edges
each one has two endpoints, so 2 times m. So that's where
this number comes from. Now, if you're paying attention, you might say, "Well, there aren't exactly
2m spots available, there are only 2m minus 1 spots because i has already
taken one of those spots." If you think that you
would be absolutely right, but actually, this one make a huge difference in
our calculations, especially if we're looking at a very large network
where m is very large, so we'll approximate that by 2m. But what we're after is the expected number of
edges between i and j. Since i has k_i edges, then the total expected
number of edges between i and j is going to
be this number here, which is the chance that j
shows up in one of them, times the degree of
i, which is k_i. We have this, again, this is the total expected number of edges between
two nodes, i and j. What we really want is
the expected fraction of edges between nodes
in the same community. Now, we can write this down. This is going to be
the sum over all pairs of nodes and we're
only going to be adding up something whenever
the two nodes are in the same community and in here we have the
expected number of edges between the two nodes i, j. Because we want the fraction, not the total, this sum
is just adding them up, all of the edges that are in the same group and we want
the fraction of them, then we're going to
divide by m here. Again, because of the fact
that a node show up twice, here our pairs of
notes show up twice, then we have to,
again, divide by two. We now have the
expected fraction of edges between nodes in the
same community and recall, we are already had computed the actual fraction of edges of nodes in
the same community, that was the one that had the adjacency matrix inside the sum, and so we're ready
to simply write down what modularity is. Modularity is the actual fraction of edges between nodes
in the same community, i, minus the expected, which we already found
the two terms for it and if we do a little
bit of simplification, we get this formula
here in the red box, which is the one that
is used all over the place to compute modularity. Using modularity, we can score a given partition of a
network into communities. However, the measure
itself doesn't tell us how to find
good partitions. We can take a partition and quantify the quality
of the partition, but we don't know how to
find the best partition. One might say, "Well, why
don't we just maximize this modularity function over
all possible partitions?" The answer to that is, "Well, that's not computationally
feasible." If you imagine, especially
for very large networks, all possible sets of
partitions is very, very large, and so it's
not possible to take this approach of really trying
to maximize modularity. The options we have
is to use heuristics, to use approximations
that can generate partitions with high modularity, and that's what we're going to explore in the next few lectures; what are algorithms
that can help us find these good partitions. I'll
see you in that video.