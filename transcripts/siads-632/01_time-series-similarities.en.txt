Hello everyone. Welcome back. I hope you now understand how to extract patterns from
time series data. As we know that patterns
and similarity are two basic building blocks
of many data mining tasks. From now on, let's
talk about how to calculate similarity
between time series data. As we emphasized again and again, we can see that a
time series is the least of timestamped values. X_1, x_2 to x_n are
numerical monuments and t_1, t_2 to t_n are actual timestamps, instead of just orders
or positions. This will indicate
how different we will be in computing the similarity
between time series. How to calculate similarity
or distances of time series. Well, this is the basic
data mining question. In reality, we usually have multiple time series and want to understand how
similar they are. For example, we have one
series that has n values, x_1 to x_n, measured
at n timestamps, t_1, t_2, to t_n. We have another time
series that has m values, y_1, y_2, to y_m measured
at m different timestamps. So how can we find the
similarity of the two sequences? In other words, how can we find the distance of the two series? Well, because as we
know that differences usually just are
reciprocal of similarity. If we know how to measure
similarity between time series, we can apply it to many
interesting tasks. For example, if we know how the stock market price of a stock actually goes over time, and we also know the sentiments
measured in Twitter. We're interested in how well those two time series are
similar to each other? In other words, can we use one to predict or at least
to indicate another. Another interesting application
of time series similarity is to search for
similar time series. As we know that if
we have a database of many time series data, similar to many other data, like the normal database search, only find exact matches. The normal database
query will give you only the transactions that
matches this query completely. But in many scenarios
we're interested in find similar time series and not exactly the
same way as occurred. We will allow a certain
amount of differences. In this case, we
need to be able to compute the numerical
similarity or distance. There are usually two scenarios
of similarity search. We could search for similar whole sequences
or whole times series. For instance, we want to find which other stocks have very similar time series
of the stock Google. We want to match the
entire time series. In other scenarios
we only care about finding the time series that a part of it
matches the query. Or a part of it is
similar to a query. This is called subsequence match. In this lecture, we will introduce whole sequence
match or the similarity of two complete series and we leave subsequence match to
future work actually, you can actually
read the textbook, I know that there is a
sub chapter about that. So how to calculate similarities. Well, as we will see that if we treat time series
similar to vectors, you can again apply techniques that we have learned
in vector data mining, for instance, Euclidean distance. All you needed to is to
ignore the timestamps, and you treat the timestamps as if they're just dimensions. This is to treat each time
series as the vector. An assumption is that the two time series have exactly the same
number of dimensions. Because if they have
different dimensions, we cannot calculate
Euclidean distance. We also assume that
the timestamps, or at least the positions of the timestamps are
naturally matched. So x_1 should be matched to y_1, x_2 should be matched to y_2, and both x and y will
have n dimensions. If this is the case, then we can calculate that
Euclidean distance of the two time series x
and y as the square root of the sum of the square
of the differences of the two time series at
every particular timestamp. For instance, at
timestamp one t_1, the difference is x_1 minus y_1, we take the square, and
then the second timestamp, we have x_2 minus
y_2 take the square. We sum them up over
all dimensions, in this case, all the timestamps and then we take the square root. That's how we get
Euclidean distance. I'm sure that you still
remember this from data mining. Of course you can apply the same technique to many
others in narrative functions. All you need to do is to treat time series data as
if they are vectors. For example, you can
compute Manhattan distance, which we know that is the sum of the absolute value
of x_i minus y_i. You can also compute
the Cosine similarity. We know that cosine similarity is bounded between zero and one, which is very nice. You can also compute
Pearson's coefficient that gives you the correlation
between two time series. In this case, the time series will be naturally normalized. In fact, you can
use any applicable vector space similarity
measures to time series data. All you need to do is to treat the time series as vectors. You should understand
that by doing that, you are losing the
actual timestamps. You are only counting them
as different dimensions. This indicates some problems
of directly applying Euclidean distance
or other vectors in their estimators
to time series data. One problem with
Euclidean distances is of course that it's
sensitive to scale. If two time series are just
measured at different scale, then the Euclidean distance, because we're using
the difference between the values x_1 and
y_1, x_n and y_n. In that case, the difference
could be too large, but the shape of the time series could be actually very similar. If you want to accommodate that, you can always normalize
the time series first and then we'll preserve the patterns instead of the numerical values as they
apply Euclidean distance. You can also use
Cosine similarity or Pearson's coefficient instead because they
naturally would actually normalize the numbers. But the real problem of
applying Euclidean distance or any other vector space
similarity matrix is that, two time series are
not always aligned. The assumption that they share exactly the same number
of timestamps and the timestamps are taken at the same time are actually
not necessarily true. In the rest of the lecture, you will see how we accommodate two misaligned
time series.