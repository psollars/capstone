Now let's operationalize some of these
theoretical Concepts that we've talked about and go to a software
system called mrjob or Mr Job. So mrjob is a map-reduce
system using Python. It was developed by Yelp and will actually
be using a Yelp data set in this course. As I mentioned, it's a python
implementation of mapreduce Mr. Job can run on Hadoop. It can actually run on a number of
other systems that support distributed computing. Such as Amazon AWS elastic mapreduce,
that's a mouthful. It's also called EMR if you
happen to use Amazon AWS, you can look up EMR as one of the services
and go ahead and experiment with that. We're not going to be using Amazon AWS
in this course, let's take a look at a specific application that
we're going to run using mrjob. So we're going to talk a little bit about
the framework and then we're going to return turn to our word count example that
we introduced in the previous example. Our mapper in this framework is
going to break the input line into key value pairs
are reducer is going to take all of those key value pairs with the same
key and compute an aggregate function. In this case. It's going to be a sum but it turns out that the count is identical
to a some if you're only adding up one's. Now mrjob takes care of things
like sorting the map or output invoking the reduce tasks for us,
assembling the final output and while it's doing all that it's going to take
care of scheduling and monitoring tasks. So we're going to be using
a local implementation of this. We're going to avoid using Hadoop. We could use Hadoop for
our purposes though. When you start looking at the notebooks. Please know that we're not using YARN. We're using all of
the Native functionality and now our job to schedule a monitor tasks. Let's take a look at some. Mrjob code that's supports
our word count example. You'll see on the right-hand side of
the screen the example that we just talked about a few minutes ago with our input
splitting mapping shuffling reducing and our final result and let's try to figure out how we're
going to implement that using mrjob. Now.
Keep in mind. This is the first time you've
seen this type of code in Python. It's going to look a little
foreign to you and there's a fair bit of what I All magic
that's going on in the background here and we're going to walk through this file line
by line or through this code line by line. And then hopefully it'll make sense. We're going to get a chance to practice
this in the homework assignment as well. So our first line here
starts with a double % that double % is a magic
command in Jupiter. Now, this is a very specific use of
the word magic you've encountered magic commands before I know
that in PSI as five one five. We talked about magic
commands the % % magic prefix indicates that this is going
to operate on the entire. of this block,
what I'm doing here when I write % % file and then give it
a file name is I am instructing Jupiter to take this code and
write a file called word count dot p y with the contents
of the remainder of the cell. That's important because mrjob is
designed to run as a script and not as part of a jupyter notebook. So we're going to have To
write out the file and then run the file using our
bank command in Jupiter. So the first line there a magic
command that instructs Jupiter to write out the remainder of the file
to word underscore count dot py the next line here is an import statement. That should look familiar to you. It will import this mrjob
from The library Mr. Job to job, we've pre-loaded this for
you on your jupyter notebooks. So you don't have to do this by yourself. Now.
I've also set you up with this code to help you with some of the homework
assignments are e-stat ends for regular expression. This will allow you to do better
splitting of each line into words. If you choose to use it for now. We're going to use something
that's just plain old python that you'll see down below. Now.
This is object oriented python here. So we're defining a class
called MRWordFrequencyCount. That is a subclass that is it inherits everything from mrjob
which is what we imported up. So this mrjob is what allows
us to subclass mrjob. Mrjob as a class gives us
a lot of functionality. So it is the part that understands
how mappers and reducers work. When we do something like run this it will
allow us to do exactly the right things. So this is what I call boilerplate code. You don't need to touch anything
down to this point at all. The next two things that you'll see
are two function definitions one for mapper and one for reducer. So those are separate and the mapper does exactly what you would think it does
the mapping the reducer does the reducing. So let's think about what we want to
do here and I'm setting you up for something that's a little bit more
complex than our original example, but stay with me on this one. I'm going to focus on this
line in here in particular. Now we've seen the yield statement before
the yield statement as you'll remember from our discussion about
generators in five one five is something that will return that value. And then pause execution at that point. Now this example of MRWordFrequencyCount
doesn't just count words for us. It will also count characters and lines. So here's how this is going to work for
us. Going to take each line and split it. Now.
This is a plain old string split in Python. So that split is what's going to
allow us to go from here to here. Now remember mrjob has a lot of hidden functionality
behind it that hidden functionality is what allows us to know that
the mapper is called once for every line in the file,
that's why we have line over here. So that line value is set for
each line in the original data file. What we're going to do in this middle
yield statement is we're going to yield out a key value pair
where the key is words and the value is the length
of the split of the line. So we're doing something
a little bit different here. We're not counting the number
of words that exist. We're counting the total number of words,
but I want you to get a feel for how this hangs together because
I will ask you to implement the word count process
that you see on the right. So we're doing a partial. implementation of this so
the mapper will give us as we call them a per the number of
characters which is the length of the line what I just talked about with
the number of words crudely split using python split you can do a better
job using regular Expressions if you so choose and here's one of these pieces that
we often see in mapreduce things where if I give you exactly one line of text and ask you how many lines of text do You have
the answer is always going to be one. So if I keep calling map or
over and over and over again, I will get three different types of keys. They will be repeated. So it characters chars words and lines
will limit the values that you see there. Every time mapper is called it will
return each yield statement in order. So if we call it for line 1 of
deer Bear River, it will calculate the total number of characters as
the length of that line and you That out. It will count. The number of words the next time it's
called and it meant the number of words with the line split and tell us that
we have one line the reducer will then take for every key it will
take the sum of the values. So in this particular case,
if we wanted to count the number of lines the total number of
lines in here we could add up. All the ones is going to get a little
bit more complicated as we look. At the number of words there. We're not going to be just adding up once
we're going to be actually adding up the value of the length of
that line split over here. So that's the mapper and the reducer
the other idiom the final idiom that we're going to look at here is to say
if we're being invoked as a file then we're going to simply call The Run
function that is provided by mrjob. Okay, so here's how This will work for us. Let's take a look at this
example on some real text. So on the left hand side of the screen you
have exactly the same code that we saw in the previous slide. Let's say we fed it a file that
had just two lines in it to be or not to be that is the question. So these are two separate lines
one text file as we pipe this or as we pass this as an argument to
our script what it's going to do. Do over here in the mapper? It's going to first omit the number
of characters for that first line. So that's what's going to
give us characters 18. If you count the number of characters in
this first line, you'll find that it's 18. The next thing that is going to yield
over here is the number of words by splitting it and in Python a plain
old split will give us one too. Three four five six words,
so we're going to omit the literal words because that
corresponds to words over here and the number six which is
the number of words. Finally, we're going to omit
the literal lines and the number one. So that's how we get lines. And one over here. We're going to repeat exactly
the same thing with the next line from our text file. That is the question. We're going to find out that
that has 20 characters. If we split this into words we
find out we have four words and again consistent with All of our work
one line will always have one line. Now you can say why are we
saying lines comma 1 you'll see that in a second remember
in our mapreduce framework. We often have a hidden piece that we
Shuffle the common Keys together. So hidden between the mapper and the
reducer is a mechanism by which we bring together the 18 and the 20 NT for
the characters as a list we bring together the 6 and
the 4 over here with the same key and we bring together the two ones over here what happens next is we invoke
the reducer and it will yield out a key and I've asked for
it the sum of the values. So here Mikey is consistent. From our output of our sorting and
shuffling step. We add these together with a sum function. We get 38 here again words
gets emitted as the key for our output 6 plus 4 is 10
we omit lines over here. And this is 1 plus 1 which equals 2 so
you see what happened here. Every time we emitted a one here that sets
us up to bring these things together and then to add them up to find out
we have to mine's over here. So that's our code and
that's a description of how the code works when we run our mrjob word count
script here's what's going to happen. First of all,
we're going to invoke it in a Jupiter cell by using an exclamation mark
at the beginning of our line. Now as I've said before in some of the
work that I've done in these courses Data, scientists can be a little
bit lazy sometimes so instead of saying exclamation mark
we're just going to say bang. Ba NG bang and
that's what we call an exclamation mark when we're dealing with python or
shell scripting. So we're going to invoke the python
interpreter outside of Jupiter. We're going to pass in
the name of the file. And remember this came from our % % file line where we
said % % file word count. P.
Why? That's where this comes from. So that has to be consistent. Mrjob also provides functionality to allow us to
take command line arguments and pass them into the file by
default mrjob assumes that arguments passed to that script are the
names of files that it should operate on. So if we invoke that in our Jupiter cell
so will invoke that line in Jupiter. We get the following output. Now, I'm going to clear this just to
make it a little bit simpler to follow. So if we run this we get a lot of output that at first can look
a little overwhelming. It'll tell us things like no
configurations are found or no configs are specified and
that's some advanced stuff. We're running on something like AWS EMR. We're going to want to take
a look at our configurations and make sure that they're correct. Mrjob that is also emits a lot of information about some temp
directories that it's creating. So if we were operating on a cluster we
want to Generate random file name, so it doesn't conflict with other jobs
that are running on the machine. So it'll create a temporary directory
in which it'll do all of its work now depending on how you've
set up your mrjob script. It may have multiple steps in our case. Our mapper only has one step. So we're going to be running. Up 1 of 1 we're going to be told
that our job output also goes into some folder that should correspond
to this folder up here and then it'll tell us that is going to stream
the final output from some output files. So these output files Are all the same? And what we're going to find
when we have our output, so this is the content of the temporary file. We're going to find out that our
results are words nine lines three and chars or characters 41. So that's the guts that's
are those are our results. That's what we're after and you can see
that mrjob is a little bit primitive. So it doesn't quite give us all that
functionality all that nice functionality that we're used to with. And statements and F statements in Python. It's pretty primitive,
but it gets the job done. And then finally it tells you again
that it's going to clean that folder up. I don't think you should be concerned with
that sort of chatter that you get here. So all this can be ignored what we're
interested in are the results and the best way to get familiar with this
is to work on some exercises on your own which is what this week's
homework is all about.