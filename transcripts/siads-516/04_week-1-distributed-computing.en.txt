So we've talked about some
defining features of big data and talked about how it's an approach or
philosophy of analysis. We've also talked a little bit in an
abstract way about mapping and reducing. I want to now continue on and
talk about another important piece of our foundation here, and
that's distributed computing. What I mean by distributed
computing is a way to differentiate vertical
versus horizontal scaling. So vertical scaling is when you're hitting
a limit of analysis with your machine. So you're running out of memory, you're running out of disk space,
you're running out of time. You go out and you buy a bigger machine. You buy a more powerful laptop, you
consider buying a very expensive server that has rack mounted somewhere,
that's vertical scaling. When you buy a bigger machine. An alternative to that is
to do horizontal scaling. Horizontal means that you're
expanding things out. So you have multiple machines
doing the same analysis or different components of the analysis,
but applying the same techniques. And it comes down to a question
of how much delay or how much lag you're willing to tolerate. This, as we mentioned in the previous
segment, relates to how much time or how much money you have to spend. So if I'm there as your manager
as a data scientist, and I'm asking you to do an analysis. If you're sitting there
doing nothing waiting for an analysis to crunch out,
that's very expensive for me. So I might want to simply
buy you a bigger machine. At some point, though,
you're going to hit a limit and I'm going to get tired of
buying bigger machines for you. So what we're going to look
at in distributed computing is a way to use relatively
inexpensive machines and a whole lot of them to help us achieve
reasonable throughput for our analysis. Now MapReproduce and
distributed computing are tightly related. If you think about when
we split our input, there's an important feature that we need
for MapReduce and distributed computing. We don't want any interline dependencies,
especially in the reducing stage. So, for example, it's easy to calculate something like
the average number of words per line. That we simply count the number of words. We count the total number in each line. We count the total number of lines. We calculate the quotient and
we're good to go. If we're doing something that relies,
say, on the previous line, that is say, we're calculating the change of
line length from line to line, that's not a good application of
MapReduce or distributed computing. So in other words, each line can be
processed independently of other lines. Now, if you think about this, and
let's say that we have ten lines of text, it doesn't matter where
the computation takes place. So I could give you one line of text and ask you to analyze it, I could give
someone else another line of text and ask them to analyze it
to compute your results. So we're talking about,
perhaps a different machine. I'm using people as analogies for machines
here, but we could take those values. I could ask each of you to count
the number of words in a line, and then I could ask you to come together,
pool your analysis and then calculate some sort
of summary statistic. So that's how MapReduce works.