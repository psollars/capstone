Welcome back. I
want to go through a few last remaining
techniques that might help boost your effectiveness in terms of network visualization. Remember there's a huge complexity of
network visualization. We've talked about
some of the layout approaches that might be useful. I want to talk
about a few others. The layout we've done. I want to talk about
first data reduction as a possible approach. Here's our first example of
a data reduction technique. In this case, what
we've done is condensed the edges into a smaller, tighter fitting edge that is routed across the circular network
going through the middle. If all the edges have similar source and
destination locations, we can compact them all into a tighter edge bundled
representation of the edges. It's a little bit harder to read. Like there are
certain things that are not possible to do. But visually you can
get a better summary of the underlying data because
we've reduced a ton of the edge crossings or made them a little bit smaller and off to the side by making
everything a little bit more compact using
this bundling approach. You're going to need some way of uncovering the details of this. You can't just from this get it all the details that you need about the underlying
data structure. Interactivity or some
secondary visualization might be necessary in this case. You can also bundle nodes
in much the same way. The visualization on the
far left we can identify these tight cells of communities that are
strongly connected. You see H_1, H_2, and H_3 communities that
have been detected either by the person's direct
manipulation like they've drawn something or
through algorithmic means. We can detect communities
using algorithms. Once we found these
tightly connected clusters of nodes, we can collapse them. H_1 which used to be five nodes can now
be reduced into one, similarly for H_2 and H_3. We still have edges
that go between these. The kind of connection between those communities is
still represented here. But if we have a huge
network and we want to get a summary view of it this
might be a good approach. This is the data
reduction approach. Let's talk for a second about improving things
through interaction. I want to show you a couple of very different
systems that have been generated to solve
different domain tasks, like different domain
level problems. But the interactivity
used in them. I think it's really cool
and might be something to consider when implementing your own network
visualization techniques. A couple of complete
systems to consider. The system highlights
all members within two degrees of separation while desaturating the
rest of the display. Connectivity is computed through the complete backing network, uncovering connections that pass through members not
yet visualized. For example; distant nodes
in the network may light up, signifying a friend in
common that is not yet visible. Once zoomed out users can click and hold
a node to inflate the highlight itself creating
a focus plus contexts view. You will have noticed that
there's a lot of things going on including the
focus plus contexts. When you mouse over something
it highlights that node, it highlights its neighbors, it highlights its neighbors'
neighbors but smaller. The scale of that goes down. But you're still able to
see those connections. Very smooth animation all
allowing your eye to track. There's a bunch of really
positive aspect of this Vizster system
which you might be able to apply and other systems
that you're implementing. This particular
system is focusing on social connections and specific nodes like that is at a high level the kinds of
tasks that it's targeting. The technique is node-link, as much of what
we've seen before. But the specific
encoding and the kind of interactions ensures that you're able to understand important and interesting
subparts of the network. Social network analysis,
often what we're targeting as the
study of ego-nets, like this is not every kind of social network analysis but as a common kind of social
network analysis. Ego-net basically corresponds
to a central node, the ego, and its friends and possibly the connections
between those friends as well. That node and its neighbors
and all the edges within that small thing are
considered the ego-net. That is the thing that is
emphasized in Vizster. As you mouse over a node, you're picking the ego, it
highlights all its neighbors, it highlights the
edges between them, it highlights maybe even a
second-order an ego plus one. All that becomes much more
visible and salient through the interactive mechanisms
that we have in Vizster. The interactions basically
boost our ability to track these kinds of things and identify which nodes
are important, which nodes belong to that
subset that we care about, how many of those nodes
existence and so on. The interaction allows us to make salient and filter out nodes of interest in the visualization. I'm going to walk through
a second example here. This one is going to use a
very different kind of layout. This is called
Semantic Substrates. NVSS allows users to organize the nodes into
a semantic substrate. In this case, we've put 52 Supreme Court
cases in one region, 112 Circuit Court cases
in the second region, and then 123 District
Court cases in the third. They're all organized in the
same chronological format. There are thousands of
links which would be overwhelming if we
expose them all. But the user can control
which ones they see, here the Supreme to Circuit Court cases or Supreme
to District Court cases. Of course, it can get very
busy if you have lots of them. But if we take the
situation where we give users control by selecting
these range sliders, we can limit the complexity
of the display and allow users to show just the
links that interest them. They get this dynamic
query effect by sliding across and then they can
do additional exposure of links by the selection
which confirms or lends support to one of the hypotheses of our
political science partners, which is that
District Court cases have a short half-life, Circuit Court cases are referenced for longer period of time and Supreme Court cases
get referenced for even longer periods of time. This is a cool approach. It is one where we have a need to analyze different
classes of nodes. We saw an example of this when we were
looking at hive plots. In this case, they have a
very different semantics. There are different
kinds of court cases, those that went to the
Supreme Court and so on. That's going to be
the nominal attribute that we're going to
use in order to lay out the visualization
on the y-axis. Rather than letting the network just be laid out as it wants, like using one of these
force-directed layout approaches, we're going to constrain
the layout based on a couple of specific
and important attributes. On the y-axis, it's
the case type or the court type and on
the x-axis it's time. Things that appear
earlier or later. There are semantics
then that are being preserved within that
network visualization. If you look at a specific
node, you can tell, does it belong to a Supreme
Court case that happened in 1970 that's readable
from the visualization. Rather than letting the graph go basically all over the place, we have a smaller graph
and we need to have those constraints to satisfy a number of tasks that
the analysts have. In the interactions there you saw all cleverness in
terms of filtering. Selecting ranges and being able to select different
types of cases, like there were a bunch
of check boxes that allowed for filtering and
this dynamic manipulation. It looked a little bit
like parallel coordinates. If you remember, that
you can basically filter by specifying ranges and moving
that range slider around. Very cool technique,
one that might be very suitable for a specific
kind of data-set. Just a few brief takeaways. One is that we can optimize our visualizations based
on a number of things. One is data reduction. So much as we've seen up till now when we talked
about multi-dimensional, multivariate stuff,
there often is a time and a place for
reducing the data. Either reducing the number of edges or coming up
with a mark that is representative of lots of edges or reducing the number of
nodes collapsing them. Often the interaction will be necessary to basically
get at the details. Once we've collapsed,
is it necessary to be able to expand and get
those additional details? All these different
interaction techniques like you saw in Vizster and in semantic substrates are
also great at facilitating, the interactions with the data and getting at answers for
different domain-level tasks. I will encourage you to think
of different combinations, basically picking and choosing from this library of algorithms, these libraries of
interaction techniques, data reduction
techniques, and whatever, merging them together
in order to get the right network or hierarchical visualization
for your tasks. Summary of just this week. Hierarchical and network
visualizations are complex. Hopefully you've
bought into this idea. While there are some really
simple techniques that are common when it
comes to real data, we have to think of really some crazy
alternatives to make these visualizations
still work in terms of supporting
different kinds of tasks. For hierarchies, we saw node-link space-filling for the networks, we saw also node-link
matrix, and so on. But again, the picking of this right combination of these different things
is going to be crucial and you have to play with
these things as you're learning how to deal with network or hierarchical data-sets to get the right performance for
whatever task you have. Right, and with that,
thank you for listening.