Hi. Welcome back. I want to talk about one
last topic for this week, which is new ways of
interacting with data. So far, we've mostly seen
examples of using the mouse, basically to manipulate
what was on the screen. Maybe there was some typing, like you could filter
based on the name. But largely what we were doing was what is called
direct manipulation through mouse action or
through some cursor behavior. There are other ways of
interacting with data that are emerging based on
new technologies. I want to show a few
different examples. Now, all these different
things have some risk, like some of them are cool
and novel and not so useful. What I will point out is that there are
opportunities for using things like voice and speech and gesture and using
large displays, but you have to do
them strategically. So don't just use them
because they're cool, but you'll see in
these examples, areas where they're actually useful, where they actually add
something substantial to the visualization
and the interaction. This is a first example. This is using the dust and magnets approach
that we saw earlier, just with a very large
multi-touch display, and you can see different
people are going to be interacting with this
data simultaneously. But because of the way they're manipulating the
dust and magnets, being able to touch
things might be a very reasonable approach.
Here's the video. You can see here that the user is clicking to basically drag
the magnet from the top. They're selecting magnets,
so they find one, they drag it over and, then the points
dynamically move around. The other person
says, "I want to add this other magnet",
so they drag it in. Again, another magnet's
being added. Everything is smoothly, animating out, dynamically
as they do this. You'll see they're able to work together
at the same time. What you might not have
caught was that one of the people enlarge the
magnets as they were going, so they said this needs
to be more important, so they were able to use
different gestures in order to manipulate the strength
of the magnets. So this is Another system. This
is called SmartCues, this was actually
developed in my group, one of the few systems that I'll talk about
that we developed. Basically, it's using
multi-touch and gesture in order to get additional
data about data. You're looking at
the visualization and you're going to be
able to interact with it. Again, instead of mousing over, you can tap to get
additional information. So you can tap on the bar to get that additional
detail on demand. But as you'll see in a second, when you need to make comparisons between two different bars, you're able to touch
two simultaneously, and the difference
between them is displayed as an annotation. As you do this repeatedly, the system is actually
learning that you're interested in those
comparisons and will eventually
re-encode the data based on that repeated actions. It has learned you've done the same operation
multiple times, you've compared these two
bars one to the next, and so why don't I just show you all the differences between the bar that you
always seem to be selecting and all the
other pieces of data, again, a really simple example. The system also supports
being able to do things like move your hand across the display to indicate that you want to trend line and things like that. When you don't have a keyboard
or a mouse, for example, you can use the affordances
of a touch surface like an iPad or a touch screen in order to get these
additional details. In this next example, I'm going to show you really quickly a system called Eviza, which is actually implemented inside of Tableau right now, so you can use speech in order to control
the visualization. This is just a 30 second clip, but if you have
Tableau installed, some of these features
are available and some of the newer
versions of the software. Eviza is a prototype
system that supports an interactive dialogue with
an existing visualization. Let's begin, this is a map of earthquake data in
the United States. Let's look at some of the attributes of
these earthquakes. Where are the large earthquakes? Our system maps the term large
to a data attribute called magnitude and sets the value to be five based
on some semantics. Evisa also supports pragmatics and
multimodal interaction. This is a really
powerful approach when you have situations
where there's no keyboard, for example, like you need to be able to make certain queries, so speech is an
appropriate approach. Natural language is also appropriate in situations
where your end-users might not be able to easily
define certain queries. If we think about having a really sophisticated
visualization system where it requires understanding
something about SQL, that's not great. It might be better to
have a natural language and maybe even a speech
based interface that allows you to just express
vocally what it is that you want and have the system
tries its best to interpret. There's always going to be some problems with this approach. It's going to be sensitive to the speech recognition
system and so on. There have been a number of projects that have tried
to tackle this problem of ambiguity within speech and natural language interfaces. But this is an evolving
area that I think is going to be very powerful and
useful in the future. Just a few takeaways; there are various technologies that are driving novel
interaction techniques. I showed you some examples
with touch and speech. I didn't show you any with VR-AR, you can find some on the web. This is an example of a space where there
are examples and they look cool but are not necessarily the
most useful or practical. VR-AR has these problems with
what's called gorilla arm, so if you keep waving
your arms about, it's like your arms
get really tired and it's hard to manipulate data. It also requires 3-D
data structures, as we learned in our perception and earlier discussions
and Infovis one. 3-D is not the best way
to represent most data. VR-AR is one of
these areas that I think is cool and has potential but there aren't examples that I would point out readily
today that I think are like, "wow, this is like a
thing that will make a huge difference to how
you use interactive data." To wrap up the
interaction week for us, interaction, again, is key for lots of information
visualization applications. Static representations,
as we noted, don't really scale and aren't
really easy to explore, or ask additional questions. They have limited expressiveness and
limited effectiveness. Interactivity is going to be the thing that gives
us this great boost. The multiple views we have, like if we have multiple
visualizations simultaneously, they show more data, but they also often amplify
our need for interactivity. Even if we address the problem of not being able
to see everything that we need in one
visualization and we have multiple visualizations being
displayed simultaneously, we need that interactivity to
connect the visualizations, to support filtering that
basically will exclude the same data from all the
visualizations on the screen. Interactivity doesn't
go away simply because you're using large displays
or many visualizations, and oftentimes it's crucial. The last point that I
want to make though, is that returning to that idea
of the feedback mechanism. Remember we have this as pipeline of the data
being transformed and tables being generated and the views generated all
in service of the end-user. That feedback loop through interactivity is crucial
because it represents a dialogue between the end
user and the application. It is the mechanism by which
the end user is able to specify what it is that they want to understand
about the data. By giving the end
user the right set of language constructs
like the ability to say certain kinds of things, the system can appropriately address the needs
of the end user, they can understand
the dialogue back. This is the job of
the designer of sophisticated
visualization software to enable the right set of interactive features to support
that kind of dialogue, again, in the
interests of boosting the effectiveness
and expressiveness of the underlying visualization. With that, thank
you for listening.