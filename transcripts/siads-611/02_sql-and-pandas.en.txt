Now I want to talk about a couple of techniques to connect pandas or Jupyter
Notebooks to SQL. So there's two basic approaches. The first one is to realize that Jupyter Notebook is
nothing more than Python. It's an interactive
Python interpreter where you kind of go through
cells and you run them. And so any of the things
that we've been doing in the Python programs that we've written for this
class will work there. Importing the Python connector, Python Postgres connector. There is a pandas
extension called read_sql, which takes a database connection like we were using in
Python before and it runs an SQL command and basically
brings you back a DataFrame. There's also a
"magic" SQL function, that you can say, percent, and then run SQL commands. And it kind of turns a
Jupyter Notebook into a simple psql client and so it just is a command line client
and you type commands. And if you really like Jupyter Notebooks rather
than command line, it's a way for you
to run a command, explore it, run a
command, explore it. Maybe put a LIMIT clause
on it, or whatever. So we'll talk about how
both of these things work. If, for example, you are using
something like InfluxDB, it's kind of maybe a weird
database and it gives you an SQL interface and it gives you a Python library to talk
to its SQL interface. Well, you're probably
going to have to use something like
straight Python. Because the Magic function,
which we'll talk about next, uses SQLAlchemy and
you have to have a driver for each of the databases like
connected the right way. So at some point you might find that if your world's a little more complex, you want to use straight Python. And so this looks kind of like the code we
were writing before. It just happens to be
broken into cells. And so we're going
to do an import. We do a connection string. By the way, I didn't want
that to be small, so that's all one long line with the database name and the user
and the port and the host, and all that stuff. And then you make your connection, and you get a connection back. Connection is your like
portal, your window in. And then you can
send SQL commands. I just happened to put this
into a string and then I used the pandas read_sql query where I pass in the SQL statement
in a connection string. And it just gives me
back a DataFrame. So that's in pandas. pandas is running the SQL
command and it's looping through the results set and
giving you back a DataFrame. Okay? So that's the
straight Python. It's pretty straightforward. I think ultimately
it will give you the most flexibility but
it looks like Python code. And you might think
that's a good thing, or you might think
that's a bad thing, I think it's cool and I'd like to be able to
write little snippets in a notebook and then just go
paste those things over into a Python application and
then let it run all night in ways that I know how it's going to work and how
it's going to control. But if you really want to
use Jupyter Notebook you can install this SqlMagic function and there's a pip
install for this. And so you have to get this installed into your environment. And so this is where you say load this extension in the config, and then you basically make a database connection
by typing %sql. And that first one sets
the database connection for %sql from the rest
of the session. Then you say %sql and then
you type in some SQL, and that will run it and
it'll show it to you, or you can say give
me back a result. And this is kind of like what we did when we were
talking in Python is you get a result. You run a query and
you get a result set. And then you have to work
through that result set. So the result set itself
is not a DataFrame. But the SqlMagic is
designed to talk to pandas. And so you can say, hey, give me back a DataFrame for that result, which means read
through the result and give me back a DataFrame. And then you can just
print out the DataFrame. So those are the two ways, and we'll go through
some examples. This is just an outline of what we want and we talk about. And so in summary, SQL and
pandas are good friends. Sometimes you've got no choice, because the data is
in an SQL database. Someone else has
done all the work to give you a database. pandas is really amazing
in its use of memory. And if your data is
like medium large, you can sort of maybe
squeeze it into memory by using clever
schema mechanisms, which are effectively
compression. Much like we think of
a database schema as it's got a function of compression or reducing the
amount of data scanned. But sometimes it's just so
large you can't do it. You've got to put that
thing in a database. And then if you want, you can actually ignore terminal
and command line and just run SQL commands
in your Jupyter Notebook, and then pull that data and
get it back into pandas. So in general, talking
to SQL is pretty natural in pandas and the skills naturally pretty
much move both ways. [MUSIC]