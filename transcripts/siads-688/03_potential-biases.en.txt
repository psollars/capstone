We talked about
reputation systems and the various varieties
of reputation systems. What we're going to
talk about now is the potential biases that
reputation systems might have. The paper is called The Dynamics of Discrimination by Bohren, Imas and Rosenberg. We have a fair amount of
evidence that there exists systematic discrimination
sometimes based on the racial profiles, ethnicity, gender, or
sexual orientation. There are some very
helpful surveys such as the Bertrand and Duflo
survey and Fang and Moro that gives an overview
of the type of models as well as the robust
findings on discrimination. Most of these studies were
conducted in a static setting. For instance, you have
a man and a woman; they each produce a product;
there's an evaluator. In the Q&A sites, you can think of the
evaluator as the user who consume the content and
decide to upvote or downvote. If the evaluator has
prior bias against women, if he thinks that men are better at programming and therefore this man's product should be better than a woman's product, he will provide an
upvote for the man. If we take one snapshot, then we capture this bias if we can evaluate both products. Imagine another setting where we have the same man and
woman and the evaluator, and at this point, there have been a fair amount of experience and reputation, so the man has produced
lots of programs and code, and has accumulated reputation. Let's say that the man's
reputation score is a 100 and the woman also produced a
reputation score of a 100. In that case, the evaluator
might decide that after seeing the
reputations over time, I think both of them are good, so I'm going to upvote
on both products. In fact, if the
evaluator realizes that his initial
prior was inaccurate, he might actually overrespond. This is what the paper is about, which is to provide
a dynamic setting. Why is it important to study the dynamics of discrimination? In economics, there are
two types of ways to model discrimination: one is to think of them as
preference-based, the other one is belief-based. Sometimes they're also called taste-based discrimination versus statistical
discrimination. In a static setting, it's difficult to identify
the source of discrimination. Well, what's a preference
based discrimination? Suppose you know perfectly well the nutritional
content of broccoli. There's no more information
that we can provide you to get you to know
broccoli better, but you still don't like it. That's what we call
taste-based discrimination. No amount of new information
could change your mind; you just don't like it. Whereas belief-based
discrimination or statistical
discrimination is based on your beliefs about, let's say, the productivity or the quality of products of
certain types of workers. You might form your beliefs
based on what you read, and the people you
are in contact with, and those beliefs
might not be accurate. As you experience more
people of different kinds, you gain new information and
you update your beliefs. Your posterior might change. Sometimes we look at if we cannot decide whether a discrimination is belief based or
preference based. We can look at the dynamics. For instance, if we
observe a reversal then it is fairly clear that this is
belief-based discrimination. Why is it important to
differentiate between the two? If discrimination is
preference-based, then no amount of information can change someone's beliefs. You can change someone's beliefs. You can't change that
person's preferences, whereas beliefs are
flexible in the sense that you can update based on
the information you have. In the belief-based
discrimination, we also look at whether your prior beliefs is
biased or accurate. It turns out that that
makes a difference. The paper itself has
a theoretical model. In this type of dynamic model, discrimination at one
stage can be functional for or precursor to discrimination
at different stages. For instance, we
just talked about similar empirical
studies reaching different conclusions.
Here's another one. Williams and Ceci conducted a resume study where they sent fake resumes for applications of assistant professor positions for two faculty members
for evaluation. Some are male resumes. Some are female ones. It turns out that people actually systematically favor
the female candidate. Katy Milkman and
coauthors conducted a similar study except that they pose as first-year
graduate students asking for researchers
assistant positions. There the professors favor the male over the
female students. How do we reconcile that? After we discuss this experiment, I think we'll have a way to reconcile these
different results. In this study, they use three
different data sources. One is the field experiment
that they conducted. They also use
proprietary datasets from an online Q&A site
which they did not reveal, but I think once we start to describe the
reputation system, you'll probably be able
to infer where it's from. They also used observational data from their experimental setting. They used a online
mathematics forum. The researchers themselves, or through their
research assistants, posted questions and answers from accounts with male
and female usernames. Other users on the forum
can vote on the posts. The reputation is
publicly observable, and these are aggregates
from past votes. How do you know whether there is gender discrimination
on the site? If the content posted to male or female
accounts are similar, but they receive
different treatments, you know that there are gender discrimination
on the site. Here's an example
of what it's like. Here's a math question. You can see the number of
upvotes and net of downvotes. You can also see the
account formation. You know that this
is a female name, Molly, and you can also see
the reputation of that user. In this particular
case, it's 186 upvotes. In this particular setting, what is the purpose of upvotes? Upvotes are used to reward
high-quality posts. They translate into reputation, which can unlock privileges, including editing, commenting, moderating, and posting bounties. This should sound familiar. The field experiment is on the dynamics of discrimination. How do they impose the
experimental control? They exogenously vary the
reputation of question posters. Reputation is a signal
of past performance, and therefore it's a
signal of ability. The interpretation of reputation depends on the beliefs
about other evaluators. If females face higher
initial threshold to receive upvotes than males, then how does that affect
discrimination of future posts? They manipulate the
subjectivity of judgment, which theoretically
corresponds to the uncertainty
over the quality of posts by comparing discrimination for questions and answer suppose. The idea is questions
when you upvote, this is a good question, this is an interesting question. There is more subjectivity
in it than the answer. Because it's a Math forum, usually in math the answer
is either correct or not so there's less subjectivity. The experimenters chose
the setting because it's an important resource for men and women in stem fields. It's a large forum with the large database and it is a controlled and
anonymous setting. The researchers built
their reputations on 140 accounts until the
reputation score are above 100, and that put these accounts at the top quartile of the distribution in
terms of reputation. Once they reach that reputation, they randomly reassign the
usernames in the sense that 35 male accounts were renamed to female
names and vice versa. This is one feature about this website that's interesting that allows this flexibility. Then they posted 140 questions on accounts with high reputation. These are some of the details
of the method on they post two questions per hour between 5:00 PM and 10:00
PM Monday through Thursday, and collect data in the seven-day window
for each question. The data were collected in raw form and also
bad by screenshots. The theoretical prediction is that at no reputation when
these accounts were newbies, so we'll represent newbies, women face discrimination
because in math there is this stereotype
at least in North America, that on average, men are
better in math than women. They anticipate that
with no reputation, women faced discrimination and male accounts would receive more upvotes than female
accounts for posted questions. Remember the questions
were randomized. What's important
is the interaction between gender and reputation. If it is preference based, you should expect no effect of reputation on discrimination. However, if it is belief based, you would anticipate
that reputation were mitigate discrimination
and if it's belief based with
bias which means that the initial beliefs
were inaccurate, then you would anticipate
that reputation reverses the direction
of discrimination. In other words, if women
face discrimination at the beginning, with reputation, men would face discrimination towards the high
reputation accounts. However, the model
doesn't predict how reputation affect
the levels of upvotes. Here's the first
empirical results, this is the no reputation case. The dark bar represent changes in reputation
for the male accounts, and the light one
represent female. If you look at the changes
in reputation and the arrow bars that men gain more
reputation compared to women, even though the questions that they posted were randomized. This is the histogram which gives us the distribution of changes in reputation and what you see is a fairly big bar for the
female accounts between 0-5. More women receive the lowest
upvotes compared to men. There are significant
discrimination at the initial stage and the
question is what happens when they accumulated
reputation at high reputation? In fact, it's reversed. At high reputation here
is again the changes in your reputation and the
light bar is higher, which means now women will gain more upvotes compared to men. This represent discrimination against males with reputation. Here on the right-hand
side on the right panel, you will see that for males, the accumulation of upvotes, there's a fairly large high bar with the lowest 0-5. In terms of regression, this is a simple
specification which looks at the changes
in reputation. Here you have a dummy variable, male and the reputation variable. The interaction term captures the effect of reputation
on discrimination. If you set reputation to 0, the male dummy represent that without reputation when
everybody's in UB, males receive higher upvotes. But with reputation, the
effect is actually reversed. Male at high reputation receive, on average 5.3 fewer
upvotes compared to women. How about downvotes? Downvotes on the website
are fairly rare. But you can look at the
net number of votes, which is upvotes minus downvotes. It turns out that, if you look at the
net number of votes, the direction is the same, and it's also highly significant. In terms of judgment, they could also vary
the subjectivity, which is; Because
it is a Math forum, answers are less subjective,
relative to question. Here are the websites guidelines for upvoting from the forum, for questions you should
ask, is it interesting? Is it important? Is it creative? All of these to some extend, are fairness objective for
the answers is it correct? It's a binary outcome. It's either the correct or not. So examining the answers can enable us to look at
whether discrimination varies with the subjectivity
in judgment of quality. Now they're going
to look at answers. Again. It's a very careful
set of procedures, the RAs working pairs
one RA writes answers, that will be posted on the
website and email them, so the RA who writes the answers doesn't
actually post them. They e-mail them
to the second RA. The second RA receives
the answer assign gender according to a predetermined
randomization procedure, and post the answer. What does that prevent? It prevents the first
story to write an answer for a female account
in such a way that the changes his
or her writing style. Since the first RA is blind, it ensures that the answers are neutral or at least not biased in favor of
one or the other gender. The prediction again is that if discrimination
is preference-based, we would anticipate the same
level of discrimination against females for
questions and answers. If it's belief based, however, we should see mitigation
of discrimination against females for answers
relative to questions. This turns out to be
the case, that is, there is no significant
gender difference found in answers. The summary of the study is, it's a novel experiment design in the sense that it
took two snapshots, and the dynamics
enables the authors to identify the sources
of discrimination, and attributed to beliefs
rather than preferences. The implications of
this study is that, the welfare implications for preference-based versus
belief-based sources, and the other part is that the timing of interventions matter for discrimination
down the road, and so for this type of scenario, if you anticipate that
discrimination is preference-based or there's not much you can do in terms of information
interventions. If you anticipate
that as belief-based, and that people's
beliefs might be biased, it is possible to intervene initially to signal that there is no fundamental
difference in terms of the quality of male
versus female accounts. This also tells us that the design of reputation
systems is not trivial. That it can incorporate
all biases. Something to bear in mind when we use it for our data analysis.