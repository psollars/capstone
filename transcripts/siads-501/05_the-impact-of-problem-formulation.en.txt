I want to talk now for a few minutes about
the impact of problem formulation and why it should matter so much using
the example of college rankings that Cathy O'Neil writes about in chapter three
of her book, Weapons of Math Destruction. It's one of the recommended readings for
this week. So in 1983, US News and World Report,
a weekly news magazine, devised a ranking system for
colleges and universities. It's become quite popular. I imagine many of you have seen it. And now, of course,
quality of a school is a little amorphous. Perhaps what we really care about
is whether the schools create good citizens who contribute to society,
but how would you measure that? So instead we pick proxies like SAT
scores of the entering students, the student teacher ratio,
acceptance rates. Later they added other things like how
much money gets spent on facilities. Of course, the schools that
finish high in the rankings, they don't complain too much. But if you're ranked 27 as Michigan is,
and you think you should really be in the top 20, you might think that they're
not measuring exactly the right things. We think that the ranking system may be
biased in favor of private universities over public universities. So here's the listing of
just the top public schools. Maybe we'll advertise that we're number
four on the list of public universities, but actually we think we belong
at number one on that list. So we're still dissatisfied
with the ranking system. Anyway, regardless of where you are in
the rankings, to maintain your spot you have to try to do well on
whatever the proxy measures are. And you see quite the distorted
set of actions that university administrators are taking now to to
try to do well in those proxies. So as soon as you define these proxies for
the thing that you really care about, this amorphous notion of university
quality, whatever correlation there might have been between, say, SATs for
the incoming class and some notion of the quality of the university, you risk
destroying that natural correlation. Once you have people responding to
the fact that they're getting measured that way. So for example, Baylor University in 2008, they sent out message to
their incoming students, people who had already been admitted, who had already said they
were going to come there, and they asked them,
please take the SAT again. See if you can get a better score. And they did. They raised the average across all of
the students in the freshman class from the 1200 that they
had initially to 1210. It's not a huge jump, but it's enough to make the school look
better in the US News rankings. Of course, the set of students who they
attracted, that didn't change at all. They didn't attract stronger students. They just got higher scores for
the same students. So we would call this gaming the system or
gaming the proxy. So the conclusion here is that if
you choose outcome proxies for the outcomes that you really care
about beware that they may be gamed. Here's another example from Cathy O'Neil. And here I'll quote exactly from page 55. Let's say a website is looking
to hire a social media maven. Many people apply for the job and they send information about the various
marketing campaigns they've run. But it takes way too much time to track
down and evaluate all of their work. So the hiring manager settles on a proxy. She gives strong consideration to
applicants with the most followers on Twitter. That's a sign of social media engagement,
isn't it? Well, it's a reasonable enough proxy. But what happens when word leaks out,
as it truly will, that assembling a crowd on Twitter is
key for getting a job at this company? Candidates soon do everything they can
to ratchet up their Twitter numbers. Some pay 1995 for a service that populates
their feed with thousands of followers, most of them generated by robots. As people game the system,
the proxy loses its effectiveness. Cheaters wind up as false positives,
end quote. I'll see you in the next video with
a summary of some maxims and questions for the problem formulation stage.