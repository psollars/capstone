In this video, we're
going to see how instrumental variables can
identify treatment effects, when we make the assumption that the effect is the
same for everybody. To review, the basic idea behind the instrumental variables approach is that the treatment is affected by some
unobserved confounders. While this is a problem
for causal identification, we do have an instrument
that replaces the treatment. The instrument affects
the treatment, but it has no effect
on the outcome, except for its effect
through the treatment. We can think of the instrument as causing a chain reaction. The first link A, is the causal effect of the
instrument on the treatment. This is called the first stage. The second link, B is
the one we're after. This link connects the
treatment with the outcome. We cannot directly estimate B, because the variation in the
treatment is endogenous. Endogenous means that
the variation is tied to some variables
that affect the outcome. However, because some of the variation in the treatment
is due to the instrument, which is randomly assigned
and therefore exogenous, we can capture the causal effect of the treatment on the outcome. Exogenous means that
the variation is unrelated to all other variables that might affect the outcome. Of course, we have to assume that the exclusion
restriction holds, that is, that the instrument itself doesn't have a direct
effect on the outcome. Another way to think about
this is that we can split the treatment variation into an exogenous and endogenous part. IV seeks to isolate the variation in the
treatment that is exogenous. Because this variation is
unrelated to any confounders, it allows us to study the causal effect of the
treatment on the outcome. Let's write down a
causal model for Y, with constant treatment effects and an unmeasured confounder. The equation is Y equals
Alpha plus Tau times D plus Gamma times U plus v. D
is our treatment variable, Tau is the treatment effect that they would like to estimate, U is the unmeasured confounder
and v is the error term. We assume that the treatment is uncorrelated with the error. If we measure the confounder, then we will be able to
estimate the treatment effect. In other words, if
U were observed, we will be happy to include
it in our regression model. The problem, as always, is that we don't observe U, so we have to work with the short version of
this regression model. But the short regression doesn't identify the causal effect, because the treatment D, is correlated with the error
of the short regression. Here's where the
instrument comes in handy. If the instrument satisfies independence and
exclusion restriction, then we know that Z is uncorrelated with any
other determinants of the outcome variable. This is like saying
that the covariance of the instrument and the error in the short regression is zero. It's again, the
version of the CIA, the conditional
independence assumption, that we have seen
in previous videos. With the instrument in hand
and a little bit of math, we can calculate the
treatment effect. We start with the covariance between Y and the instrument Z. Then we replace Y with the terms on the right-hand
side of the regression model, we saw on the previous slide. The next step is to split up the covariance into
different parts. Two of those new
covariances are zero. Now we can easily solve for
Tau, the treatment effect. After rearranging
terms, we can divide the numerator and the denominator
by the variance of Z. This is useful because it's usually easier to think in terms of regression coefficients
than in terms of covariances. The numerator is simply the regression
coefficient of Y on Z. We call this the reduced form. The denominator is the
regression coefficient of D on Z, our first-state. This formula also shows you why the first stage cannot be zero, which is something you
can check in the data. If we would divide by zero, we will get an infinite value
for the treatment effect, which is not really informative. Note that in practice, we would use the sample
analogues of the covariances and variances to obtain an estimate
of the treatment effect. With the binary instrument, which is typical for experiments with an
encouragement design, the IV estimator reduces to the ratio of simple
differences between groups. The reduced form is
the difference in average outcomes
between those who were, and those who were not
offered the treatment. At the first stage
is the difference in average treatment status
between those who were, and those who were not
offered the treatment. In other words, the treatment effect is
simply the effect of the instrument on the outcome divided by the effect of the
instrument on the treatment. Intuitively, what we
do here is to adjust for the fact that not everyone is actually getting
the treatment. In principle with a
binary instrument, we don't even need
to run a regression to get an estimate of
the treatment effect. Now, this is not entirely
true because we usually would also like to get a measure of the precision of
our point estimate. That is, we would like to have the standard error associated with our estimate of
the treatment effect. For this, we need to use a method called two-stage least
squares or 2SLS. Now, we will come back to that
in one of the next video. Let's first apply
this IV estimator to an example mentioned in the
mastering metrics book. One of the authors of
the book, Josh Angrist, studied the question
of whether attending a charter school has a positive effect on
academic achievement. Charter schools are
tuition-free schools of choice that are publicly funded
but independently run. To study the benefits
of charter schools, the researchers use
data from one of the most widely replicated
charter models. The Knowledge is Power
Program or short KIPP. KIPP is a network of public schools that develops
curriculum materials, trains teachers, and centralizes some of the
administrative functions. The goal of KIPP is
to help kids from low-income families
prepare for college. KIPP schools emphasize
math and reading skills and encourage students
a strong work ethic. The school days at
KIPP schools are also typically longer than
at regular schools, and children have to follow
stricter behavioral rules. KIPP schools have often be central in the
debate over whether schools alone can substantially reduce racial achievement gaps. Support has point out the positive achievement effects compared to nearby schools. But critics argue that the apparent KIPP
advantage simply reflects the fact that KIPP
attracts families whose children are more
likely to succeed anyway. Now, what makes KIPP
schools ideal to study with instrumental variables
is that they assigned seats by lottery system. This is because there
are more children who applied to the schools than
the schools can accommodate. This is an experiment with randomized
encouragement design. You cannot force
applicants to attend KIPP, some are offered the seat, but nonetheless choose to
go to different schools. Other applicants might
lose the lottery, but they still somehow
find a way in, for example, because
their siblings are already in that school. This is a case of imperfect compliance with
the treatment assignment. But we have a source
of random variation that affects the
treatment, the lottery. Since the lottery is a
truly random mechanism, the independence
assumption is satisfied. To be sure that winners and losers are similar on average, we can nonetheless
check for balance in pre-treatment outcomes
and background variables. Let's do that now. Covariant balance by offer
status looks indeed good. The second column here reports averages for KIPP
lottery winners, and the third column shows the difference in means
between winners and losers. Winners and losers are about equally likely to be Hispanic, or black, or poor enough to
qualify for free lunches. We can also check for balance in pre-treatment outcomes that is test scores in fourth grade which is prior to
KIPP enrollment. These test scores
are standardized by subtracting the
mean and dividing by the standard deviation
of scores in the population of
Massachusetts fourth-graders. Thus, math scores are measured
in standard deviations. We see relatively small and insignificant
baseline differences in test scores between KIPP
lottery winners and losers, so these differences are
most likely due to chance. The exclusion restriction
says that there is a single channel for which the instrument affects outcomes. Here, the exclusion
restriction means that the test score differential
between winners and losers is attributable solely to the win-loss differences
in attendance rates. While the exclusion
restriction is not testable, it's plausible that the
assumption is satisfied. It's rather unlikely that winning the lottery directly
affects test scores. That is independent
of enrollment. We can further check whether we have a strong first stage. As this table shows, winners are 74 percentage points more likely to attend
KIPP than losers. To recap, we have seen
that the decision to attend KIPP is not
necessarily random. Thus, we have a treatment
with unmeasured confounding. But because there
is a lottery that determines who can attend
KIPP and who can't, we have an instrument
that is random. Because the lottery itself
does not affect test scores, we can be confident that exclusion restriction
is satisfied. Moreover, as we've just seen, we have as a relatively
strong first stage because lottery winners are much more likely to attend KIPP. Now that we have checked
the three assumptions, we can estimate the
average treatment effect of KIPP attendance
on test scores. Here, we focus on math scores. The offer of a seat
at KIPP boosts math scores by 0.36
standard deviations; a relatively large gain. This is the reduced
form estimate that is the effect of the
instrument on the outcome. Winning the lottery increases attendance rates by about
74 percentage points. This is the first
stage estimate that is the effect of the
instrument on the treatment. Dividing the former by the
latter yields an estimate of the causal effect of 0.48
standard deviations. This is the average effect of attending KIPP on math scores. Note that we have assumed that the treatment effect is
the same for every person. This is not necessarily true. Children likely differ in the extent to which
they benefit from KIPP. For example, it could be that for those with a supportive
family environment, the choice of KIPP versus some other public school
matters very little. For others, KIPP attendance
may matter a lot. We estimated the causal
effect based on children whose enrollment status was determined solely by the lottery. This may be exactly
those children who benefit a lot
from attending KIPP. In the next video, we will relax the assumption of constant treatment effect and allow for individuals to have different treatment effects.