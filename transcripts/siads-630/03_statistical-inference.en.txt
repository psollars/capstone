In this video, we're going to talk about statistical inference. The aim of statistical inference is to make statements about the population of interest using a sample of data
from the population. We're often interested in understanding something
about the wider population. For example, this could be the average health of
the US population or the causal effect of
health insurance on people's health among those who can't get health insurance. As it's often not
possible to collect data on the entire
population of interest, we have to rely on samples
of the population. In fact, we often
observe only one sample. So if we took another sample, the results would almost
certainly look different. What this means is that there is uncertainty in our results. Statistical inference is about quantifying
this uncertainty. In other words, we are trying
to understand how much our results would change
if we took another sample. Statistical inference
involves three main steps. First, we estimate
the population value, such as the causal effect of
health insurance and health. Second, we estimate the precision of our estimate, that is, we calculate the
standard error of the estimate or its
confidence interval. This gives us, for example, a range of plausible
values for the effect of health insurance on
health, and third, we do a hypothesis test to
calculate the chance or probability of getting a result more extreme than
the one we observed, assuming the null
hypothesis is true. So hypothesis testing gives
us a sense of whether our estimate is reliable or more likely the
result of chance. Causal effects are defined as the difference between
two states of the world, such as the difference in a person's health with and
without health insurance. One parameter that is of particular interest is the
average treatment effect. It is the average
change in outcomes if everybody were to go from
untreated to treated. So the average treatment
effect is simply the average of the unit
level treatment effects. But just like individual
treatment effect, we cannot calculate the
average treatment effect because we're missing
counterfactuals. We wouldn't need two
outcomes for each person, but we only observe one. While we cannot calculate the
average treatment effect, we can get an estimate of this population
parameter and this is what we will spend a
lot of time trying to do. As mentioned in the
previous video, the average treatment effect
has also some limitations. For example, it doesn't
tell us anything about who has a positive or
negative treatment effect. It doesn't even tell us
whether the majority of people have a positive
or negative effect. But that's usually
the best we can do. Besides the average
treatment effect, there are other
average causal effects that could be of interest to us. For example, we
might be interested in the conditional
average treatment effect. This is the average
causal effect for a particular subgroup
in the population, such as women or
low-income individuals. So when estimating the conditional average
treatment effect, we focus on people who have a certain value of
the covariate x. A third parameter of
interest is called the average treatment effect
for the treatment group. This is a mouthful,
but let me explain. It is the population
average treatment effect for the group of individuals
who receive the treatment. Now note that the average
treatment effect and the average treatment
effect on the treated are usually not the same. This is because
the parameters are based on different segments of the population and just like
other treatment effects, we cannot know the true value of the average treatment
effect on the treated or the conditional
average treatment effect, because this would require us to have two
observations per unit, but we only observe one. As mentioned at the
beginning of this video, we typically do not have data on the entire
population of interest. What we can do
instead is to create a sample that mimics the characteristics
of the population. The best way to achieve this
is to draw a random sample. Random sampling means
that every possible set of x individuals is equally
likely to be selected. For example, if our
population consists of ten people and we randomly
select one person, then there are 10
possible samples and all are equally likely. The sample average
will likely vary from one sample to the other, depending on who ends
up in our sample. However, the expected value of the sample average is equal
to the population average. So the concept of mathematical expectation plays an important
role in what we do, and so now it's time to
define it more formally. The expectation of E of Y refers to the expected value
of a random variable Y. Mathematical
expectation is closely related to the concept
of probability. Expectations are the
weighted average of all possible values
that Y can take on with weights given by the probability this values
appear in the population. For example, imagine
rolling a die. You know that the
expected outcome of a single die roll is 3.5, but how do you know this? Well, the possible outcomes
of a die roll are 1, 2, 3, 4, 5 and 6 and each outcome has a
probability of one-sixth. So the average is
one-sixth times 1, plus one-sixth times 2 and so on, and so this gives us the 3.5. Now instead of rolling a die, think about the Y's
as the outcomes of everyone in the population from which our sample is drawn. The expectation of Y is there is nothing else than the
population average. The expectation of Y
is a single number, so we call it a parameter, a characteristic
of the population. For a given population, there is only one
expectation of Y, while there are many
sample averages of Y, depending on how we choose the sample size and just
who ends up in our sample. Random samples have
some nice properties. As mentioned on the
previous slide, the expectation of the average of a random sample is equal to the average
in the population. We now know that the average in the population can also be
written as expectation. So the expected value of
the sample average equals to the expected value
in the population. The sample average in one
sample might be too big, but in other samples, it will be too small compared
to the population average. The sample average in one
sample might be too big, while in other samples, it will be too small compared
to the population average. Unbiasedness tells us that these deviations are not
systematically up or down. So if we were to draw infinitely many
random samples then the average of the
sample averages will equal the population mean. Note that unbiasedness holds
for samples of any size. So now, what can we do with this? Well, if we take a random
sample from a population, say everyone who has
health insurance, then we know that in expectation, the sample average of the insured corresponds to the average of
everyone who has insurance. Sometimes our attention
will be focused on the expected value
within a subgroup, such as when we want to estimate the conditional
average treatment effect. Conditional expectation
is the population average for a specific sub-population. Sub-populations can be
defined in terms of individual background
characteristics such as a person's gender or income, but we can also think of sub-populations in terms
of treatment status. Now, this can lead to more
complicated expressions. For example, the expectation of Y_1 given that D equals zero, denotes the expectation of
the potential outcome under treatment when the
person is selected at random from those
who are not treated. So why we will never observe Y_1 for
untreated individuals, we can imagine it. Random sampling ensures that in expectation, a sample statistic, for example, the sample mean is equal to the corresponding
population parameter. But that doesn't mean we can
expect the sample mean to be bang on with the corresponding
population parameter. It will almost certainly deviate from the population mean. So, how can we bring the sample mean closer to the
corresponding population mean? The answer is by increasing
the sample size, and this is because of
the law of large numbers. To see the Law of Large
Numbers in action, consider the following example. Suppose our population
of interest consists of green and
purple individuals. We know that there are three times as many green people as they are purple individuals. In other words, 25 percent
of the population is purple. Random sampling says that, if you select one
individual at random, then the probability that
she's purple is 25 percent. So if we repeated the
process many, many times, then we will get 25 percent of purple
individuals on average. However, each time
we draw a sample, the person will be
either purple or green. So the sample is not very representative of the
underlying population. Now, what happens is, instead of selecting one person, we sample groups of two individuals and we
do it say 1,000 times. Most of the time, we will get groups
where both individuals are green as shown on
the right-hand side. So again, these samples are not very representative
of the population. What about groups of size 4? So let's suppose we draw
1,000 samples of size 4. Now, the most frequent
samples are the ones with one purple and
three green individuals. So we're more likely to get a sample that closely resembles the
underlying population. Now, here you can
see the distribution of drawing samples of size 8 and here is the distribution
with groups of size 100. As you can see, as we
increase the sample size, the sample looks more similar
to the full population. Here we have sample
sizes of 1,000. So if a sample is large enough, we can bring it close to the population from which
the sample is drawn. The main purpose of
statistical inference is to describe the sample to sample
variation associated with, for example, sample averages. Understanding this variation is important so we
can understand how much our random sample tells us about the
underlying population. If this variation is large, then we are less certain what the true population value is, but if it's small, then we can be more
confident that our estimate is close
to the true value. So statistical inference is about quantifying the
uncertainty in our estimates.This
variation is captured by the sampling distribution. Make sure not to confuse sampling distribution with
sample distribution. Sampling distribution
is, for example, the distribution of sample
means from repeated sampling. In contrast, the
sample distribution is the distribution of individual observations
in the sample. In what follows, we will
discuss concepts of statistical inference
using the population mean as the parameter we
are trying to estimate. However, these concepts apply to the estimation of any
population parameter, such as the average treatment
effect or regression slope. First, we need a metric to quantify the variation
in the distribution. We call this the variance. The variance is the average squared deviation from the mean. For example, the sample variance in the sample of i units is the sum of the squared
deviation from the sample average
divided by n minus 1, with n being the sample size. We divide by n minus 1 rather
than n because estimates of the sample variance tend to underestimate the
true sample variance. Estimates are
typically denoted by the hat symbol to indicate
that these are estimates. The corresponding
population variance simply replaces averages
with expectations. To keep the measurement unit the same as the underlying data, we typically work with the
square root of these numbers, and we call this the
standard deviation and denote it by the
Greek letter, Sigma. Here's an example. Let's say we want to know
the average health status in a population of
2,000 UMSI students. Health in this case is
measured on a scale from zero, with close poor health to 100, which means excellent health. Now, suppose we have data on the entire population
of interests, that is all students who're
currently enrolled at UMSI. So we know the true value
of the population mean, our parameter of interest. Note that we rarely have data on the entire population
of interests. This is just an example. Now this graph shows the
distribution of health in our population of
2,000 UMSI students. The true population mean is 50, denoted by the Greek letter μ. That's what we're going to try to estimate using a random sample. The population standard
deviation here is 15. So now let's draw a
sample and see how close the sample mean gets to
the population mean. So we first need to draw a
sample of say, 10 students. The health status of
these 10 students is 66, 62, 35, and so on. Next, we can ask how close the sample mean
is to the true value. Remember, the
population mean is 50. Now if we average over
these 10 observations, we get a sample mean of 52.8, which is not so far off
from the true value. So the difference
between sample mean and the true population mean is due to random sampling variation. In expectation, the sample mean will correspond
to the population mean. But each sample mean will
be off by some margin, and now what we want to do is to quantify by how much on average. If we repeat the random
sampling process, say 500 times, then we get
a sampling distribution. All sample statistics,
that is point estimates of unknown population parameters have sampling distributions. The spread of the
sampling distribution is called the sampling variance. It tells us how the sample mean will vary about
the true population mean. So it gives us an idea of the uncertainty in
our point estimate. As mentioned before, in practice, we often work with
standard deviations rather than variances. So the standard deviation of
the sample mean is called the standard error of the mean
or short, standard error. The standard error
tells us how far the typical estimate is away from the actual
population parameter. In other words, it describes the typical error or precision
of our point estimate. The formula for the standard
error of the mean is Sigma, which is the population
standard deviation divided by the square root
of n, our sample size. So with larger samples, that is, we have more data, we get a smaller standard error. In other words, there
will be less dispersion. The standard error
is a function of the standard deviation
of the underlying data. Now, the problem is that
we typically don't know this number because we don't
have the corresponding data. So we need an estimate of the population
standard deviation. It turns out that the sample
standard deviation is a good proxy of the population
standard deviation. To make the distinction clear, we use the hat symbol
for the sample version. Now remember that every
point estimate we will discuss has an associated
standard error. Formulas for standard errors can get more complicated
than for the mean, but the idea remains the same. It's important to
keep in mind that standard deviation is not
the same as standard error. The standard deviation
is a measure of the variability of
individual values. In contrast, the
standard error is a measure of the variability
of the point estimates. In this graph, the dark gray bars represents the distribution
of individual values, whereas the light gray bars represent the distribution
of the sample means. But the two distributions
have one thing in common, if we were to repeat the sampling process an
infinite number of times, then the mean of the
sampling distribution would equal to the
population mean. So as we discussed earlier, this is the
unbiasedness property. Now that we have described the measure of
variability, that is, how much we expect our estimate to vary
from sample to sample. We can get a better understanding
of how much our results may differ if we would
draw a different sample. So one thing we could
do is to estimate a range of plausible values for the parameter of interest. This is also known as
the confidence interval. For example, the 95 percent
confidence interval is defined as the mean plus
or minus two standard errors. Standard errors can also be
used for hypothesis testing. Hypothesis testing
allows us to assess whether the observed value
of our point estimate could be due to chance
or whether it is likely to replicate if you
were to repeat the process. In our example, hypothesis testing allows
us to answer the question, what is the probability of getting a sample mean as larger, even larger by
random chance alone, assuming that the null
hypothesis is true? This probability is
estimated using a p-value. P stands for probability. The null hypothesis is our
benchmark, for example, our belief about the
population mean or that the treatment has no
effect on the outcome. Hypothesis testing
involves three steps. First, we need to state
the null hypothesis. For example, the mean takes on a particular value or there is no difference between two rips. The null hypothesis is often the opposite of our
research question. Not that we can
never prove whether a particular hypothesis is true, we can only try to reject it
with a certain confidence. The second step is to calculate a test statistic based on
the observed sample data. Finally, we need to
calculate the p-value and evaluate the hypothesis
in light of our p-value. Now, let's explore hypothesis
testing using an example. Suppose we don't know
the health status of the entire population
of UMSI students. Instead, we have health data
on a random sample of say, 30 students for which we believe the true
population mean is 50. So the population mean of 50 is our working hypothesis,
the null hypothesis. The alternative hypothesis
is that the mean is not 50, it's either higher or lower. Using our sample data, we can calculate the sample mean, which in this case is 57.6. The estimated standard
error of the mean is 2.7. Now we can ask, assuming that the null
hypothesis is true, that is that the
true average is 50, what is the probability
that we observe a value of 57.6 or higher? A common statistical
procedure to test this hypothesis is the
t-test to be more precise, here it's a one-sample t-test. We can use the t-test when
the sample size is below 30 or when the population
standard deviation is unknown. The associated test statistic
is constructed as follows. It's the difference between the sample mean and
the hypothesized mean divided by the standard
error of the sample mean. So if we plug-in the numbers now, we obtain a t-statistic
of about 2.8. Now, all we need to do is to transform this number
into a probability. The t-statistic has a
sampling distribution that is very close to a bell-shaped
normal distribution. As you can see,
the t-distribution in red is similar
to the bell curve, that is the standard
normal distribution shown here in blue, but it has heavier tails. According to this distribution, we expect absolute t values to be larger than roughly two, only about 5 percent of
time just by chance. So if, as in our case, the t value is larger than two, we say that the sample mean
is significantly different from the value under the null hypothesis
which here is 50. In other words, the
probability that we got such an extreme result just
by chance is very small, it's less than 5 percent. The plus minus 2.05 is called the critical value and depends on the number of degrees of
freedom, sample size. You can look up the
critical value in the table or let the statistics
program do the work for you. Here, the p-value associated
with a t-statistic of 2.8 is 0.008. In other words, the probability that we
obtain a t-statistic equal to 2.8 or higher in absolute
terms is 0.8 percent, and so very, very unlikely. In this scenario, we can
reject the hypothesis that the average house status
in the population is 50. Now keep in mind that p-values and also confidence intervals, they say little about the economic significance
of our results. For example, if you find a significant difference
between two groups, it doesn't tell you whether the difference is large or small.