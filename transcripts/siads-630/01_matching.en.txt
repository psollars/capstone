In the previous video, we have seen
that randomized experiments are usually the best way to learn about causality. Randomization ensures
that the treatment and control groups are comparable
on any pretreatment covariate so that any remaining differences
are due to the causal effect. But what if we can't run an experiment for
some reason? Much of the remainder of
this course is about how we can learn about causal effects
when we have observational data. In observational studies, we do not
have control over treatment assignment. As a result, treatment and
control groups are usually not comparable, so we're going to have to work
harder to justify our analyses. The first approach that we
will focus on now is matching. Let's start with the causal question. Is it worth going to a private college, or are we better off
attending a public college? So what's the difference
between the two options? Private colleges are more expensive. Tuition and fees at private colleges are about $20,000
higher per year than at public colleges. On the other hand, private colleges
may be the better schools. For example, private colleges
usually have smaller classes, better teachers,
smarter students, and so on. In addition, private college grads often
have a higher income later on in life. So those who went to a private college
earn about 14% more on average than those who went to a public college. So does this mean that private college
education causes wages to go up? What if we compare the average earnings
of private and public college alumni? Is this an apples to apples comparison? Well, probably not. Private college grads differ in a number
of ways from public college grads. For example, private school
grads have higher SAT scores. They score 120 points higher on average. Private college grads also
come from wealthier families. The income of their parents
is 13% higher on average. So the problem here is that these
covariates may jointly determine school choice and future earnings. For example, students may choose a college
based on where they think they will get in or based on what they can afford, and those factors may also partly
determine the future incomes. So unlike in the experiments, where people are randomly assigned
to treatment and control groups, here people are choosing the treatment
based on their potential outcomes. So we are back to the familiar
selection bias problem. Instead of simply comparing public and
private college grads, we could compare individuals who have
the same value of covariates, for example, SAT scores, but
different values of the treatment. For simplicity, let's assume that
the only things that matter for future income are the SAT score and
the choice of school. What we could do is to take
a private college student and find a public college student that has
the same or a very similar SAT score. Since SAT score is the only thing
that matters besides school choice, the two individuals make a good match. In other words, we use the public
college student's earnings to fill in the missing counterfactual for
the private college grad. Then we can just take the difference
in earnings between the two. And if we repeat the process for all other individuals who
attended the private college, then we get an estimate of the ATT, the
average treatment effect on the treated. So this is the key idea of matching. Now, if we were to do this also for
public college students, that is, we match treated to control and
control to treated, then we can estimate
the average treatment effect. So here is an example of what matching
on the single covariate could look like. We start with our two groups of students
who attended either a private or a public college. In our example, there are five people
who went to private college and eight people who went to a public college. And we also know the SAT scores for
every person here. If we assume SAT scores and
school choice determine future earnings, then we can attempt to find matches
of private college grads and public college grads
with the same SAT scores. Now, suppose that not only SAT scores and school choice determine future earnings,
but also gender. So now we may have a problem. We might not have a control
person with the same gender and the exact same SAT score. So what we typically do in this situation
is to choose a control individual that comes closest to the treated
individual in terms of covariate values. There are different ways to pick pairs,
but it's always the same basic procedure. So first, we need to identify a set
of pretreatment covariates that we believe affect both the outcome and
whether someone takes up to treatment. Then we try to find good matches, that is,
people with similar covariates but different values of the treatment, and
we drop control units that are not match. Finally, we calculate the effect
of the treatment on the outcome in the matched data set. Note that matching has two
important limitations. First, we have to ignore people for
which no acceptable match can be found. But if we begin to drop individuals,
then it's unclear what we are estimating. It becomes the treatment effect
among the matched individuals, which may or may not be something
that is interesting to us. Second, matching is limited to
observable characteristics, since that is all we observe. So matching only solves the problem
of selection on observables. Now, let's review the two key
identifying assumptions for matching. The first one is the conditional
independence assumption. Here the inverse T symbol stands for
statistical independence. So what the assumption means is
that treatment assignment is independent of the potential outcomes
conditional on observables X, such as SAT scores or gender. In other words, we assume that there
are no unmeasured confounders. Selection into the treatment is
based only on observable data. There are many names for this assumption,
and they vary by discipline. For example, in statistics
it's called ignorability, and in epidemiology it's the no
unmeasured confounders assumption. So why do we need this assumption? Conditional independence allows us to
construct an unbiased counterfactual for the treatment group
using the control unit. The CIA assumption is not only used for
matching, but also for other causal identification strategies,
like for example, controlled regression. Note that CIA is not testable because
it requires potential outcomes that we don't observe. So is this assumption plausible? Well, CIA may or may not be a credible
assumption depending on the application. It's hard to defend because it assumes
that we have the exact right covariance. But how do we know that we
haven't forgotten one, or maybe we just haven't
measured it correctly? So this is why it's so important to
know the assumptions that we work with. A second key assumption for
matching is common support. This assumption says that for
each value of the covariant X, there is a positive probability that
there is a treated or a control unit. This is why the assumption is sometimes
also called the positivity assumption. Common support is required so that we
have an overlap between the treated and control units. If there are values of X for
which this assumption doesn't hold, then we have to do some
kind of extrapolation or limit our analysis to regions
where there is an overlap. So unlike the CIA, common support is testable because
it's based on observables. There are two broad types of matching,
exact matching and approximate matching. Exact matching, as the name says,
involves perfect matches. For each treated unit, we need to find the control unit that
has the exact same covariate values. If there are many control units
with the same covariate values, then we can just randomly select one
of those control units to be the match. As an alternative,
we can also take the average outcome of the control units
that are a perfect match. If there is only one match for
two treated individuals, we can use the control unit twice,
but then we have to make some adjustments. That is, use weights to account for
the fact that we use an observation twice. But don't worry too much about this. Statistical programs can
do the matches for you. Now it's time for an example. Imagine we have data on 13 people, some of whom went to a private school
an others went to a public school. What we know about this individuals
is their SAT scores as a proxy for their ability and
earnings after graduation. We assume that conditional on
SAT scores going to a private or public school is as good as random. This is the CIA assumption. So for each private college alumni,
we look for a public college alumni
with the same SAT score. As you can see, we can't find
an exact match for student number 2. So we discard that observation for
the moment. Once we determine the matches, we can get an estimate of the average
treatment effect on the treated. To be precise, it's the ATT
among the matched units since we discarded one observation
in the treatment group. Our estimate of the ATT implies
that attending a private college increases the salary
by $6250 in average. In this example,
a simple comparison of private and public school alumni gives us
a private college effect of $16,500. So quite a bit different estimate. On the previous slide, we decided to
discard student number 2 because there wasn't an exact match in the public
college group if an essay T score of 1250. Let's say we don't want to discard
observations because we already have just a few people who went to private school. So what we can do is to
apply approximate matching. We look for
units that are as close as possible. Since we all have only one covariate here,
the SAT scores, we can use a simple distance metric
like the Euclidean distance. Everything is the same as before,
except that now we have a match for student number 2. Turns out we actually have two adequate
matches. Both students number 8 and number 9 have an SAT score that is just
50 points off from student number 2. So we could just randomly
select one of the two. Flipping a coin, I just determined that
we're going to use student number 9. But now we are using student number
9 twice, once as a match for student number 2 and
once for student number 3. Matching with replacement, that is,
when a single control unit is matched multiple treated units,
it's generally okay. It allows us to find better matches. But as mentioned before,
technically we now have to account for the multiple appearances by giving less
weight to this particular matches. This is because we are relying on
less data compared to the situation where we have different control units for
each treated unit. Now our estimate of the ATT with
approximate matching is $6000, so slightly lower than
with exact matching but still quite different to when
we do a simple comparison. One more thing here, our two samples are not perfectly
balanced in terms of covariant. In other words,
there is a matching discrepancy. The difference in SAT scores
between student number 2 and student number 9 is 50. All other differences are 0. So it's important to check for
covariant balance after the matching and asked whether we can do better. One way to achieve better matching is to
take the average of two possible matches. Remember, we have two adequate control
individuals for student number 2. Instead of randomly selecting number 8 or
number 9, we can just take the average of the two. If we take the average of number 8 and 9,
then the distance measure shrinks to 0. So now the treatment and control groups are perfectly
balanced in terms of SAT scores. In this scenario, our estimate of
the ATT with approximate matching and averaging is $8000, so we're a little closer now to our estimate
using simple differences in means. Note that in these examples we
only looked for matches for treated units, so our results
give us an estimate of the ATT, the average treatment
effect on the treatment. If we were to do the same for
control units, we would obtain an estimate of
the average treatment effect, the ATE. The idea of nearest neighbor matching
is to find the control unit that is closest to each treated unit. So we need some distance
metric to assess closeness. The smaller the distance, the closer
units are in terms of the covariance. But obviously the choice of
distance metric matters because different metrics will
lead to different matches. There are two popular distance metrics. The first one is to normalize
Euclidean distance. The intuition for normalizing the distance
between two data points by the standard deviation of each variable is to account
for the distribution of the variables. For example,
if the covariates that we're using for the matching our SAT scores and parental
income, we need to find a way to make the distances across the two
variables comparible. Say the difference in SAT
scores is 100 points and the difference in parental
income is $20,000. Then standardizing those
distances makes them comparible. Another commonly used distance
metric is the Mahalonobis distance. The Mahalanobis distance also
takes covariances into account. In other words,
if two covariates are highly correlated, then it's easier to get
close in both dimensions. So what we need to do is to give
less weight to their distances. Here you can see the formulas for
the two distance metrics. The normalized Euclidean distance is
just the square root of the sum of the squared distances divided
by the variables variances. The formula for
the Mahalanobis distance is similar, but instead of dividing by the variance,
we use the variance covariance matrix. When there are many covariates, it becomes
more challenging to find good matches. For example, if we may have to match
our college grads based on their age, gender, SAT scores, parental income, and
so on, we can end up in the situation where we have many treated units that
have no acceptable counterparts. So the loss of data decreases
our statistical power and the generalizability of the results. On the other hand,
if we match based on just a few variables, we increase the chance of
omitted variable bias. One way to deal with the curse
of dimensionality is to match on the propensity score. The propensity score method is similar
in spirit to nearest neighbor matching, but instead of matching units
based on many covariates, we match on the probability
of getting the treatment. The idea is that we match individuals
based on a single number, the propensity score. This allows us to use data
on many characteristics without drastically reducing
the number of matches. In the randomized experiment, the
propensity score is known by design and usually the same for all people, say 50%. When we use propensity score
with observational data, we first have to estimate
the propensity score. Propensity score matching is very popular
method, especially medical sciences. One advantage of propensity score matching
compared to regression based approaches is that the covariates are typically
more balanced between treatment and control groups. There are different ways to apply
the propensity score method, but they mostly varying technical details. The general procedure works as follows. First, we need to determine
the covariates and estimate the propensity score using
a probit or logic regression. This is because our dependent
variable is a 0, 1 variable. Second, for each treated unit you need
to find the control unit that has the closest value of the propensity score. Third, we need to check for
covariance balance, while treated and control units are balanced on their
propensity score, it could still be that their underlying covariates differ
systematically within match pairs. Finally, as a last step, we can compute
the within pair differences in outcomes to get an estimate of
the average treatment effect.