In this first video, we're going to talk
about why it's important to understand causality and why it can be challenging to identify causal relations
in observational data. The first and most intuitive
way to learn about causality is to look
at raw correlations. The problem is, as you
probably have guessed, that correlation
is not causation. Consider the following example. There was once a Pacific
island tribe who believed that having body
lice promotes good health. Now why did they believe this? Well, the tribe
members observe that almost every healthy
person had some body lice, verse many sick people did not. So they observed a clear
positive correlation between having lice and being healthy and this led them to conclude that the
lice infestations must be good for one's health. Of course, today, we know that lice do not cause good health. It's the other way around. It's being sick that causes lice to seek a new
healthier host, because hey, lice are not stupid. They prefer a healthy
cooler body to sequence. The idea that correlation does
not imply causation is so widely understood now that the expression has
almost become a cliche. Yet it is still common for people to interpret
correlations causally, such as when we see
attention-grabbing headlines about the research study. For example, CNN recently
reported about the study suggesting that any amount of running lowers the risk
of premature death. So it doesn't mean
that a little jog every week causes
us to live longer? If so, should we run
for like 10 minutes, half an hour, or
maybe even an hour? Here's another example. The Washington Post reported on the study linking all
soda to an early death. Does it mean that both
sugary drinks and diet sodas have a causal impact on
our life expectancy? If so, how much does the risk of an early death increase compared to, say,
drinking coffee? We often read about
studies on how certain things can make our
lives better off worse. However, these claims are
often based on correlations. For example, it could be that drinking lots of soft drinks is just a marker for an otherwise
unhealthy lifestyle. In other words, perhaps
it's not just soda, but an unhealthy
lifestyle more generally, that causes our
lives to be shorter. Maybe soda has nothing to
do with our health at all, maybe it's something else. News headlines do not
necessarily use to write cause, but we tend to interpret
them in a causal way. It's not just news articles. We have a general tendency
to interpret correlations as causal relationships
as described by psychologists and Nobel laureate Daniel Kahneman in his book, Thinking Fast and Slow. This is largely due to our
automatic thinking mode. It makes us jump to
conclusions far too easily. Now this is not to say that correlations cannot be useful. Correlations can
hint at causation. For example, the reason why we discovered that smoking
causes lung cancer is that we saw correlations
between the number of cigarettes people smoke the day and their health outcomes. What can go wrong when we interpret correlations
in a causal way? Let's use a simple graph
to see what can happen. Suppose we have two
variables, D and Y. D is some activity and Y is
the outcome we care about. Now, assume we observe a positive correlation
between the two variables. We suspect that D causes Y, as indicated by the
directed graph, that is the arrow. But does D actually
cause a change in Y? First, the two
variables might just happen to be
correlated by chance. For example, the figure here shows a strong
correlation between the divorce rate in
the state of Maine and the per capita
consumption of margarine. As the divorce rate declined between the
year 2000 and 2009, the amount of margarine
consumed during the same time period also declined at almost the same rate. Does it mean that
the consumption of margarine causes
couples to divorce? Well, probably not. There are hundreds of these so-called
spurious correlations. If you want to see more
funny example like this one, check out Tyler Vigen's homepage. Another possibility for
the relationship between D and Y is that causality
runs the other way, just like we saw in
the lice example. Instead of D causing Y, Y is causing the activity D. Reverse causality is typically
less of a problem though, because the timing of events can help us discern
cause from effect, it gets more
challenging though if there is simultaneity, that is, if D causes Y and Y
causes D. For example, imagine you find that smoking
and depressions are linked, could be that smoking
causes depression and then that depression causes
us to smoke even more. More concerning or situations where there is a
third variable X, a con-founder that jointly
determines D and Y. It is called a
con-founder because it confounds our ability to
discern the effect of D and Y. For example, going back to the study about
soda and health, it could be that as
mentioned before, people consume lots of soda, are also more likely to have
an unhealthy lifestyle. If we don't account for the effects of these third
variables in some way, we will obtain a
biased estimate of the relationship between D and Y. This bias is called omitted
variable bias because we leave out one or more relevant
variables in our model. In the context of causal models, this is often referred
to as selection bias. As people choose the
activity D. But note that the term selection bias can have different meanings depending
on the field of research. Selection bias is by far the most common problem causal inference is
trying to solve. The identification of causal
relations gets really tricky when we don't
observe the con-founder. To highlight the
distinction between observed and unobserved
con-founder, I use the variable U
for unobserved and describe the relationships
with dashed lines. It doesn't have to be that U
is not measurable in theory. It could be that U is just unobserved to the
data scientists. That is, U is not in the data. For example, you could be the exercise habits of the participants in
the Sutta study. While exercising is measurable, it may be that we don't
have it in the data. In reality, there will be many unobserved confounding
variables, not just one. This makes the identification of causal effects so difficult. Now, let us look at an example from the
Mastering Metrics book. Imagine you have the choice between getting health
insurance or not. You can either pay for
health insurance and get quality health care service, or you can remain
uninsured and rely on the emergency room
for your health care needs as they cannot
turn you away by law. The problem is that
emergency department may not be the best place to treat
certain medical conditions such as diabetes or heart disease because ER's are not designed
to provide long-term care. Now, of course, I've greatly simplified the decision problem. For example, not
everyone can afford health insurance and getting health insurance has benefits for society and not just for
you as an individual. But for the sake of illustration, let's assume that decision is a simple trade-off
between whether or not to pay for
health insurance and the quality of health care. Now, suppose there is a
strong long-term correlation between having health insurance and positive health outcomes. We post a question, should we get health
insurance or not? The positive correlation
between health insurance and health may indeed reflect
the causal effect. But the direction of the
association is far from obvious. For example, most Americans get health insurance
through their employers, and bad health may
result in a job loss, and consequently to the loss of insurance reversing the
chain of causation. Alternatively, it could
be that the correlation reflects differences in
who gets health insurance. For example, people who
buy insurance may be less of risk-takers to
begin with and thus, they are less likely to engage in risky behaviors that
could harm their health. Or they might simply be
more concerned about their health and thus adopt
a healthier lifestyle. These are example
of selection bias. All of these hypotheses
could account for the observed correlation between health insurance and
health outcomes. Even worse, it could be the product of all these
factors working together. So why should we care
about causality? Well, identifying the
true cause is important, because each explanation
gives different advice. For example, if the
positive correlation is due to risk of its people being more likely to get health insurance then being insured might not
improve our health. On the other hand, it could be that having health insurance is indeed
beneficial to one's health. So how can we find our
way for such a web of alternative explanations to get to the cause and
truth of the matter. With the rise of big data, new tools such as machine
learning have emerged that help businesses and governments make
data-driven decisions. These tools are useful in
so far as they help us identify trends and
predict what will happen. But machine learning is about
correlation, not causation. These techniques does have a very limited ability to
tell us why things occur. So what is the causal effect of having health insurance
in your health? Think about everything that
could affect your health besides the medical treatment covered by health insurance. The causal effect of health insurance is
the difference in your health when you have
insurance minus your health, when you don't have insurance, holding all those other
variables constant. Thus, the causal effect is the difference holding
all other things equal. The Latin name for it
is ceteris paribus. If other variables change with your health insurance
status, such as, for example, your age, then we don't know what
caused your health to change. Maybe it's your health insurance. Maybe it's your age, or maybe it's something
completely different. So in an ideal world, we would create a clone of you and not give a
health insurance. Then measure you and your clone's health
a few years later. Now, obviously this
is not possible. We cannot just build
a clone of you. In the real world, we either observe you with or without health insurance,
but never both. You cannot simultaneously
be insured of or not. It's just not possible. The fact that we cannot observe a person in both
states of the road that is with and without health insurance is what
makes things so difficult. In other words, we're missing
the counterfactual outcome. Then what would
have happened if we hadn't changed that
one specific aspect. This is called the fundamental problem of causal inference. So causal inference
is essentially the study of [inaudible]. It's about finding ways
to learn about the what would have happened if we hadn't changed that specific aspect. In the insurance example, we will need to find a person or a group of people
whose just like you, but who doesn't have
health insurance. Now as this example illustrates, finding or creating a good comparison
group is challenging. Everything has to be as
similar as possible, except for that one thing. Methods of causal
inference use data and various
assumptions to let us, so to speak, observe the counterfactual,
the unobservable. By doing this, we can make appropriate comparison and
learn about causality.