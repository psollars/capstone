Math methods for data science. Probability review, basic ideas. This set of lectures
will be in two parts. Part 1 will be review
of probability, the basic ideas of probability, addition rules and compliments, conditional probability, and the multiplication rule
as well as Bayes rule. The second part of these lectures will be maximum likelihood, defining what is
maximum likelihood, and in the context of linear
and logistic regression. A probability experiment is one in which we do not know what any individual outcome
will be but we do know how a long series of
repetitions will come out. For example, if we
toss a fair coin, the possible outcomes
are heads or tails. We denote the event
as a script X or Y. The collection of all
possible outcomes in a probability experiment is
called the sample space. For example, a coin toss. The sample space consists
of heads and tails. A six-sided die, the sample space consists
of the numbers 1, 2, 3, 4, 5, and 6. The probability of
an outcome is the proportion of times that the outcome
occurs in the long run. So for a fair coin, that is, one that is equally likely to
come up as heads and tails, the probability of
heads is one-half and the probability
of tails is one-half. The law of large numbers
states that as the probability experiment
is repeated again and again the proportion
of times that the given outcome occurs will
approach its probability. In other words, the proportion
of time something happens is equivalent
to the probability. If a sample space has N equally likely outcomes and
an event A has K outcomes, then the probability
of that event is the number of outcomes
in A over the number of outcomes in the sample
space or K over N. Once we have a sample space
for an experiment, we need to specify
the probability of each event. This is done with
a probability model. Let's write the sample space
for a six-sided die. We have the random
variable Y and all of the outcomes in
our random variable. We can write the probability
distribution which corresponds to the probability
mass of a given outcome. The probability of some events in the random variable Y
is equal to one-sixth, one-sixth, and so on for all of the events as they are equally likely on
the six-sided die. The Kolmogorov axioms, the probability of an outcome
is always between zero and one and the sum of
the probabilities of those entries in
the probability distribution is equal to one. A random variable
X is described by a probability
distribution P sub X. A discrete random variable has a finite sample space where this notation denotes
the number of possible outcomes.
In other words, the probability
distribution of that six-sided die is
a vector of values one-sixth and the number of outcomes inside of
that sample space is six. The probability distribution of a discrete random variable
X in the set of all X random variables is a vector of a certain number of non-negative numbers
that sum to one. If we were to write
this mathematically, we would have P of X in the set of real numbers for
the number of values in the probability distribution such that each entry in
the probability distribution is greater than or equal to zero
for all X's in this set of random variables and the sum of all probabilities of all of the values of X is equal to one. An event is a collection or set of objects in a sample space. If A denotes an event, then the probability of
event A is denoted by P of A. Say we roll our six-sided
die where we have our random experiment with possible outcomes,
one through six, we can define events like
the probability of rolling a one or the probability
of an even number, probability of rolling a value
greater than or equal to three or something like the probability of rolling a value less than
or equal to four. Events can include one or more of the outcomes in
a sample space. When we talk about
the probability of rolling an even number, we're actually talking about the probability that X equals two or X equals four or X equals six. In other words, we can write this as probability that X equals two or probability that X equals four or the probability
that X equals six. This could also be written
as the values 2, 4, 6 as the subset of
the random variable. This U is set notation
for the word OR. The logical AND operator corresponds to
the intersection of sets, often used to describe composite events involving
multiple random variables. If A is any event, the complement of A is the event
that A does not occur. The complement of A
is denoted as A_c. The rule of compliments states
that the probability of A_c is one minus
the probability of A. Two events are said to be
mutually exclusive if it is impossible for both of the events to occur
at the same time. Mutually exclusive events
have no outcomes in common whereas non-mutually
exclusive events have outcomes in common.