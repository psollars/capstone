Math Methods for Data Science,
Optimization, Gradient Descent. After learning some of the basic ideas
behind and components of optimization and learning how to calculate a gradient,
you might be thinking, what's next? Well, we know that the gradient
gives an equation for the slope of the tangent plane at
some point, be it x, y or x, y, z. The vector you have written contains
slopes along each of those different dimensions. We can evaluate the gradient at a given
point say we have this function f(x, y) = 5x y squared minus y squared and
the point (2, 1). The gradient can be calculated as
the vector 5y squared and 10xy- 2y. Plug in the value (2, 1) for x and
y respectively, and we get the vector, [5 18] this is the value of the gradient
at the point (2, 1). Let's look at what these calculations mean
visually, we're at the point (2, 1) and we've calculated the gradients
as 5y squared and 10xy- 2y. We plugged in the value (2, 1) for x and
y respectively and got the vector [5 18]. The tangent plane will
have a slope of 5 in the x-direction and 18 in the y-direction. So, why did we write a vector? The vector will tell us the direction and
magnitude. The direction of the gradient vector will
point in the direction of the steepest increase for the function. The magnitude will give us the slope
of the plane in that direction. Each part of the gradient gives
a slope in one dimension. The magnitude of the gradient vector gives
the steepest possible slope in the plane, and to calculate the magnitude, we find
the length using a squared plus b squared equals c squared or the Pythagorean
theorem where c is the magnitude and a and b are the gradient vector
components at a given points. Let's evaluate the magnitude
given our point (2, 1). We have the vector [5 18] where a is 5 and b is 18 and
we're solving for c. Plugging this into the Pythagorean
theorem, we have 5 squared plus 18 squared equals c squared or 25 + 324 = c squared. And so we have c = 18.682. Remember that the magnitude of
the gradient vector gives the steepest possible slope of the plane. We just calculated the gradient which is
a vector in the direction of the fastest increase for the function. Steepest descent methods use
negative values of the gradient to find the direction of decrease. Then, the function is minimized
in the direction of the decrease. Steepest descent, say we have
the formula f(x, y) = x squared- 2x + 3y squared- y from
an initial point of (3, 2). First we find the gradient
at the point (3, 2) by using partial derivatives
with respect to x and respect to y. Our gradient will be 2x- 2 and 6y- 1. Plug in the value (3, 4) for
x and y respectively, and we will get a vector [4, 11]. This is the gradient at the point (3,
2) which is the direction of ascent. Use a vector pointing in
the opposite direction [-4 -11], we now need to find
the coordinates of a new point. We will use vector translation
which takes our old point plus some scalar times a vector
to create our new point. So our new point will equal our old [3 2] plus some scalar, times our descent vector, in other words, our new point Will be 3- 4a, 2-11a, where a is some scalar also
known as a learning rate. A learning rate is a hyperparameter
that controls how much we are adjusting the weights of our network
with respect to the lost gradient. The lower the value, the slower we
travel along the downward slope. While this might be a good idea, using a
low learning rate in terms of making sure that we do not miss any local minima,
it could also mean that we are taking a long time to converge especially
if we get stuck on a plateau region. Let's take our original equation and plug in our new point, f(x, y) = (3- 4a) squared- 2(3- 4a) + 3(2- 11a) squared- (2- 11a). We would then minimize f(a),
substitute the minimized value into the original function to get
the coordinates of the new point. Finally, we repeat this until one or
a combination of condition is met, either a certain number of times or
iterations a low enough value of the gradient, the gradient will
approach 0 on its way to a minimum. A small enough change in the vector or a small change in the function values
between an old and a new point. To summarize what we just did,
basically we just found the vector of steepest ascent,
flipped it to get the vector of decent, created the cross-section along
the vector at a given point, and then minimize the function
along that cross-section. What could possibly go
wrong with this method? The method could take a long time to
converge to 0, either the function could be extremely flat around the
minimum, there could be saddle points or a complex surface, or the learning
rate could be too small or too big. To solve some of these problems,
there are alternate methods. There are multiple types of gradient
descent methods including steepest descent, general case, convex case,
general cases with line-search methods, and conditional gradient methods. The details of which are beyond
the scope of this course. There are also other optimization
algorithms that build on gradient methods, first order optimization algorithms
minimize or maximize a loss function using its gradient values with
respect to parameters. It tells us whether the function is
increasing or decreasing at a point, and gives us a line or plane which is
tangential to the point on the surface. Second-order optimization algorithms use a
second order derivative aka a Hessian and also gives quadratic surfaces that
touch the function of the errors. There are also other types of
optimization, adadelta, adagrad, Adam, conjugate gradients, BFGS,
momentum, nesterov momentum, root mean square prop, and
stochastic gradient descent. I want to show you a comparison of
several optimization algorithms so you can see how different algorithms
find the minimum on a surface. The minimum value of this
topography is at the gray star, and we're comparing stochastic gradient
descent in red to other methods. We can see that the adaptive
algorithms converge very fast and quickly in the right direction in which
the parameter updates should occur to get to the minimum. Whereas standard stochastic
gradient descent, NAG, and momentum techniques are very slow and don't
necessarily find the correct direction. So what am I asking of you? I want you to be able to
talk about regression and classification as optimization. Articulate what goes into
an optimization problem including variables constraints and
objective functions. Define what constrained means,
find a gradient, and calculate the magnitude of a gradient.