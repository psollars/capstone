Hi, and welcome to week
two of 682s readings. Today we're going to be
talking about readings that involve time and the overall data patterns that we see in social media data. Just to refresh, this week
is about visualizing and modeling patterns in social media data and in
the assignment for this week, you're going to load a
large social media corpus. You're going to produce
some summary statistics over that corpus and
then you're going to visualize that corpus
over different dimensions including geographic
and temporal axes. The readings for this week really tap into this and
show in my opinion, what can be done when
you are looking at social media data through the
lenses that you're going to look at social media data in
your assignment this week. I'm going to briefly go
through and kind of orient and set the table for the
readings for this week. In the first reading
for this week, the remarkably insightful
authors have looked at the temporality of
social media data and how that relates to the credibility of events unfolding in social
media platforms. So specifically,
here's a graph from the paper Figure
One that looks at the volume of tweets per
unit time and how that relates to credibility
measurements that are given by crowd workers. One of the reasons I assign this and I think this
is interesting is it's actually a relatively
simple metric to compute. It's not a really
fancy metric but it provides a lot of
information actually about what's unfolding, and that's
one of the things I want you to look for in
the reading for this week. The reading reflection prompt for this one should you choose
it is that you should describe in your
own words how time is modeled in the papers and what did they learn from this author's operationalization of time. That word that's clearly hard
for me to say means how did they compute time and how did they measure it in
a specific way. The second paper is a fun
paper that I really liked from about ten years ago called Tweets from
Justin Bieber's Heart, the dynamics of the location
field and user profile. This paper is all about
how data that are generated by people,
and sometimes we call that user-generated
content, can differ substantially from other types
of data we might be given. An example here is
the location field which you will use in your
assignment this week and how people input data that is not location and is not
a geographic entity. This figure from the table shows a breakdown of
that information. Only, of the data they collected, only two-thirds of
it is valid geographic information
and the others are different types of sarcastic
jokes, et cetera, et cetera. One of the lessons of
this paper is don't treat as perfect data you receive from social platforms and question what you might be receiving. The reading reflection prompt for this week is along those lines. What are some of
the validity issues that are documented
in the Hecht reading? That's the paper I just showed. What are possible ways
something similar could arise in data you either collect or data
that's given to you. If you're coming from, let's say, even a business background or modeling fluid dynamics
you're not going to assume that the fluid
being measured has somehow intentionally tried to corrupt the flow rate data
that you receive from sensors. However, in some cases, in domains like this, you might find that to be true and that's pretty different. Something that's pretty different when
human-centered data are collected and analyzed.