In this part of the course, you'll get
an introduction to the basics of neural networks which are abroad family of
algorithms that have formed the basis for the recent resurgence in the computational
field called deep learning. Early work on neural networks
actually began in the 1950s and 60s. And just recently has experienced
a resurgence of interest as deep learning has achieved impressive state of the art
results on specific tasks that range from object classification and
image is too fast, accurate machine translation to gameplay. The topic of neural networks
requires its own course. And indeed,
if you're interested in more depth, you can check out the excellent course and
course era called neural networks for machine learning by a pioneer in
this area, professor Geoff Hinton. Here will provide an introduction
to the basic concepts and algorithms that are foundation
of neural networks, and of the much more sophisticated deep
learning methods in use today. You'll learn about some basic models
called multilayer perceptrons supported by scikit-learn that can be used for
classification and regression. Let's start by briefly reviewing
similar methods we've already seen for regression and classification. Linear regression and logistic regression,
which we show graphically here. Linear regression predicts a continuous
output y hat shown as the box on the right as a function
of the some of the input variables xI shown in
the boxes on the left. Each weighted by
a corresponding coefficient, wI hat plus an intercept or
bias term be hat. We saw how various methods like ordinary
least squares, ridge regression or less over aggression could be used to
estimate these model coefficients wI hat and b hat shown above the arrows
in the diagram from training data. Logistic regression takes this one
step further by running the output of the linear function of the input variables
xI through an additional nonlinear function. The logistic function
represented by the new box in the middle of the diagram
to produce the output y, which because of the logistic function is
now constrained to lie between 0 and 1. We use logistic regression for
binary classification since we can interpret y as the probability that
a given input data instance belongs to the positive class in a two-class
binary classification scenario. Here's an example of a simple neural
network for regression called a multi-layer perceptrons,
which I'll sometimes abbreviate by MLP. This were also known as
feedforward neural networks. MLP's take this idea of computing weighted
sums of the input features like we saw in logistic regression, but it takes
it a step beyond logistic regression by adding an additional processing step
called a hidden layer represented by this additional set of boxes,
h0, h1 and h2 in the diagram. These boxes within the hidden layer are
called hidden units and each hidden unit in the hidden layer computes a nonlinear
function of the weighted sums of the input features, resulting in
intermediate output values v0, v1, v2. Then the MLP computes a weighted sum
of these hidden unit outputs to form the final output value y hat. This nonlinear function that the hidden
unit applies is called the activation function. In this example, the activation function
is the hyperbolic tangent function which is related to the logistic function. You can see that the result of adding this
additional hidden layer processing step to the prediction model is a formula for y hat that is already more involved
than the one for logistic regression. Now predicting y involves computing
a different initial weighted sum of the input feature values for
each hidden unit, which applies a nonlinear activation
function and then all of these nonlinear outputs are combined using another
weighted sum to produce y. In particular, there's one wait between
each input and each hidden unit and one wait between each hidden unit and
the output variable. In fact, this addition and combination
of nonlinear activation functions. Allows multi-layer perceptrons to learn
more complex functions than is possible with a simple linear or logistic function. This additional expressive power enables
neural networks to perform more accurate prediction when the relationship between
the input and output is itself complex. Of course, this complexity also means
that there are a lot more weights model coefficients to estimate in the training
phase which means that both Training data add more computation are
typically needed to learn a neural network compared to a linear model. As an aside,
there are a number of choices for the activation function in a neural
network that gets applied in hidden units. Here, the plot shows the input value
coming into the activation function from the previous layer's inputs on the X axis. And the Y axis shows the resulting
output value from the function. This code to plot this example is
available in the accompanying notebook. The three main activation functions
will compare later in this lecture are the hyperbolic tangent,
that's the S-shaped function green. The rectified linear unit function,
which I'll abbreviate to relu, shown as the piecewise
linear function in blue. And the familiar logistic
function which is shown in red. The relu activation function is
the default activation function for neural networks in scikit-learn. It maps any negative input values to 0. The hyperbolic tangent function, or 10 H function maps large positive input
values to outputs very close to 1, and large negative input values to
outputs very close to negative 1. These differences in the activation
function can have some effect on the shape of regression prediction plots or classification decision boundaries
that neural networks learn. In general, we'll be using either the
hyperbolic tangent or the relu function as our default activation function, since
these perform well for most applications. Let's take a look at how we use
neural networks in scikit-learn for classification using the more complex
synthetic binary classification data set. To use a neural network classifier, you import the MLP classifier class
from the SK learn neural network module. This code example shows the classifier
being fit to the training data using a single hidden layer with three different
numbers of hidden units in the layer. One unit, 10 units and 100 units. As with all other classification types
we've seen, you can create the classifier object with the appropriate parameters and
call the fit method on the training data. Here are the main parameter for a neural network classifier is
this parameter hidden layer sizes. This parameter is a list
with one element for each hidden layer that gives the number
of hidden units to use for that layer. So here we're passing a list
with a single element, meaning we want one hidden layer using
the number in the variable called units. By default, if you don't specify
the hidden layer size's parameter, scikit-learn will create a single
hidden layer with 100 hidden units. While a setting of 10 may work well for simple datasets like the one
we use as examples here, for really complex data sets the number of
hidden units could be in the thousands. It's also possible, as we'll see shortly,
to create an MLP with more than one hidden layer by passing a hidden layer
size's parameter with multiple entries. I want to also note the use of this extra
parameter called solver which specifies the algorithm to use for
learning the weights of the network. Here we're using the LBFGS algorithm. We'll discuss the solver parameter setting
further at the end of this lecture. Also note that we're passing in a random
state parameter when creating the MLP classifier object, like we did for
the train test split function. And we happen to set this random state
parameter to a fixed value of 0. This is because for neural networks,
their weights are initialized randomly, which can affect the model
that is learned. Because of this, even without changing
the key parameters on the same dataset, the same neural network algorithm
might learn two different models, depending on the value of the internal
random seed that is chosen. So by always setting the same value for the random seed used to initialize
the weights, we can ensure the results will always be the same for
everyone using these examples. This graphic lots the results of running
this code to show how the number of hidden units in a single layer neural network
affects the model complexity for classification. With a single hidden unit, the model is mathematically
equivalent to logistic regression. We see the classifier returns the familiar
simple linear decision boundary between the two classes. The training set score is low and
the test score is not much better, so this network model is underfitting. With 10 hidden units, we can see that the MLP classifier is able
to learn a more complex decision boundary that captures more of the nonlinear
cluster oriented structure in the data. But the test set accuracy is still low. With 100 hidden units, the decision
boundary is even more detail And achieves much better accuracy on
both the training and the test sets. Here's a graphical depiction of
a multilayer perceptron with two hidden layers. Adding the second hidden layer further
increases the complexity of functions that the neural network can learn
from more complex datasets. Taking this complexity further, large
architectures of neural networks with many stages of computation are why deep
learning methods are called deep. And we'll summarize deep learning in
an upcoming lecture for this week. Here's an example in the notebook
showing how we create a two layer MLP with 10 hidden units in each layer. We just set the hidden layer size is
parameter when creating the MLP classifier to a two element list indicating 10
units in each of the two hidden layers. You can see the result of adding the
second hidden layer on the classification problem we saw earlier. On the left is the original MLP with one
hidden layer of 10 units and on the right is the same dataset using a new MLP
with two hidden layers of 10 units each. You can see the MLP
with two hidden layers, learned a more complex decision boundary
and achieved in this case a much better fit on the training data and
slightly better accuracy on the test data. Once we start adding more hidden
layers with lots of hidden units, you can see that the number of weights or
model coefficients to estimate for a neural network can increase rapidly. So that more complex neural networks
could have many thousands of weights to estimate. We can control this model complexity
just as we did with ridge and lasso regression by adding an L2
regularization penalty on the weights. Remember that L2 regularization penalizes
models that have a large sum of squares of all the weight values. With the effect being that the neural
network prefers models with more weights shrunk close to zero. The regularization parameter for
MLPs is called alpha, like with the linear regression models. And in Scikit learn is set to a small
value by default, like 0.0001, that gives a little bit of regularization. This code example shows
the effect of changing alpha for a larger MLP with two hidden layers of
100 nodes each from a small value of 0.01 to a larger value of 5.0. For a variety here, we're also setting the activation function
to use the hyperbolic tangent function. Here's the graphical output
of this notebook code. You can see the effect of increasing
regularization with increasing alpha. In the left plot, when alpha is small, the
decision boundaries are much more complex and variable, and the classifiers
overfitting as we could see from the very high training set score and
low test score. On the other hand, the right plot uses the
largest value of alpha here, alpha 5.0. And that setting results in much smoother
decision boundaries while still capturing the global structure of the data. And this increased simplicity allows
it to generalize much better and not overfit to the training set. And this is evident from the much
higher test score in this case. As with other supervised learning models,
like regularized regression and support vector machines, it can be
critical when using neural networks to properly normalize the input features. Let's apply the multilayer perceptron
to the breast cancer dataset and notice that we first apply the MinMaxScaler
to preprocess the input features. Here, we'll combine a more complex network
using two hidden layers with 100 hidden units each. With a higher regularization
setting of alpha at 5.0 and using the LBFGS solver again. You can see that with this multilayer
perceptron, both the training and test set accuracy are among the highest
we've obtained on this dataset. Like many of the other supervised
learning methods we've seen, you can also use multilayer perceptron for
regression as well as classification. We're including MLP regression here
as an example for two reasons. First, because MLP
regression may be useful for some regression problems on its own. But more generally, because some deep
learning problems are regression problems. And so as with classification, using
multilayer perceptron is a good starting point to learn about the more
complex architectures used for regression in deep learning. Here's the example of a simple MLP
regression model in our notebook. You use the multilayer perceptron
regressor by importing the MLP regressor class from the SK learn
neural network module. And then creating the MLP
regressor object. When creating the object here, we're setting the number of hidden layers
in units within each hidden layer using the same hidden layer size as parameter
that we used for classification. This example uses two hidden
layers with 100 hidden nodes each. This notebook code has a loop that
cycles through different settings of the activation function parameter and
the alpha parameter for L2 regularization. Here we've included regression
results that use in the top row, the hyperbolic tangent
activation function. And in the bottom row,
the relu activation function. You can see the smoothness of
the activation functions somewhat influences the smoothness of
the corresponding regression results. Along the columns, the plots also show the
effect of using different alpha settings to increase the amount of L2
regularization from left to right. Again, as with classification,
the effect of increasing the amount of L2 regularization by increasing alpha is
to constrain the regression to use simpler and simpler models with fewer and
fewer large weights. You can see this effect for
both activation functions in the top and bottom rows. The regression line on the left has
higher variance than the much smoother regularized model on the right. On the positive side, beyond
the simple examples we've shown here, neural networks form the basis
of advanced learning architectures that capture complex
features and give state of the art performance on an increasingly
wide variety of difficult learning tasks. From World Championship play for
the game of go to detailed and robust recognition of objects in images. However, with this increased
power come increased costs. These larger and more complex models
typically require significant volumes of data, computation and
training time to learn. In addition, careful preprocessing of the
input data is needed to help ensure fast, stable, meaningful solutions to
finding the optimal set of weights. In general, neural networks are a good choice when
the features are of similar types. For example, all derived from
the pixels of an image and less of a good choice when
the features are very different types. Finally, let's review the key parameters
for the multilayer perceptron in Scikit learn that can be used to
control model complexity. The main way to control
model complexity for the MLP is to control the hidden
unit size and structure. Using the hidden layer sizes parameter
that controls the number of hidden layers and the number of units within each layer. Alpha controls the amount of
regularization that helps constrain the complexity of the model by
constraining the magnitude of the model weights. Finally, you can experiment with at
least three different choices for the nonlinear activation function
by using the activation parameter. Earlier we saw the solver parameter for specifying the algorithm that
learns the network weights. The solver is the algorithm that actually
does the numerical work of finding the optimal weights. And one intuitive way of visualizing
this process is that all of the solver algorithms have to do a kind of
hill climbing in a very bumpy landscape with lots of local minimum, where each local minimum corresponds
to a locally optimal set of weights. That is a choice of weight setting that's
better than any nearby choices of weights. So across this whole landscape
of very bumpy local minima, some will have higher validation scores on
the test data, and some will have lower. So depending on the initial random
initialization of the weights. And the nature of the trajectory in the
search path that a solver takes through this bumpy landscape. The solver can end up at
different local minimum, which can have different
validation scores. The default solver atom tends
to be both efficient and effective on large datasets with
thousands of training examples. For small datasets like many of
the ones we used in these examples, the LBFGS solver tends to be faster and
find more effective weights. You can find further details on these more
advanced settings in the documentation for scikit-learn.