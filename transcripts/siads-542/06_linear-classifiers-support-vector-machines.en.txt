Let's look at how linear models
are also used for classification, starting with binary classification. This approach to prediction uses the same
linear functional form as we saw for regression. But instead of predicting a continuous
target value, we take the output of the linear function, and apply the sign
function to produce a binary output with two possible values corresponding
to the two possible class labels. If the target value is greater than 0,
the function returns plus 1, and if it's less than 0,
the function returns minus 1. Here's a specific example. So let's take a look at a simple
linear classification problem, a binary problem that has
two different classes. And where each data instance is
represented by two informative features. So we're going to call these features
x1 on the x axis and x2 on the y axis. Now how do we get from taking
a data instance that's described by a particular combination of x1,
x2, to a class prediction? Well, in a linear classifier, what we do is we take the feature values
assigned to a particular data point. So in this case it might be 2.1. 2.10, so that represents the x1,
x2 feature values for this particular instance, let's say. And so that corresponds to the input here. And then we take that those two x1,
x2 values and put them through a linear function f here. And the output of this f
needs to be a class value. So either you want it to return
+1 if it's in one class and -1 if it's in the other class. So the linear classifier does that by
computing a linear function of x1, x2. That's represented by this
part of the equation here. So this W is a vector of weights. This X represents the vector
of feature values, and then b is a bias term that gets added in. So this is a dot product, this circle
here is a dot product which means that, let's say in the simple case
where we had weight vector 1, 2. And a feature vector of x1,
x2, the dot product those is simply the linear combination
of w1 x1 + w2 x2. And then so we take the x values and we have certain weights that
are learned for the classifier. So we compute w1 x1 + w2 x2,
and then we feed that and then plus the bias term if there is one. And we feed the output of that
through this sign function. That converts the value in here. If it's above 0 it will convert to +1, and
if it's below 0, it'll convert it to -1. And that's what the equation represents
here, so that is the very simple rule that we use to convert a data instance with its
input features to an output prediction. Okay, let's take a look using a specific
linear function to see how this works in practice. So what I've done here is drawn a straight
line through this space that has, it's defined by the equation x1- x2 = 0. In other words, every point on
this line satisfies this equation. So you can see, for example,
that x1 = -1, and x2 = -1. And if you subtract them you get 0. Essentially it's just the line that
represents all the points where x1 and x2 are equal. So this corresponds to,
so we can sort of rewrite this x1- x2 = 0 into
a form that uses a dot product of weights with
the input vector x. So in order to get x1- x2 = 0, that's equivalent to writing
a linear function where you have a weight vector of 1 and
-1, and a bias term of 0. So for example, so
if If we have the weights W1W2 and that product of X1X2. Recall that this is just the same as computing W1X1 plus W2X2, and so in this case, if W is 1 and negative 1, that's equivalent to X1 minus X2. So all I've done here then, is just
convert the description of this line into a form that can be used as
a decision rule for a classifier. So I might have to look
at a specific point. So suppose that we wanted to classify
the point here that had coordinates negative 0.75 and negative 2.25. So this point right here. So all we would do to have
a classifier make a prediction with this decision boundary
would be to plug in those coordinates into this
part of the function. Apply the weights and the bias term
that describes the decision boundary. So here, we're computing,
so this expression here corresponds to this
part of the equation. And so if we compute weight 1 times
X1 plus weight 2 times X2 plus 0, we get a value of 0.15 that's
inside the sine function. And then the sine function will output
1 if this value is greater than 0, which it is, or
minus 1 if the value is less than 0. So in this case,
because it's greater than 0, the output from the decision
function would be plus 1. So this was classified this
point as being of class 1. If we look at a different point,
let's take a look at the point negative 1.75 and negative 0.25. So again, we're just going to this is
corresponding to the value of X1 and X2. And again,
if we just take these values and plug them into this part of the equation,
apply the weights and the bias term that described the decision
boundaries that we did before. We do this computation,
we find out that in fact classifier predicts
a class of minus 1 here. So you see that by applying
a simple linear formula, we've been able to
produce a class value for any point in this
two-dimensional feature space. So one way to define a good classifier
is to reward classifiers for the amount of separation they can
provide between the two classes. And to do this, we need to define
the concept of classifier margin. So informally, for our given classifier,
the margin is the width that decision boundary can be
increased before hitting a data point. So what we do is we take the decision
boundary and we grow a region around it that sort of this in perpendicular to the
line, this direction and that direction. We grow this width until
we hit a data point. So in this case,
we were only able to grow the margin small amount here before
hitting this data point. So this width here between
the decision boundary and the nearest data point represents
the margin of this particular classifier. Now you can imagine that for every
classifier that we tried, we can find do the same kind of calculation or
simulation to find the margin. And so, among all possible classifiers
at separate these two classes then. We can define the best classifier as
the classifier that has the maximum amount of margin,
which corresponds to the one shown here. So you recall that the original
classifier on the previous slide had a very small margin. This one managed to achieve
a much larger margin, so again the margin is the distance. The width that we can go
from the decision boundary perpendicular to the nearest data point. And so you can see that by
defining this concept of margin, sort of qualifies the degree to which
the classifier can split The classes into two regions that have some
amount of separation between them. We can actually do a search for the
classifier that has the maximum margin. And this maximum margin classifier
is called the linear support vector machine also known as an LSVM or a support
vector machine with linear kernel. Now will explain more about what
the concept of a currently is and how you can define nonlinear kernels as well
as kernels and why you want to do that. We'll cover those shortly in
a continuation of our support vector machine lecture later
in this particular week. Here's an example in the notebook on how
to use the default linear support vector classifier in Scikit learn, which is
defined in the sklearn as SVM Library. The linear SVC class implements
a linear support vector classifier and is trained in the same
way as other classifiers, namely by using the fit
method on the training data. Now, in the simple classification
problem I just showed you, the two classes were perfectly
separable within linear classifier. In practice, though, we typically have
noise or just more complexity in the data set that makes a perfect
linear separation impossible. But where most points can be separated
without errors by linear classifier. And our simple binary classification data
set here is an illustration of that. So how tolerant the support vector
machine is of misclassifying training points as compared to its
objective of minimizing the margin between classes is controlled by
regularization parameter called C, which by default is set
to 1.0 as we have here. Larger values of C represent
less regularization and will cause the model to fit the training
set with his few errors as possible, even if it means using a smaller
margin decision boundary. Very small values of C,
on the other hand use more regularization that encourages the classifier to find
a large margin decision boundary, even if that decision boundary leads
to more points being misclassified. Here's an example in the notebook showing
the effect of varying C on this basic classification problem. On the right when C is large,
the decision boundaries adjusted so that more of the black training points are
correctly classified while on the left for small values of c the classifier is more
tolerant of these errors in favor of capturing the majority of data points
correctly with a larger margin. Finally, here's an example of applying the
linear support vector machine to a real world data set,
the breast cancer classification problem. And here we can see it achieves reasonable
accuracy without much parameter tuning. On the positive side,
linear models in the case of linear and logistic regression are simple and
easy to train. And for all types of linear models
predictions very fast because of the linear nature of
the prediction function. Linear models including linear
support vector machines, also perform effectively on
high dimensional data set, especially in cases where
the data instances are sparse. Linear models scale well to
very large datasets as well. In the case of linear
support vector machines, they only use a subset of training
points in decision function. These training points
are called support vectors. So the algorithm can be implemented
in a memory efficient way.