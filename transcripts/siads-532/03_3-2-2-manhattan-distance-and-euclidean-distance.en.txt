So how to deal with these problems. To overcome these
limitations of dot product, people have introduced a series of a
distance matrix that measures the distance of two vectors in the vector space. One of them is known as
the Manhattan distance, and is named after the street
map of the city Manhattan. Although this concept sounds unfamiliar,
but you have seen that many times
when you use Google Map, when you use any map that you're
trying to find how long it takes for you to walk from one location to another,
the distance. The time is calculated based
on how many blocks you will actually travel to get
from one place to another. And the reason the distance is named
after Manhattan because the streets in Manhattan are well aligned
vertically and horizontally. So Manhattan distance of two vectors
can be calculated as the sum of the number of blocks,
right, in each dimension. So in each of the p dimensions, we
calculate the absolute difference between the two values xi and yi, and we sum up
all these absolute distance together. That gives us Manhattan distance. If you look at this illustration
in this 2-D coordinate system, you have two vectors X and Y. Then the Manhattan distance between X and Y is essentially how far away X is
to Y on each of the dimensions, and you just sum up
this distance together. You may ask, why should I just
calculate the number of blocks? I walk from one from
one vector to another, why can't I just calculate
the street map distance? And logically,
if I can take a helicopter to go from one place in Manhattan to another place,
shouldn't the distance be shorter? Indeed, there is another very famous
distance metric that computes the straight line distance in
a p-dimensional vector space. And this distance metric is known as
the Euclidean distance, which is named after the famous Greek mathematician,
the father of geometry, Euclid. So basically, what Euclidean distance
does is to compute the straight line distance from the endpoint of
the two vectors in a coordinate system. Essentially, what it does is to
calculate the square of the distance, the square of the difference of
the values on each dimension xi-yi. And then you take the square,
you sum them up over all the p dimensions, and then you take
the square root of the sum. This is known as the Euclidean distance
that measures the straight line distance in a p-dimensional vector space. Why do people favor Manhattan distance and
Euclidean distance? Because they have quite a few
interesting advantages. First, most of the distance
metrics are symmetric, and that means the distance
between the vector X and vector Y is equivalent to
distance between Y to X. That means it takes the same number
of blocks or the same straight line distance to travel from one of the
place to another and then to come back. Another nice property is that both of
the distance metrics are non-negative. And that means the smallest distance
between two data points will be what, will be zero. And that only happens if the two data
objects are identical to each other. And you can see that now it nicely
solved one limitation of dot product. Now the distance between one data object
and itself will be smaller than distance between this data object to any other
data objects that are not identical. And finally, there is another nice property that
is known as the triangle inequality. And that basically means if take a detour,
if you do not go directly from X to Y, but you have to bypass one data point Z,
then the distance will not be shorter. The distance would be either
be identical or be longer. The distance from X,
Y is always smaller or equal to the distance from
X to a third vector Z plus the distance from the third
vector Z to the endpoint Y, so taking a detour is not helpful. And in fact, if a function
satisfies all the above properties, that function is known as the metric,
and that metric is the distance function that has lots of nice
properties in mathematics.