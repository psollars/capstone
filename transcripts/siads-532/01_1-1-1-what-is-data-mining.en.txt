Hi, this is Qiaozhu Mei
from School of Information. Today we will talk about the introduction
to the field data mining. You may have heard about this term,
data mining, in various contexts. Your manager talks about it. Your co-workers talk about it. You heard that from your clients,
from the Internet. But when they are talking
about data mining, are they referring to it as particular
techniques in database systems? Or are they talking about anything that's
related to analyzing large scale data? What do you think? What's your own opinion
about what is data mining? In fact, many people may have problem
distinguishing the term data minding from related concepts such as machine
learning, such as data science, and big data analytics. There are also other terms that more or
less have the similar meanings with the concept data mining such as
knowledge discovery in databases, knowledge extraction,
sometimes data pattern analysis, sometimes even data archaeology,
data dredging, or information harvesting. In this lecture, we will give a formal
definition of data this mining that will help you understand the connections and
the differences between these concepts. So why do we care about data mining? We need data mining as the tool to deal
with the explosive growth of data. By the recent statistic,
in the year 2025, it is estimated that we will have over 100 zettabytes
of data from all over the world. What is a zettabyte? A zettabyte is roughly 1,000 exabytes. The exabyte is 1,000 petabyte. A petabyte is 1,000 terabyte. So a zettabyte is actually
1 trillion terabytes. That's awfully a lot of data. If we use the example that you're more
familiar with, how many tweets are there? Based on the recent statistics, there are
over 6,000 tweets generated every second. And that translates to 200
billion tweets per year. And that's 30 times as large as
the population in the world, it's huge. But the problem with this explosive growth
of data is that we actually don't have so much knowledge that can help
us make better decisions. You may have heard about this famous
scene that we are drowning in data, but starving for knowledge. And data mining is the tool to help you
obtain knowledge from the big data. To give you another perspective
of why data mining is important, let me introduce the fourth paradigm of
science based on the vision of Jim Gray. Jim Gray is the computer scientist and
Turing Award winner in 1998, the toppest award for computer scientists. So in his NIST presentation,
he gave the vision that characterizes scientific
research in the four paradigms. The first paradigm is empirical and
experimental science. The goal of which is to use
experiments to explain phenomenons and this paradigm has been there
thousands of years ago. In less than 400 years,
scientific research has entered the second paradigm that is known as theoretical
science, where the theoretical foundations are being developed
in every branch of science. And since 1950s,
thanks to the invention of computers, scientific discovery has entered
the third paradigm that is using computational tools to simulate
complicated experiments. We call that computational science. Jim envisioned the fourth paradigm
of scientific research that is known as data-intensive science. He himself called it eScience. The goal of data-intensive
science is no longer using simple experiments or theory or
computational tools, but use the mixture of data and
theory to make discovery. In other words, scientific
discoveries are now data-driven. It has everything to do with learning from
data that you collect from experiments, from computational simulations, and
from the world to make discovery. And this term data-intensive science
is closely related to the concept data science we know nowadays. In this process, you can see that
data mining is the major challenge. So what is data mining? Can we give a definition of this term? Many people agree that data mining is the
process of knowledge discovery from data. And this is why it's called data mining. You can see that in this general and
simple definition, there are two important components. First, the goal of data mining
is to discover knowledge. And second, this discovery
process has to be based on data. Now different people may have
different interpretations of those two important components. For example, if I take Professor
Jiawei Han, he defines data mining as the extraction of interesting patterns or
knowledge from huge amount of data. So you can say that the term pattern
is used as the synonym of knowledge. And this process has to be
done with huge amount of data. He also emphasized that
knowledge has to be interesting. What does he mean? He defines interestingness of
the knowledge as non-trivial, implicit, previously unknown,
and potentially useful. So the goal is to extract patterns that
are new, that are previously unknown, and that can be helpful for
people's decision-making process. Let's also look at the definition
by Professor Sunita Sarawagi, a professor at Indian Institute
of Technology. She defines data mining as
a process of semi-automatically analyzing large databases
to find patterns. So you can say that, again,
she emphasized the large quantity of data. And she defines patterns as
something that are valid, novel, useful, and understandable. So if you compare the two definitions, you can see that both of them emphasize
on the large quantity of data. And they emphasize on the usefulness
of the knowledge or patterns. But they may have their own definitions
about what they mean by usefulness or meaningfulness of knowledge. In fact, if you look at other definitions
of data mining, they are more or less focusing on same dimensions. Professor Vipin Kumar at the University
of Minnesota defines data mining as exploration and
analysis of large quantity of data, again, in order to discover
meaningful patterns. And this is very much in
line with other definitions. So based on this definition, now you can
see that many data analytic processes you're familiar with can be described
as the data mining process as long as they're discovering new knowledge
from large quantity of data. But please be careful that not
everything is considered as data mining. Let me give you one example. If you think about looking up a phone
number in the phone directory, is this process considered as data mining? Well, it is dealing with large scale data,
but arguably, the phone number is not
a new piece of knowledge. It exists in a phone directory. And all you need to do is to find it out. So based on the previous definition, it is
not considered as the data mining process. A similar example is
querying a search engine for pages that contain the word Amazon. Is this data mining? Well, based on this definition, you can
also argue that this is not a data mining process because there are web
pages containing the word Amazon. We know it, the search engine
just need to find it out. However, nowadays the search
engines are smart enough. You can even ask it more
complicated queries like what do data scientists Amazon use? And now a search engine has
to aggregate information from multiple web pages and
to discover new patterns. If that is the case, it could be
considered as the data mining process. For another example,
what about deductive expert systems? The system that helps you make decisions
based on set of rules defined by experts, is that a data mining process? Well, this time it is definitely
generating decision support knowledge. However, because of
the knowledge is not from data, the knowledge is derived
from human annotated rules. This is also not considered
as the data mining process.