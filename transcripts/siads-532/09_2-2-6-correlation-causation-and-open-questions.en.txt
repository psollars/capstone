So there are a lot of questions about Association
and Correlation. But I do want to remind you that correlation does
not indicate causation. When you apply correlations extracted from large
scale data in reality, you should be cautious. For one example, people felt that ice cream sales is correlated with the rate
of drowning deaths, which is surprising.
What should we do? Stop selling ice creams? Fortunately, there is no real causation
between these two. To draw robust causal
decisions you need to apply much more complex
causal inference techniques. Many of those causal
inference techniques also rely on frequency and
correlation as prerequisites. Are you interested about why there's the correlation
but not causality? This is because
both variables are correlated with temperature. There have been many progress made in mining
frequent item sets. I want to point you to
a few open questions. People are still focusing on how to find frequent patterns, from very large scale data. How do we improve
the efficiency and the scalability of the frequent
pattern mining methods? Instead of finding the patterns
that appear frequently, people often interested in finding patterns with
certain constraints. For example, finding
patterns that are statistically significant
instead of just being frequent. Because you want to
use the patterns discovered for
supporting decisions, it is very important
to be able to interpret why the
patterns are useful. Is that just to show some numbers that they're frequent or they are statistically
significant. We need more measures to evaluate the true insterestingness
of patterns to filter the truly
useful patterns from the very large-scale
frequent patterns. We also need better
measures to make use of the itemsets that
we discovered for downstream tasks such
as classification. Finally, we need
more applications. Applications is always the key of a successful data
mining procedure. I also want to point you to a few interesting tools for frequent pattern mining,
frequent itemset mining. One of them is Weka, that is the very well-known tool in data mining community. It is written in Java. It is well-made maintained,
and documented. It has implemented many
data mining algorithms and it has the Python wrapper. It is harder to install
in the local environment, but if you're interested, it offers many functionalities. Another tool that is
the Python package, known as the Mlxtend, it is a Python package
which comparing two Weka it has limited
functionalities, but it does offer many
interesting touches. Many useful touches of
frequent pattern mining. It is very simple to use. I recommend to you to
start with this tool kit. As a summary of this lecture, we have introduced
basic methods of frequent pattern mining in particular frequent
itemset mining. I hope you understand
how Apriori is able to scale up
frequent itemset mining, because it's shrinks the number of carrying the items
that you need to check. I hope you understand
how to measure the interestingness of patterns. How to go from frequency
to association and how to go from
association to correlation. We have introduced
multiple applications of itemset mining. I hope that you can apply itemset mining in
your real scenarios. Finally, if you're
interested in text mining, do remember that
co-occurrence is the key. You could look at
co-occurrence of births, co-occurrence of phrases and co-occurrences of even
longer language patterns.