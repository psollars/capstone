So earlier in the course,
we discussed distributions. And today we'll be talking
about how we can build and plot histograms in Python to actually
visualize those distributions. A histogram is a great tool that
allows us to quickly discover and visualize the underlying frequency
distribution or shape of continuous data. And also identify outliers and
skewness among other things, and it's intuitively understood
by almost any audience. Most people know a histogram by
its graphical representation, which is really similar to a bar chart or
bar graph. Python offers a handful of
different options for building and plotting histograms. Let's check out one. Let's create a jupyter notebook histogram. So first let's just import all of
the libraries that will need and the iris dataset. So import pandas as pd,
import matplotlib as mpl, and import matplotlib.pyplot as plt. Then we'll load the iris dataset as well. We'll use the plt.hist method
in matplotlib to create the same very basic histogram of sepal
width that we just looked at. So plt.hist(iris 'sepal_width'). This simple histogram is a great first
attempt and understanding your data. Notice that by default the histogram
in matplotlib uses ten bins, that is ten different bars. Let's do the same function, but
this time we'll change the bin size to 25. So will do plt.hist(iris 'sepal_width')
and we'll use the bin function and set it to 25, and this will automatically
create 25 evenly spaced bins. Now that we've sampled the plot, we can see that it looks a lot
smoother than the previous one. We've included an optional reading
that goes into more detail on this, so feel free to check that out. The hist function has many options to
tune both the calculation and display. The plt.string also has more
information on other customization options that are available. Let's explore those and create a few more
customized histograms that gives us more information about the axis. We can stick with the bin size of 25,
and set the transparency level using the alpha at alpha=0.5,
and set the histype at 'stepfield' which generates a line
plot that is by default filled. And let's also change the color to coral. So plt.hist(iris 'sepal_width')
the same thing that we set up beforell, bins=25, alpha=0.5, and
we'll do the stepfilled and coral. We also need to add a title and
axis labels, so we'll do plt.title and we'll call this Histogram of Sepal Width,
and we'll also do the x-axis label as Sepal
Width and the y-axis label as Frequency. The plot most often accompanied by
a histogram is a normal distribution plot. These pots come in very handy when
you're trying to identify averages outliers distributions. They also are very easy
to produce with Python. First, we'll be focusing on a normal
distribution using the probability density function. Basically, if you have a range of x's,
which in this case would be our sepal width variable measures,
and mean and standard deviation, we can pass them into the formula and
get a corresponding y values, which we can then plot using
the standard matplotlib function. Let's set up the scene first. Okay, load in the norm
function from scipy.stats. So from scipy.stast import norm, and convert the pandas DataFrame object
into a numpy array and sort. So we'll call this se and we'll do
np.asarray for the sepal width variable, and then we'll sort it using
the sorted(sw) function. Let's use the scipy stats module.pdf or
probability density function to fit a normal distribution with the same mean
and standard deviation, and inside it we can also use numpy to determine the mean
and a standard deviation of sepal width. So we'll call this fit will do norm.pdf, our sw that we just created,
.mean(sw) to get the mean and np.std(sw) to get the standard deviation. Now we can plot both series
on the same histogram. So we'll do plt.plot sw, fit,
will adjust the linewidth tol 2, and we'll label this to Normal
distribution with the same mean and var. And then for the next one will do pltist,
sw.normed=true and with our 25 bin size, and
labeled as Actual distribution. And add our information that we
need like title axis and so forth. So will do plt.title and we'll call this Histogram of Sepal
width with normal Distribution Line. And our x variable is Sepal Width,
our y variable is Probability density. We'll add a legend and
we'll show the plot. This data doesn't look very normal,
as we can see there are several points extending above the normal
distribution line. Let's check out the kurtosis. Kurtosis is a measure of whether the data
is has a heavy tail or a light tail, relative to a normal distribution. That is, data sets with a higher kurtosis
tend to have heavy tails or outliers. Data sets with low kurtosis tend to
have white tails or lack of outliers. A normal distribution would
be an extreme case up here. We can use pandas .kurt
functionality to do this. Note the pandas uses Fisher's
definition of kurtosis. So kurtosis of normal would equal 0. So we'll do iris sepal_width .kurt
to get our kurtosis function. We can see that the data are indeed
not normal because of the kurtosis level doesn't equal 1. The sign of the kurtosis indicates how the
data deviate from the normal distribution. In our case we have
a positive value of .228, which indicates that the distribution
has heavier tails and a sharper peak than a normal distribution. If we had a negative value here,
say -0.45, this would indicate our data has lighter tails and
a flatter peak than a normal distribution. Okay, so before we start crying over
our keyboards we can try to transform the data to make it more normal, or
at least as normal as it can be. There are a variety of popular and
useful data transformations you can use. They're simple and will help you to continue to analyze your
data using parametric test, for instance. However, in many cases,
there's simply no transformation that will produce a close to normal result and
that's just something to keep in mind. To try and remedy your data, you can change the vet data values
consistently across the data. This will change the distribution of the
data while maintaining the integrity for any future analyses. To make this more concrete,
below is an example of Gaussian numbers transformed to have
an exponential distribution. So first we can just generate some data. So we'll do np.random.seed to ensure
that we get the same data every time, and we'll just call this X
= (np.random.randn) 100 and so forth to get our
exponential distribution. Let's plot the histogram
above to see what's going on. So plt.hist(x) of the random
numbers we just generated. We can already see from
the histogram that the data appears pretty noisy, and it's strangely skewed. With experience, you'll begin to notice
that the data are positively skewed in this case because the tail of the right
side of the distribution is longer or flatter. This is indicating some sort
of power law or exponential. Let's check out the kurtosis using
the scipy.stats again this time. So again will load in
the scypi.stats kurtosis measure, we will specify that we want to
use the Fisher's definition. Kurtosis is the fourth central moment
divided by the square of the variance. If Fisher's definition is used then, 3.0 is subtracted from the result to
give a 0.0 for the normal distribution. So we'll do kurtosis X and
indicate that we want fishers=true. This data doesn't have too
much of a kurtosis issue, but let's check the skewness. For normally distributed data,
the skewness should be about 0. For unimodal continuous
distributions a skewness value of less than 0 means
that there's more weight and on the right side of the tail
of the distribution. So first import the skew argument
from the scipy.stats again, and we'll just do skew and insert our
variable of interest, which is x. Which we would hope to be 0, but
of course, this is not the case. Okay, so we can transform the data
by trying to invert the mathematical operations that have occurred up to
this point where we measured it. And that's okay because
we're not altering the data, we're just changing how it is represented. So we'll do this by creating a data
frame called df and then we'll do pd.Dataframe(x) to create the pandas
dataframe out of the numpy array. And then we'll do df_exp = df.apply to do a log transformation. Exponential and then we'll add a title and Xxlabel and we'll show the plot. Okay, so this looks pretty weird as well. I wonder if it's a power law
transformation is needed. So for
this will do df_pow = df.apply(np.sqrt), df_pow.plot.hist, same
we'll do 15 bins and we won't show a legend on this one. And we'll just add in our
x labels in our title. Okay, so that's looking much better. So it looks like it was
a power iaw to the power of 2. Here we see a histogram, it's just a bar chart where the x
axis is a given observation and the y axis is the frequency with
which that observation occurs. For instance, the first bar is showing us
that there are about four observations with a value of 2, and we can see that
the data are close but not exactly normal. So why are histograms useful? Well, first of all charts are much
more visual than tables, obviously. After looking at a chart for ten seconds
you can tell much more about your data then after inspecting
the corresponding table for ten seconds. Generally figures convey more information
about your data faster than tables. But to be sure,
let's fit a normal curve over the top. So for this will import
the scipy.stats and the norm, and we'll set up the fit for
the normal distribution to the data. And will do linear spacing of
a hundred elements between 0 and 20, and use the fitted parameters
to create the y data points. Okay, now let's plot this again. Plot some fancy text to show what
the parameters of the distribution are, mean and standard deviation. We can just use the plt.text and input the information that
we'd like to appear there. We can also plot a line of the fitted
distribution over the top. And again,
just some more standard plot stuff. So we'll add in the xlabel,
the title, and we'll show the plot. Okay, great. That's looking pretty good. So this is how you can actually
describe any population distribution using the different measures and
see graphically how it looks, as well as transform your data to be normal or
as close to normal as you can get it.