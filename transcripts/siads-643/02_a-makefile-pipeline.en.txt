The make command can be a convenient
way to define a DAG for a machine learning pipeline. This is a command that's
usually available on Unix or Linux systems that have their
software built packages installed. This is a tool that's been commonly
used for C and C plus plus. [COUGH] This is a tool that's
been commonly used for years with C and C plus plus projects
to manage the compilation workflows and linking workflows that are needed
in those kinds of projects. The flow is defined by
a file called a Makefile, which is stored usually with
the application source code. So even though the make command and its
Makefile have traditionally been used for software compilation pipeline. They can actually be really convenient for
managing data workflows as well. Targets is the term that
the make process uses. We've also been talking about those in
terms of steps in our other pipeline conversations. In the Makefile for each target you can define what
the dependencies are of that target. And if necessary, you can also define the
command that's used to create that target. If it needs to be recreated,
make as clever. And it uses the file system time stamp of
the artifacts that are created by each target to decide which
targets need to be rerun. And if dependencies have been rerun, it
will automatically manage the process of rerunning the things that are downstream
from that in the pipeline. So this is where we left our pipeline. The business of running the pipeline and
deciding which things happened in which order is happening
in the if name is main block. Where we take the output of the clean step
and pass it as input to the train step. Let's see what that will look like if
we were to define it with a Makefile. And as we do that, we'll explore
what the Makefile Syntax looks like. So this is what our pipeline would look
like if we were to use a Makefile. Now the reason we can do this is because
we broke our different steps into different modules. The train.py module and the clean.py module we're using those here
to define the steps that make needs to take in order to generate
the targets that we've defined here. So let's look at the detail
starting with the clean.csv target. So the format of the Makefile is
the target is defined followed by a colon, then a space separated list of any
of the dependencies of that target. The things that are that if they
change this target needs to be rerun. And then finally on the line below
intended with a tab is the command that's needed to actually generate this
target if it needs to be regenerated. So we've defined two dependencies for
the clean.csv file. We've defined clean.py as a dependency and sales_export.xlsx as a dependency. It might seem a little strange to define
our Python script as a dependency. But if we make any changes to that script,
we'll want this step to rerun. So it's important to include our
scripts that actually run our steps as dependencies in this kind of format. If either the clean.py or
the sales export file have changed, make will run the command
that we've defined below. It will run python clean.py. And passing as arguments
the sales export file. And then the output argument of clean.csv. Therefore, actually creating
the target which we defined here. The model.pkl target is
follows the same pattern. We have two dependencies, the train.py
Python script and the cleaned.csv file that was generated in the other
target that's defined in the Makefile. And the command to generate
model.pkl if that's necessary. There's a lot of information packed
into this very tight format. Let's take a look at what this looks
like in a running environment. Here we have our Makefile
in the code editor. Before we dive into the make command and the Makefile that will
use to run the pipeline. Let's just note that the clean.py and train.py scripts are just like they
were in our modularized pipeline. That we haven't changed those at all. They still have the same input and
output arguments. And they stay still
behave in the same way. The only difference here is that
will be using a Makefile instead of the pipeline.py file to run our pipeline. So to run our pipeline with
make defined by this Makefile, we can use the make command. Now I used the make command
without any arguments. And since we defined the model.pkl
target first in our Makefile, that's what make runs by default. Now it does a few things when we ask
it to run the target for model.pkl, it checks to see its dependencies. It checks to see if it
has the train.py file. And it checks to see if it has clean.csv. When it did that,
it did not have clean.csv. It hadn't been created yet. It checked in its dependency graph to see
what it would have to do to create that. It found that clean.csv target and saw
that it needed both the clean.py file and the sales export file in
order to create that. But since clean.csv hadn't
been created yet, it now knows that it needs to use this command
to actually create the clean.csv file. So that's the first thing it
did when we told it to run. It ran the command python clean.py with
the arguments that we specified in line 5 of the Makefile. Now that it had done that, it could
continue building the target that we asked for initially,
the default target model.pkl. Since the model.pkl file didn't exist,
but it had its dependencies. It could run the python train.py
command with the appropriate arguments, which it does. Next, the output that we see here is what
is being printed by the train.py script. And then it finishes. Now if we run the make command again. You can see that nothing actually happens. Make gives us a message that
says model.pkl is up to date. Because it has a file called model.pkl,
it's already satisfied that target and doesn't need to do anything. Let's see what happens if we
change one of the dependencies. Let's make an insignificant
change to the file. We'll just add a comment here so
that the file itself has changed. But the behavioral stay the same. This time, if we run,
make something else will happen. So this time we just got
the train script run. So this time just the train.py script run. Why is that? The reason for that is that in
order to make the model.pkl target, make already had all
the dependencies that it needed. It had already run from our
first run of the make command, it already had clean.csv. So it was able to run the command to
generate just the model.pkl target, which is what it did here. If we were to make a change
earlier in the pipeline, let's make a similar change
to our cleaned module. Now if we ask it to generate our default
target, the model.pkl, make will notice that one of our dependencies
earlier in the pipeline has changed. And it will rerun everything
after that point. I'll use the arrow to go back in
my history to my previous command, which is make and run that. So this time it's running both the clean
command and the train command. So even though the declarative style
of the Makefile can be really dense. And it can be hard to wrap your mind
around if what you're used to is the imperative paradigm. This approach let's us focus
on the logic of each step. And leave the heavy lifting of deciding
which parts of the pipeline should be run and when to the make command.