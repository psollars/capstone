Hi, am Elle and I'm going to be
talking a bit about DVC pipelines. DVC stands for data version control. It's an open source project and
I'm part of it. And so what it is essentially
is a software toolkit for extending git version control to
work with data science projects. And using that framework there's
a couple of problems in data science and machine learning generally
that we can address. One of them is how do we version
datasets that might change overtime or be transformed in new ways. So how do we keep track of essentially
the lineages of your data science projects that includes datasets
themselves as well as models, things that are derived from datasets. Another thing that we work with
is data access and sharing. So how do you provide
access to a teammate for it to the public to a large data set or
model that might be in cloud storage. Another topic is data pipelines, and
that's what we're going to cover here. So how do we capture all
of the computational steps that go from transforming datasets
to models or anything in between. And finally, how do we keep track of
these experiments if we've got a whole bunch of different ways to transform data
to model it, how do we keep track of all of the different things we've
tried to find the best model? So that's kind of, the scope of DVC. I mean, these are kind of big things, but everything is done through
a Git Centric Way. And if you're not super
comfortable with git, I hope that this video will still be
pretty clear to you about how we do it. So let's talk a little bit
about pipelines in particular. So pipelines are maybe a more
vernacular way of saying dad that directed a cyclic graph. And so a directed a cyclic
graph is a chain of steps and it doesn't have to be chain. It can have some weird branches too, but we've got a chain of stuff somehow that
have various dependencies on one another. So it could be that your training. There's a stage of process
of training a model, and that will depend on perhaps your
data set as well as the script for training a model, so that might be
a Python script for training the model. Those are the dependencies of
the model training stage, and the output might be a model. And DVC uses a method for
tracking the dependencies in the output of every stage of your directed
a cyclic graph, your pipeline. And we use two files to do this. One of them is the dvc.yaml file, and it's a human readable human editable file
for declaring how your pipeline looks. And we're going to look at that here. It's very similar to a make file and
then we have a less human readable file that might show up in
your project directory. If you're using the DVC pipeline approach,
called DVC Lock. And this helps us version your pipeline so
that you'll actually know do I already have the dependencies for
my model training stage? In my in my project directory,
do I need to recompute them, and it also helps to roll back in time. So like one week ago,
what did my pipeline look like and what were all the dependencies of it? So, let's go through a couple different
approaches to making your pipeline. One that it seems that you've looked
like looked at before is using Python file where you kind of change
together your various steps. This is one approach. Some downsides of this is you don't
really have any versioning here. There's not any explicit tracking of
your dependencies or your outputs. Things aren't very
separated from one another, it's all kind of in one, you know. There's a couple of engineering
reasons why this isn't optimal though this is definitely to
an extent reproducible. Makefile is another option. Makefiles are beautiful and we've got
kind of a separation of the process and the dependencies and that starts to
get used to really good advantages. Its rigorous this is this is better
engineered and I like this quite a lot. There could be some downsides to make
files which is that sometimes maybe not everybody import organization
is comfortable with them. But once you once you learn them,
they're pretty great and there are applicable to a lot of languages,
a lot of types of software development. So they're pretty great. And another alternative is DVC's. DVC has these pipeline files that
are very similar to a Makefile. Conceptually, this syntax is different, and it has a couple of features
that make it better engineered for more tailor made for data science and
machine learning type problems. Specifically where we have large
data sets, for example, but it's fairly conceptually
similar to a Makefile. And it might work for DVC, I think,
whichever one you use is pretty great. So we've got this file here, and this is, it was supposed to be
human-readable and human-writable. And what we do is,
we're going to break up the stages. So here, I'm showing you that we
have two stages, clean and train. And in the cleaning stage, we're running
this python clean.py script, and it's going to depend on the clean.py
script, as well as their data, and it's going to output this cleaned.csv. And then we've got a training
stage which has python train.py, followed by some arguments,
is the process that's being run, that's what you would
enter in your terminal. And the dependencies are your
transformed data, so your dependency is the output
of the previous stage. And then your training data, training
script, and then it outputs model.pkl. YAML stands for Yet
Another Markup Language, or YAML Ain't a Markup Language,
I'm actually not sure which one it is. But it's a fairly popular, or
growing in popularity schema for representing data structure. It's pretty human-readable,
which is something kind of nice about it, and it's conceptually
quite similar to JSON. Once you get started with it,
the learning curve is not too bad. And here's, just in this table, an example of how you might take a list
of object, and convert that to YAML, or a dictionary, or a JSON object,
and convert that into YAML. All right, so
let's go to a little bit of a demo. And I think this will help
kind of see the whole thing. I think if we can do some live coding
here, I think that will really drive home what a DVC pipeline looks like,
and how you would create one. So if we go to my code example,
we've got two scripts, this cleaning script, and
we've got a training script. And what we're going to do
is create a pipeline file. So we'll start in a directory
that has Git initialized, and we're going to have DVC initialized. So that would be kind of the foundation,
you need those two. Let's see,
let me drag this up a little bit, okay? So here's how you would
declare a pipeline, you're going to declare it in stages. So you'll start with this command,
dvc run, and then you'll use an n flag for whatever you're going to name the stage. And let's call the first stage clean, because we are going to
be doing this clean.py. Okay, then I go to a new line, and
now I'm going to declare my dependencies. So I have two dependencies,
the first one is itself clean.py. So if anything in this script changed, we would want to re-run
this stage of the pipeline. And then our next dependency is
going to be sales_export.xlsx, and that's our data, all right? Go to the next line, and I'm going to give
it an output, and that is cleaned.csv. And finally,
let's just write the commands. So this is where you enter,
what's the process that's being run? This is the same as what you'd
enter in your command line, if you were to manually run this stage. So it is going to be python clean.py sales_export.xlsx cleaned.csv, okay? Now I can run this, and
as soon as I do that, DVC will actually execute the command for
you on your local machine. And you get this brand-new dvc.yaml file. You also get this dvc.lock, and
this has some mystery numbers in it. What these are are hashes that
are going to help DVC under-the-hood version all of the dependencies,
the code, and the output. But you will not have to touch that. And so here we go,
we have the first stage of our pipeline. And you might notice that DVC recommended, to track changes with git, run this,
so you might want to do that. So like I said,
DVC is pretty closely connected with git. And you can think of doing
this git add step as kind of, you're snapshotting the project
at this moment in time. So if you want to be able to look
back a week from now and say, what did my project look like at
3:27 PM on Wednesday afternoon? Then if you've done this git add and
git commit stuff, you'll be able to roll it back then. But I don't particularly want to remember
this stage, because of I am going to, my pipeline's not done, so
let's add the next one. And I'm going to add this one
using just manually entering it, just to show you that you can do this. So let's call the next one train,
and we indent. And this time,
the command is going to be python train.py cleaned.csv model.pkl, and
let's do Dependencies and the first one is going to
be cleaned.csv and next the dependency is
going to be train.py. And will do the output is model.pickle. Okay, cool. And now if I use this function
dvc repro which is short for reproduce, DVC will
reproduce the pipeline. And you might notice that it says,
your stage clean didn't change, so it's skipping. So if DVC detects that the previous stage
here that all of our dependencies and outputs look exactly
the same as last time, it's not going to rerun it,
so it will just leave it. Sorry, if the dependencies are the same,
I meant. So if the dependencies of
this stage have not changed, then DVC will not rerun
the clean stage of the pipeline. So it's kind of smart about saving
you some computation there. And so, now we've got our brand new
stage and I will snapshot this. I'll do git add and I'm going to
get commit .m first commit, okay. And let me just show you what happens. So let's say that I go into there's
something I can change in one of these, let me see. Here we go. So in train.py,
what if I just change this? I'm going to change how we're splitting
our training test data and that's it. Now, if I do dvc repro, DVC will rerun. And boom, and now if we save this,
we'll have a snapshot of this front of the pipeline if we were to
do another git add commit. So, that's kind of the gist
of how DVC pipelines work. And I didn't show you all of the features,
so in addition to regular outputs, you can also use there's a special format
of output called metrics file which you would just do like this metrics. And then you can add a metric. And a metric is something that if you
wanted to save like this score here and you want to be able to easily compare
this over various different versions of your pipeline, then DVC gives
you some methods to do that. And there's also a plot strict too, so that you can have DataVis
be part of your pipeline. To sum up what we've seen here,
DVC gives you a declarative way to kind of layout the logic
of each step in our pipeline. And what the word I've used
here is human readable. It's very intentional declarative,
so we're meeting our stages and we're being explicit about what depends on
what and in what order they will proceed. And then we can basically leave this
to DVC to manage knowing when we need to rerun any of the stages when it's
up to date, it can manage that. And so some of the benefits to your
workflow in addition are now you're well integrated with git. So if you are in working on a project
where it is kind of an important part of the workflow, which is very typical
when you work with engineers or developers with more of
a software background. It's well-integrated with git,
so you don't need to use like an entirely different tool for
tracking what experiments have I run? What are all the variants on this
type line that I've ever run? And will save you computation,
particularly if you're pipelines get very computationally expensive, which can
happen with some larger datasets. Or when you're going to
really big modeling projects. So that's kind of nice feel about DVC. Thank you very much for watching, and I
hope that the code example has been clear enough that you can get in there and
try this yourself. We also have a ton of docs about this and
open support channels always, so best of luck to you in all of
your adventures with pipelines.