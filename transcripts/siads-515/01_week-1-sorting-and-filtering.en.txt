Sometimes, and now we're getting into the data science parts, we want to use some command to search for specific patterns. The grep command is your friend. You'll be using this
a lot when you're trying to pull out
data from a data file. Grep is an acronym
that stands for a globally search for a
regular expression and print. It allows you to quickly extract all lines that match
a specified pattern. For example, to find all
the lines that contain the word Data with a
capital D in ride2018.csv, you could use grep
Data ride2018.csv. In a similar way, if we wanted to find all
the lines that contain Capulet in a file called
Romeo and Juliet, you would use a similar format. If you're looking
for a pattern that contains a space or
other special character, you'll have to put that
in quotation marks. So for example, if I was
looking for "A B" in data.tsv, you'd have to put
quotations around A and B. Let's take a look and see how
that works in our Notebook. So let's cd into our data
directory here and do an ls. Let's say that I
wanted to find all of the lines that contain the word Data in ride.csv. So that went by quickly, but if you examine the contents of that or
you try it yourself, you'll see that all of those
lines contain the word Data. If you know about
regular expressions, you can also use those in grep. I'm not going to show
this explicitly. But for example, if you
wanted to find all lines that contain phone numbers
of the form shown below, so area code, followed by a dash, followed by the prefix, followed by a dash,
followed by phone numbers, you could use that grep
command to find them. Don't worry if you don't
understand regular expressions. This may be covered in another
course in this program. Another command that's
useful is the cut command. That's how we select
columns from a file. So in a way that's
similar to grep that selects specific
rows or lines, cut will allow you to
select columns from a file. The general format
of that is using cut and then specifying
the argument minus d, followed by a delimiter, followed by minus f, and the field numbers for a file. So for example, to extract
the third, fourth, fifth, and seventh columns from a comma separated file called data.csv, we could issue cut minus d, followed by a comma in quotes, followed by the minus f argument, indicating we wanted
3-5 inclusively by saying 3-5,7 and the
name of the data file. So let's actually try that
on our data file here. So let's do a cut minus d using
the comma as a delimiter, and then specifying fields 3-5, and let's say 7-9 on ride.csv. There we have the results. Now that went by a little fast. So we can do something
called redirection. So I've got that
line pulled back up, cut minus d as I stated
just a minute ago, all the way to ride.csv. We can use the pipe command, that's that vertical bar, typically above your return key, and pipe that to
our more command. So we've taken that output
from the cut command and said, "Don't send it to the screen, send it to the more command." Now, we covered the more
command just a few minutes ago, and I can page through
that using my spacebar. Now, more doesn't know how big that file is because
it's a stream, it's streaming the output. So it just says more
without a percentage. We can q to quit out
of that at any time. Sorting lines is another form of data manipulation that
we might want to do. The general form is
sort minus t delimiter. Now, notice that the
delimiter argument specifier is different. It used to be minus
d, now it's minus t, followed by minus k, optionally, indicating it's
numeric with an n, the sort column, and
then the file name. So for example, to sort csv file called data.csv by
the second column, which should be
interpreted as a numeric, we can do sort minus t, minus k for key, two, and then n specifying
that we want data.csv. Let's take a look at
that in the Notebook. So we could do sort minus t, minus k2n ride.csv. Again, we can pipe that through more to see what it looks like.