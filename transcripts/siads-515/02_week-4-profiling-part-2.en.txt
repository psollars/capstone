So let's shift gears once more and talk about different ways to
operate on a Panda Series. And what we're going to do is
we're going to use some of the things we just learned. To help us understand good and not so good ways of operating on the entire
contents of a Pandas Series. So there are at least five ways
to operate on a Pandas Series. We can iterate with a for loop. We can use something from
Pandas called iterrows. We can use the apply function. We can use vectorized functions. Or we can use something called Cython. So the idea of this next piece,
I want to talk about haversine. And you can ask me what a haversine is. So haversines are interesting, because if I give you two points
of latitude and longitude. And ask you to calculate the distance
between those two points, latitude and longitude. You might be inclined to use
something like Euclidean distance. So you take the delta of the latitudes,
you square it, you take the delta of the longitudes,
you square it. You add those two things together and
you take the square root. Which would kind of make sense if
you're looking at things on a map. But remember, there's something
interesting about the world. And if we go ahead and
take a look at this. We find out that haversines have to do
with the fact that the Earth is curved. So these lines between any
two points of latitude and longitude aren't actually straight lines,
they're curved lines. And why is that important? Well, the distances
are not straight lines. And we have to use a little bit
of trigonometry to help us find out what the length of these lines are. The haversine between any two points
is given by this formula here. Now this looks a little bit complicated. And I'm certainly not going to
get into the trigonometry. But you see that there are three,
well, actually let's go down here. There are a couple of cosines
multiplied by each other, two sines and a cosine multiplied together. It's complicated math. Again, it's great for us because we get some complex math
that's going to take some time to apply. Math is fast, but not the fastest thing, as we saw with the law
with logarithm transform. Some straightforward math,
multiplication and addition, is fast. Things like trigonometric functions
take a little bit more time. So let's go back and
take a look at our haversine definition. So here I've operationalized
our haversine. This is actually based
on someone else's work. And the link to that is in your materials. The haversine function between any two
given latitude and longitude points. Here called lat1, lon1, lat2 and lon2, as parameters that are sent
to this particular function. We need one thing here,
we need a constant to convert to miles. So we're interested in dealing with miles. That's just a straight out multiplier
that we'll apply down here. Just when we're almost done. What we're going to do here is
convert from degrees to radians. So we'll need to do that
using the map function. We're going to calculate
the deltas of our latitude, the delta of our longitude by
looking at the difference. And here is exactly what we saw
before in the Wikipedia page. Where we're going to take an angle here. Where we take the sine of something, the cosine of something else multiplied
by the cosine multiplied by the sine. Again, I don't want to get too
much into the math of this. I don't want to get too much into what
the arcsine is and the square root. If you study the Wikipedia page about
haversines, you'll see that this is a high-fidelity representation
of exactly those formulas. So here's a nice little
haversine definition. It'll give us a function
that we can of course time. Now, what I want you to do first
is to write pythonic code. That is something that
is very python like. That iterates over each row in our
series to calculate the distance between each of the latitudes and
longitudes. We'll call those lat2 and lon2. And I want to calculate
the distances using haversine from these particular values of latitude and
longitude. So take a few minutes to do that. I just want you to use a simple for
loop that iterates with an index that iterates over
the values in those series. Now what I also want you to do. Is to introduce timeit, so
your code is going to be here. And I want you to time it. And I want you to get an idea of
how long that that's going to take. So record that number. Now, let's go ahead and use some of
the built-in functionality from Pandas. To see how long this will take using
another approach called iterrows. Iterrows is very similar to
iterating as you just did, but instead returns two elements,
the index and the row. And so what I'm going to do here is set
up an empty list called haversine_series. And I'm going to append to that list the
haversine distance between the two values that I gave you, and
each rows latitude and longitude. And then I'm going to
initialize a new series and that data frame with that
list of haversine series. So that should be familiar to you. This is Python, sorry, this is Pandas creating a new column or
a new series in that data frame. Based on the output of
our haversine function. So let's go ahead and time that and
take a look at that result. So here, it took a 175 milliseconds
plus or minus 25.1 milliseconds. So that's not bad,
that does a pretty good job of things. Let's go ahead and
compare that to what you did up here. Is it better or worse? My guess is it's substantially better. So let's take a look at yet
another way of applying haversine. Two rows using, not surprisingly,
the apply function. Now a lot of times I hear that people
aren't comfortable using apply. It's just a little bit weird. And if you come from
a strong Python background you just want to iterate over rows. Apply gives a little bit of
control back over to Python. Gives a little bit of
control back over to Pandas because we're applying this function. Which looks an awful lot
like the code we just did. So this is identical and we're just creating an anonymous
function using our lambda from python. Saying for each row we're going to apply
our haversine function on latitude and longitude. Again using the two constant values
that I gave you for this exercise. And here we're going to say axis=1,
which means it over columns not over rows. Okay, so if we run that, Through timeit we find
out that we've taken 56 milliseconds plus or
minus 649 microseconds. So this takes roughly
half the time to run. Remember up here we saw
175 five milliseconds, down here I saw 56 milliseconds. Your numbers will be different. Remember there's a certain
degree of unpredictability or stochasticity associated
with timing these functions. This also highlights the fact
that when things take longer, timeit will scale back the parameters,
the dynamically generated parameters. So here I had seven runs of one loop each. Because this is a little bit more
efficient we can get more loops. And so
we have seven runs of ten loops each. So as our time taken decreases, timeit by default will increase
the number of repetitions. To give us tighter estimates for
how long these things take. Now let's say we want to profile this. So let's go ahead and do an LP run on
this, and we get the same results. Very similar results to what we saw above. And we find out again that we have
a large number of hits or, sorry, a little bit differently this time. We find out that we have
a large number of hits that corresponds to one
hit per row in our series. So this is the total time taken. This is the time per hit. And this is the percentage of time. Looking down here at our profiler output. We see that a lot of time
is spent in this map. And even more time, almost twice the time,
is spent in this line here. Where we are calculating the sine,
cosine, cosine and sine, squaring it, dividing it,
a fair number of mathematical operations. So if I asked you how you're
going to optimize this and highlighted this as the problematic line,
how could you optimize that? Well, there is no way to optimize it. At some point you have to
recognize that things take time. This is pretty efficient. We're already using NumPy operators,
np.sin, np.cos. So we're pretty well maxed
out on our efficiency. It's just a matter of fact that this line takes the majority of time in
our function and that's fine. So that's an example of
profiling our apply statement. Let's carry on our examination of different ways to
apply that haversine function. Another type of approach that we can
do is use a vectorized implementation. So here, we're simply applying haversine
across the board, not using apply. But just calling haversine
on that particular series, or these two particular series. So we're not iterating over rows. We're not using apply. We're just using a vectorized
implementation which is the default if we pass a function to Pandas. So let's go ahead and time that and
see the results that we get. So we have 2.06 milliseconds and let's compare that to here
where we see 56 milliseconds. So by moving from using the apply
function to using vectorized implementations we get an order
of magnitude improvement. In our total time taken for this approach. And again, if we profile this, as we did a minute ago,
we should find very similar results. These results suggest very
similar things are happening. The majority of time is being spent in
this line again, nothing to do here. So here our profiling is
the same across the board. Now let's make one small change. You'll notice in the previous
run I called haversine and passed it the df latitude series and
the df longitude series. And it took 2.06 milliseconds per loop. If we make a small change and reach into
those series and extract the NumPy arrays. And we do that by using the attribute values we find that
something very interesting happened. So the only change that I've made
here is to extract the values. The NumPy arrays that underpin the series. If we run that,
we find that it takes 256 microseconds. So compared to here at 2.06 milliseconds, we have an again an order
of magnitude improvement. So we've gone from our initial approach,
say, using iterrows,
of taking a 175 milliseconds. Now your implementation of just a for
loop may have taken longer than that. But in my first implementation I took 175 milliseconds in my implementation
using NumPy arrays. I've lowered that to 256 microseconds, so that is a an improvement of
three orders of magnitude. That's huge. And here we're dealing with 1301 rows. It might not matter here if it
takes less than a second to run. But you can imagine a situation where
we have an extremely large data frame. And it's going to say, being run over
a number of different data sets. You're going to want to
push on this efficiency. So minor changes in approach,
that is to use vectorized functions. And even more subtle approaches of
reaching in to extract those NumPy values, those NumPy arrays, has resulted in
a dramatic increase in efficiency. Now you could ask, how long does
it take to extract those values? So we can time that as well. So if this was a very expensive operation,
we might not want to do it. But this operation is extremely fast,
right? Less than five microseconds
in this example. Again, yours might vary. And here, just to show you once again,
we get the same idea. But an interesting thing happens with
the percentage of time spent in this line. Because we're dealing with NumPy arrays,
this is actually much faster. And it turns out that the majority
of time is being spent here. So the take-home message from this,
is that by changing the approach, we not only can improve
the overall run time. But we can also result in
a change of allocation of time within our function itself,
as shown by the line profiler. So what I want you to do is just
to make a note for yourself and record the times above. And comment on how
the efficiency has improved in going from your first
implementation to the last. Okay, let's say that you're
still not happy with that. And, in fact, that you want to do better. We can use something called Cython. Cython is a C translator for your code. So you can actually ask Python through
Cython to convert your code to C. To sort of compile it on the fly and
to run it. Now for that we need to load
another extension called Cython. And let's run this unaltered
haversine function through Cython. So this is our haversine function,
changed just slightly. So to make this into Cython, we need to
use a magic command operating on the cell. That's why we have
the double percent here. And we're going to do cython -a. The only change that we have to
make is we have to definitely do our import inside of our cell. And instead of def we use cpdef. So Cython, definition of haversine, I'm going to define this slightly
different function here, haversine_cy. Just so we can disambiguate it. And now we're going to go,
let's actually run this. And we get some output. So this is creating some C code. So this is what we get. And we're told that the yellow
lines hint at python interaction. And we can click on a line that
starts with a plus to see the C code that Cython generated for it. So let's go ahead and take a look
at something like, dlat=lat2-lat1. Let's go ahead and click on that. And this is the C code
that was generated for us. So you can see really why we don't want
to use C as our programming language for doing analyses or apply data science. We can use Cython to generate C for us. And when C is generated it will
compile down and it should run faster. So let's go ahead and time that Cython version of the haversine
function and see what we get. We're just going to %timeit, and
it looks like it's on the cell. But I have a backslash here just to allow
me to continue that line in a way that we can see it all. And we find out it took 58 milliseconds. And go ahead and compare that either to
the best non Cython version from above, or look at the version of apply above. You'll notice that converting
to C in this particular case has not given us a substantial boost. In fact, this number is basically the same
as our previous version that used apply. The take-home message from this, it's not always worth going
to the C version with Cython. So Cython, you might want to try it. But most of the time we see
the dramatic improvements by going to vectorized
functions on NumPy arrays. Converting to C at that point
doesn't give us a huge boost. Partly because the NumPy code is so
highly optimized.