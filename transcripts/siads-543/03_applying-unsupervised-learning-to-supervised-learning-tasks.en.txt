In this module, we're
going to explore how the unsupervised
learning techniques that we've been covering
in this course, can help with some
of the challenges that you've seen in
supervised learning. We've seen unsupervised methods
like density estimation, clustering,
dimensionality reduction, manifold learning and more. At the same time we've
seen challenges faced by supervised learning methods like the curse of dimensionality. Let's explore how problems in supervised learning could benefit from the methods in this course. This is a high level
view and we're going to be diving more deeply into some of these topics in
other modules for this week. Here's an example
of how clustering can help with the
classification problem. Suppose you're
given a very simple one dimensional
classification task with two classes, A and B. There's only one feature, namely the position of the
instance on the real line. In one sense, it's difficult to separate these two with
single linear classifier. One thing you could do is run
a clustering algorithm to discover that there
were three clusters. In fact there are two
different variants of A and you know this because
you have the labels for A. You can learn two separate
classifiers between A1 and B2. With these two classifiers, you can correctly classify incoming objects into
one of these three, and then as you're telling the prediction results to the final receiver
of your output. You can drop the clustering
distinction of A1 versus A2 and just
report the label A. In this case, clustering
has helped you identify structure
of the labeled data. It's identified that you're data instances that
are labeled with A, A2 distinct regions, and with
two separate classifiers. You can handle this
case very well. So what I'm going to do is look at it from the point of view
of supervised learning. What are the common challenges in supervised learning and how can specific techniques from unsupervised learning
help solve those? Challenge number one, big
problem in supervised learning. There's not enough labeled data, and this is especially true. The more you scale the number of parameters
in your model, labeled Data is the gold of supervised learning
as you well know. It's also very expensive to
acquire, time-consuming. There are often situations where we have a few labeled examples, but many unlabeled examples. In this scenario,
how could we label related examples automatically if they didn't already have a label? There is a way we could
do it quickly, cheaply. Turns out that there
are ways to do that. One approach is to do clustering. To find the related examples. You don't need labels for that. Two things are considered related if they end up in
the same cluster. Then you can just
apply the labels from the labeled examples to the unlabeled ones
in the same cluster. This is a form of what's called semi-supervised learning that we cover in a different
module this week. Particularly we look at a
label propagation method for semi-supervised learning. Another challenge of supervised
learning is overfitting. We often have a scenario
like this where we have say, two classes and we have
a very strong desire to have a high-accuracy
classifier that completely and perfectly
separates the classes. If we use something
where we don't control the amount of variants, we get a decision
boundary that is just way too complex
and overfitting. One approach to reducing
over-fitting using unsupervised learning is to use unsupervised learning
as a type of regularizer. What do I mean by that? What I mean is that
you apply some kind of transformation on
the original data an then you train on that, that's called unsupervised
pre-training. The effect is to take an initial dataset that's maybe has quite a noisy
decision boundary. When you apply a
powerful classifier. You transform it. For example, you do
dimensionality reduction, and then you classify using
that new representation, perhaps that dimensionality
reduced their representation. For example, in this case. But one thing we could
do is we can take the, we have in this case,
two different classes on the left and the right. This is a binary
classification problem. What we could do is we can
apply k-means clustering. We know there are two classes. We could perform k-means
clustering with two clusters to find clusters centroids
for each class. Because that's what
k-means clustering does. Then we could do something like, we could shrink all
the original points towards the cluster centroids. We're transforming
the input data, the original data in a way
that sort of smooths it, reduces the noise, reduces the variation to focus on the essential qualities
of each class, namely where the roughly
the centers are located. Then once we apply that, unsupervised clustering
based transformation, then we fit this powerful
classifier again and it finds very easily a clear
decision boundary with much lower variance. So if you just compare the old high-variance
classifier boundary with the new low variance one, giving the classifier a
smooth version of the data, it was able to find a
better decision boundary between the smooth version so it reduced the noise and the
variation in the data. The third challenge with
supervised learning is the curse of dimensionality, as you've already seen
in the previous course. Processing a dataset with
billions of rows is not too bad because these kinds of operations can be parallelized. We're dividing up operations
among data instances. But if we have billions of
columns, billions of features, can be much harder to parallelize that situation
because for a lot of models you need most or all of the features all at once
to make a decision. So, searching for
nearest neighbors are optimizing a loss-function in very high dimensions can be time-consuming and
computation expensive. So one area where unsupervised learning could help is in dimensionality reduction. You can take the original
high-dimensional dataset, reduce it with
something like PCA, and then apply your sophisticated supervised learning algorithm on that dimensionality
reduced dataset. So some really fun examples, for example, from biology, where they deal with very
long sequences of DNA, RNA. In this case, this example, they've actually developed
an embedding that can map a long RNA sequence to just two numbers, a
two-dimensional embedding. With this embedding,
they can apply more sophisticated classification techniques that might not work in a 100, 500,000, 10,000
dimensional space. Fourth challenge is
supervised learning, feature engineering. How do you decide
which features to use? How do you describe your data instances with
the right set of features. So in traditional
supervised learning, this is an object
of much attention. Representation learning
from unsupervised data can help a lot with the problem
of feature engineering. This is one of the
secrets in deep learning. We're going to review
in a different module, something called self
supervised learning, that makes use of what
are called pretext tasks. So pretext tasks are used to learn a latent representation. They don't require any
labeled data per se, but they result in training a model that can be used for a related
classification task. I'll explain in the self
supervised learning module exactly what that entails. But the basic idea
is that you can train a model with
unlabeled data in a sense, and embeddings are a good example as the word embeddings
that we saw last week are an example of a self supervised
learning task. We didn't need any labeled data to estimate the embedding. All we needed was to be able to take a word out of a sentence, for example, and predict the
context words or vice versa. The resulting embedding
is useful for lots of NLP classification tasks
that aren't really related to the original pretexts task of filling in the
blank of a sentence. We'll cover that in
a different module. Fifth challenge for
supervised learning is if you have data containing outliers. So if you have rare
examples with sort of extreme feature values, these could distort your
results significantly, especially for generative
models that focus on modeling the classes themselves and not just the decision boundary
between the classes. We've seen some examples
of outlier detection, for example, UMAP algorithm. You can also use, say,
density estimation. It computes the probability of a point and if the
probability is too low, according to the model, the point is likely to be an outlier. So if you can do
outlier detection, you can find the outliers, apply one solution for outliers. You can apply second solution and the second predictor for 'normal' instances and deal
with the outliers that way. Here's an example from the first week's notebook where we use the
Gaussian Mixture Model, with the set of unlabeled points, and we identified using the
Gaussian Mixture Model, points like the one
I've just circled, which have very
low probability in this model and thus are at risk of being considered
outlying noise, that they can be removed. You can see if we remove
this point as an outlier, in theory we could do
much better estimation, let's say classifier
between these classes that wasn't necessarily
skewed by having these extraneous points
that could affect the decision boundary
in ways that would be undesirable
for classification. The sixth challenge in
supervised learning, and I can't emphasize
enough how important this is in commercial machine learning pipelines
is significant, significant issue, the
issue of data drift. That occurs when you have
incoming new test data, that's drawn from a different
underlying distribution, than the original model
was trained and tuned on. So one example of how this happens is in search
engine ranking. Ranking team will
train a ranking model, which is a form of regression
model, essentially. Will train the model, but looks good in terms of accuracy, but then of course,
languages evolve, language usage
evolves, certain ideas of relevance evolve and how
the issues of timeliness, quality, and so forth
that change over time. Lots of different reasons. The original rancor that
was trained six months ago, you'll see consistently that it's accuracy falls over time. Eventually after a
few months it needs to be retrained, re-calibrated. One approach to dealing with this data drift is to
do density estimation, to get probability
distributions for assessing how different
the current data is that you're seeing from
the training set data that was used to
create the model. Similar to outlier detection, if too high a fraction of incoming new instances are
low-probability events, we might accumulate
these and then trigger every training if we see too
many of these coming along. This is also called
covariate shift or feature drift in the
case where we have previously unseen
or rare features that suddenly become a lot
more common, or vice versa. There's some shift in the underlying features
for whatever reason. Some features may be based on a noisy source where the underlying noise
is suddenly is fixed, or noise is suddenly
introduced in a feature, or all reasons why you have covariate shift or feature drift. But whatever the reason, it's a very significant machine
learning pipeline issue. Let me show you what I mean with a specific example
of covariate shifts. Suppose we have a
binary classifier, and let's suppose we're trying to classify two different wine, so we're trying to classify low quality wine from
high quality wine. The two features are the price, and let's say some taste measure. We gather information about
price and about taste, and we have some
labels that indicate whether people liked or
didn't like the wine. What might happen is
variable like price may end up increasing over time
for whatever reason, though that will
result into change in the distribution
of the x feature. You'll see new points coming in. If you're trying to
classify new wines according to this model, their prices will have
shifted because of inflation over time or
because of legal reasons. You'll see this shift in
x feature distribution, which of course will
play [inaudible] with the original decision boundary that was based on the old prices. This is a case where you want
to detect the situation, and you want to retrain the classifier to
take into account the new distribution of price features for
those data instances. There are lots of reasons
why this could happen. Things change in the environment. Often there are certain tasks
that are time-dependent. Business forecasting, just trying to capture
evolving market trends. Things become popular
and then unpopular. They become high in demand, and low in demand that affects the price and the availability. There are monthly and
seasonality effects, certain sports are more popular in certain
seasons, for example. Sometimes the drift is due to selection bias in
the original data where you've sampled from
an unrepresentative group, to create your training set. Sometimes there are
changes in data quality. A previously reliable feature is lost or becomes unavailable. There's a related concept
called concept drift, where the feature
distribution is unchanged. But the definition of
the label changes. Concept drift happens when, let's say the wine example, people may, there
may be no change in the price or the taste
measurements of wine. But the judges that you get, that judge whether a wine
is high-quality or not, may come from a
different area where different criteria of quality
are important or not, and that affects the labels. Concept drift affects
the label definitions, and not the feature definitions. Concept drift is also a very important problem to
be aware of, and to detect. Finally, we have a
very frequent problem in supervised learning
where we have missing data. There are certain
features that have cells that have NaN, or zero, or blank and so
there's a class of methods that we'll explore
in one of the modules this week as well
called data imputation. We'll look at basic imputation versus iterative imputation. We'll look at using just the numbers in the single
column to fix that column, or whether we can use multiple columns to infer missing values in a given column. In this case, we can actually use supervised learning to
predict missing features. We can basically
take our dataset, use some supervised
learning method like random forests to predict
missing features, fill those in and then we can apply supervised learning on the training set with the different
classifier potentially in order to do the
classification task. Some data imputation methods
use supervised learning, somewhat use
unsupervised learning like [inaudible] composition. We'll look at that in the
data imputation module that's also this week. Just to sum up, there are about seven different
key problems that supervised learning has, that unsupervised
learning can help with. It can help with there not
being enough labels by using semi-supervised methods
like label propagation, unsupervised learning
can help with overfitting by smoothing the data and transforming it in some way. Can help with curse
of dimensionality by doing drastic dimensionality
reduction if needed, you can help with
feature engineering, by self supervised methods. It can help with outliers
that might skew results by detecting them with methods like density estimation or UMAP. Covariate shift is something
that density estimation, for example, can help detect these differences in training
and test distributions. Finally, data imputation methods, which may be supervised or
unsupervised can help with missing features in
the training set for supervised learning problems. That's our summary of how
unsupervised learning can help with these key
supervised learning problems. Take a look at the modules
for data imputation, semi-supervised
learning, and self supervised learning this week
to get more information.