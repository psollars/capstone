So I've been talking all
along about how we're doing all this work to be super
fast and super efficient, and I've been drawing
pictures of indexes, and stuff like that. So finally, it's time
to talk about them. So we're going to talk
about indexes now. So the first thing that
we're going to do is we're going talk about keys. Keys are when we're making
connections between tables. We connect one table
to another table, and I kept saying
that's the relation, right? That's the relationship between
this table and the other table. And we need to be able
to put columns in tables that are kind of like
our handles for rows. They're our way to reference
a row super efficiently, right? And later we're going to figure out how to build these tables, but we're going to
start today just talking about how we put a
number on every row. Now, it turns out that we can pretty much say
this is row 1, 2, 3, 4, 5. So we kind of build this sequence, and it's an
auto-incrementing sequence and it's automatically. So if two data records are coming in from multiple
sources as fast as possible, the database kind of takes
them as a funnel, and then carefully assigns
them sequential numbers. You never get a
duplicate, no matter how fast these records come in. And so the database sort of says, "lock, add one, insert, lock, add one, insert, lock, add one, insert," and so that's something
that database takes care of us regardless
of the number and the speed of the
records that are coming in. And in Postgres, and if you ever
look at other languages like MySQL or SQLite,
it's harder than this. But PostgreSQL is like, "I'll make this easy,"
because it turns out that we do the same
thing over and over, and in all those other languages, all those other databases, I simply copy and paste
this long ugly line. But in Postgres, we
just say SERIAL. So id is a serially incrementally
automatic increment thing that just gets every
time we insert it. Now we don't have to put
it on an INSERT statement, because it's automatically
generated by the database. So we'll still be inserting
on name and email. And then we can say PRIMARY KEY. And so what PRIMARY KEY does
is it says, "build an index for this," and it's the index we're
going to use the most. This is going to be
an integer number, and integer indexes are like
scorchingly fast. There's been thousands of people who have researched how to make integer indexes super fast, and you don't need
to know any of that. So you just need to know that each row has a little
handle on it 1, 2, 3, 4, and then there
is an index here that's PRIMARY KEY that we can go and find one of these super fast. So that's this index that sits here. And by saying PRIMARY KEY, and you're not really telling it how to
implement a primary key. You're just communicating the
fact that I'm going to use this particular
little id field in a very special way and
be prepared, database, be prepared because I'm
going to use it that way. The other thing we
can do in this one that you can see is
this UNIQUE constraint. This is what we
call a logical key, and so the uniqueness
basically says, "we are not allowed to insert the same email address
twice on this column, that column is unique." And this is what we'd
call a logical key, and that means if you try to insert it twice,
it's going to blow up. Now, the way it works is there's all these rows with
emails in them, and then there's another index, which is the addresses, and then it looks in
this index and says, "oh, wait a second, you
already have one here. No, you're not allowed
to insert that." And so the uniqueness
is a just like the 128, is a constraint in the schema
that you are communicating, and then the database is
going to enforce on you. Right? Now, it turns out that
this index that it makes, it kind of realizes that index
can then be used to speed access to certain records, and in this particular index it's probably going
to make it so that sorting and prefix searching
is going to be super fast. And like you don't
even need to know that. All you just say is like,
"Ah, this is unique." And like, "Oh, I know
what to do with that. I will implement something
really nice for you. I've a little surprise for you. The next time you do a SELECT statement on your
one million records, it's going to be 20 times faster just because
you told me that." So there's a whole
bunch of functions, I won't go through them all. NOW is the function that
we use for dates and NOW is 98 percent of my
function use. Sometimes I'll do
concatenations or sub-strings. Those
things that you can do with functions. Now, indexes. I've been talking
about the indexes from the beginning and
now I kind of talk them. So like talk about them
a little more. So when I log into Twitter, they got to go my password find my password among
500 million users, and the key thing is
to shorten the scan, right? I keep saying that it's a couple of
terabytes and if you go through it, even
on a fast disk drive. if you go through
it sequentially, it's minutes. Try to back your whole hard
drive up some time. And that's how long it takes to read all the data
on your hard drive. So you're not really scanning
the whole data, right? So the whole idea of indexes
is they're shortcuts. They're shortcuts so you
know exactly where to go. So let's take a look at the
two most common indexes. Trees and hashes are
the most common index. So B-trees, I mean all this
data ends up stored on disk, and an index is
more data on disk. And so when you add an index like UNIQUE or PRIMARY
KEY to a column, you actually are telling the
database store more data. So you're telling the database don't just store the
data I gave you, but store the data about
where that data is. And so the idea of a B-tree, and the B kind of stands for
balanced or binary, is that you go to a place, and then it's sorted, and you can kind of pick a range,
right? And then you pick a range, and that tells you perhaps
another index block to read, and then you pick a range
in that index block, and then that tells you
another index block to read, or maybe it tells you
to go right to disk. And so instead of having
a million disk reads, you get to do sort of log of
a million, the log, it's the log and that's
why it's balanced. So to go through a
million records, you might actually only
have to hit the disk in six blocks of the disk. The first block,
the second block, the third block, and then
the actual data block. Right? So that's called a B-tree. So let me draw a
picture of the B-tree sort of in the way that I've been
drawing it all long, so to connect back to this. So remember I'm talking about some data that's like let's just call
it a terabyte of data, and if you have to scan
a terabyte of data, you're going through
it sort of in sequence, right? And so what you do is if this has some kind of a
sorted structure, kind of going back to that
sequential master update, you can basically have an
index that gives you ranges. So you can break
this into ranges of data depending on the
size of each disk block. And then for each of the ranges, you make a little sort of a
index that shows you the start and the stop
in each of those ranges. And then you come and
you read the index which itself as a
small amount of data, and then based on that, you can pick the right range. You come in, you read a small
amount of data, figure out which of
these things by reading here, and then go straight to
the right range on the disk. So I'm just showing
you a two-level, there might be more
than one level. And so that's the basic idea, but this is sort of sorted, but there's also blocks so there's sorting
within blocks, and the whole thing
doesn't have to be sorted, and so that's the
idea of a tree index. Now, the cool thing about
tree indexes is that they are good for exact
match lookup like if you're looking up
the email address of someone who just typed
it in a login form. They also help for sorting. They also help for range lookups because you can end
up knowing that you just have to grab a chunk of the data ultimately
for range lookups. They're also good
for prefix lookups, because prefixes are like ranges because you kind of
grab a little bit, and that turns into a range, and then you scan that
range sequentially, but it's a lot smaller than scanning the entire
thing sequentially. So, hashes. So a hash is a little different. And the hashes are often used in things like those integer keys to
make them super fast. So a hash is a computation. You scan the string and
you compute a number. It could be as
simple as adding up the letters and dividing
by a million or adding the letters up and treating every letter like a number,
like J might be 11, and O might be 14, whatever
their sequential numbers. Add all those numbers up, and then divide by a million, and then take the remainder
of the division by a million, and then use it as
an offset, right? And so it's a calculation that you do. Now if you go
read about hashing, you'll find that
there are people who spend their whole life researching the
best hash function, and if you read you'll hit
things like MD5, SHA1, SHA256, these are all hashing algorithms. Actually, the NIST organization that
helped build SQL, the NIST organization
that helped build SQL also helps build hashes.
Hashes are standards, and there's actually
competitions that people spend years of
their life figuring out the best way to take large and small blobs of text and have the
best possible hash. The cool thing about hashing
as a database technique is it really reduces the number. So if you think about the number of in a B-tree if you have
a large number of records, the number of accesses
goes by the log of them. Log is really a great
reduction. If you can say the log of a
million is like six, the log of 10 million
is like seven. So log is really slow growing. But the hashes are even shorter. Now the problem with hashes, and the reason we don't use
them for everything, is that hashes are only good
for exact match. You are prefix matching,
they are no good. The data gets completely
non-sorted, so that's no good. So if you're looking up like a name or you're
going to do sorting, then hash doesn't work. It turns out that what
hashes are really good for is primary keys or GUID, Globally Unique
Identifier kinds of lookups. And when they do that, they are super scorchingly fast.
Okay? So hashes are awesome. Now, I'm just telling you about these
two indexing mechanisms not because I want you
to decide between them, because often
the database will automatically decide
for you which kind of index. You just kind of say this is
a primary key index, chance are good that'll
be a hash, or if you say UNIQUE on a string field, chances are good that's going
to be a B-tree, because those are how
those things work. But in general we
even leave some of these decisions to
behind the abstraction, and just say, "hey, database
you're smarter than I am. You got a lot of PhDs that
work on all this stuff, and so you just worry about that, I'm not going to worry about it." So SQL is my favorite language. I'm glad to be
teaching it to you. Unfortunately, everything in the world
can't be written in SQL, but we can certainly
describe our data with that, and the whole idea
is we describe the shape, the schema of
the data to be stored, and then we have a simple set of primitives that allow
us to store and retrieve the data, the create, read, update, and delete. So thanks for listening
and welcome to SQL.