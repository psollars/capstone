## Siads 503 Syllabus: Data Science Ethics

This document includes:

I. Course Basics II. Course Schedule (list of required readings for each week)
III. Further Readings/Listings (related to each week's topics)
IV. Additional Course Policies V. Acknowledgements

## I. Course Basics Course Overview And Prerequisites

This class will teach you to recognize where ethical issues can arise when applying data science to real world problems. It will bring more analytic precision to ethical debates about the role that data science, machine learning, and artificial intelligence play in consequential decision-making in commerce, employment, finance, healthcare, education, policing, and other areas. Largely through discussions of case studies, we will focus on ways to conceptualize, measure, and mitigate harm in data-driven decision-making. You will learn to think critically about how to plan and evaluate a data science project with ethical concerns in mind, and how to cope with novel challenges for which there are often no easy answers or established solutions. To do so, you will learn key technical, ethical, policy, and legal terms and concepts that are relevant to ethical assessment in data science; learn about some of the common approaches and emerging tools for mitigating or managing these ethical concerns; and gain exposure to readings that will help you understand the current ethical and regulatory environment and to anticipate future developments. Ultimately, the class will teach you how to reason through these problems in a systematic manner and how to justify and defend your approach to dealing with them. The prerequisites for this course are admission into the Masters in Applied Data Science program and successful completion of SIADS 501, "Being a Data Scientist."

## Instructional Team

Instructor: Dr. Melissa Chalmers Instructional Team: Merve Hickok; Dr. Nick Sheltrown; Ruth Corddry; Jake Huang; Alexis Castellanos; Emily Schemanske; Mike Clark Members of the instructional team play different roles:

- Melissa and Merve have recorded course videos and iterated course content (e.g.   readings, assignments, and quizzes) since the course was launched in 2020. They, along with Nick and Ruth, look forward to interacting with you about course concepts and other content on Slack and in office hours.
- The lecturers supporting SIADS 503 - Melissa, Merve, Nick, and Ruth - should be your   first point of contact for everything related to assignments and grading. They are here to support your learning, and will be happy to help you get the support you need to be successful in the course. (Please see "how to get help" below)
- The other team members supporting SIADS 503 - Alexis, Emily and Mike - will spend   most of their time behind the scenes grading your work, but you may also engage with them in Office Hours, or on Slack.

## Communications Expectations

Slack is the primary communication mechanism between the instructional team and students for this course. If you do not use Slack, you will likely miss out on important updates, feedback, and discussions on topics of interest to the course.

- Course channel in Slack = siads503_fa23_001
- Slack response time: within 24 hours; weekend responses may be longer - Email response time: N/A; please use Slack - Office Hours: Wednesday 5 - 6 PM (Eastern (Ann Arbor) time), and Sunday 11 am -   12 pm (Eastern (Ann Arbor) time). Please refer to the Live Events page on Coursera.

## How To Get Help

This is a large class, but it's still easy to get help if you need it:

- _Questions likely to be of general interest to other students in the class:_ please post to the   course Slack channel. Note that there will be pinned posts for conversations about each of the four weekly assignments.
- _To request additional individualized feedback or support on weekly assignments:_ If you   got feedback that you are having trouble understanding, or perhaps you disagree with it and would like some substantive advice on how to improve in future weeks, please   follow these steps:
- Write up as specific a question as you can, including enough context for the   instructor team to understand it. Be sure to include your best interpretation of what the feedback is telling you.
- Send a Slack DM to **ALL FOUR of the following lecturers** : @Melissa   Chalmers, @Merve Hickok, @Nick Sheltrown, and @Ruth Corddry. One of us will get back to you in the shared slack thread, usually within 24 hours.
- _If you have questions concerning the degree program or encounter issues using Slack_ ,   please email umsimadshelp@umich.edu
- If you have an issue specific to the Coursera environment, you can begin a live chat   session with Coursera Technical Support (24/7) or view Coursera troubleshooting guides . (You may be asked to log in to your Coursera account).

## Required Textbook

You will be given a list of required and recommended readings within the course and also below in Course Schedule (section II). For more information, see Further Readings/Listenings (section III). Online access to these readings is provided through the University of Michigan Library or through approved online sources. For resources provided through the library, you will be asked to sign in with your UMich uniqname and password to access these materials. This course does not require the purchase of a textbook.

## Course Learning Outcomes

1.  Understand the most critical concepts and principles of ethics that apply to data science     and outcomes.
2.  Identify potential harms of data collection, aggregation, analysis, and use typically found     in applied data science contexts.
3.  Identify potential causes of bias and discrimination using data, and evaluate whether a     data-driven system is discriminatory to any system stakeholders.
4.  Remain vigilant of potential discriminatory outcomes when building data science     solution(s); engage in multidisciplinary conversations to actively work against discrimination for solution(s) stakeholders.
5.  Understand, identify, and discuss how data and algorithms have been used to     perpetuate racism; Introduce how to correct, combat, and prevent racism using anti-racist data and algorithmic practices.
6.  Apply course concepts to written ethical assessments and recommendations (e.g. a     memorandum) for applied data science use cases (e.g. automated decision-making systems).
7.  Articulate reasoning behind the most important ethical challenges of data science as     applied to course domains of privacy, bias/classification, provenance/aggregation, power imbalances, accountability/consequences.     Please note that you will also see "Learning Objectives" listed at the start of each week. Think of these as "Goals for This Week."

## Course Structure

Each week, this course consists of **recorded lectures, required and recommended readings** , and two **office hours** produced by the teaching team. Lectures consist of overview material about concepts as well as the discussion of case studies. In addition, a guest speaker will visit or we will take a field trip. This will provide one or more additional recorded lectures, interviews, or conversations. Lectures supplement but do not always review or duplicate the readings; readings supplement but do not always duplicate the lectures. That means some of the course content is available only from a lecture or a reading. For instance a concept may not be mentioned in a lecture, but it may be the key point of a reading. Students are still responsible for that material. A low-stakes, open-book weekly **quiz** will provide an incentive to keep up with the readings/lecture content. The primary work of the course is one writing assignment each week. Office hours offer us the opportunity for the teaching team and students to discuss course topics more informally; there will be opportunities for both student-generated questions and conversation as well as teaching-team led presentations of content related to both course topics and assignments. We also hope to welcome some guests to shed light on how ethics issues manifest in real-life professional situations. Specific information for each week is below in Course Schedule (section II).

## Course Deadlines

This course begins on **Tuesday, October 24** and ends on **Monday, November 20** . Weekly Quizzes and Writing Assignments will be due on Mondays at 11:59 pm (time zone is Ann Arbor, Michigan; Eastern Time). The Extra Credit assignment will be due on Monday, October 20 at 11:59 pm (time zone is Ann Arbor, Michigan; Eastern Time).

## Grading Assignment Type - % Of Final Grade

Weekly Quizzes (4 quizzes; lowest score dropped) - 10% Weekly Writing Assignments - 90%

- Week 1: Memo about a privacy concern (15%)
- Week 2: Evaluation of the What-If Tool (25%) - Week 3: Perform an algorithmic impact assessment (25%) - Week 4: Design an ethics oath, pledge, or checklist (25%)   Extra Credit - Write Your Own Quiz Questions - (up to 2.5% EC) Note: You are required to attempt/complete _all assignments (except extra credit)_ in order to earn credit for this course.

## Letter Grades, Course Grades, And Late Submission Policy

Refer to the MADS Assignment Submission and Grading Policies section of the UMSI Student Handbook (access to Student Orientation course required) Final letter grades for the course will be calculated using the following scale: A+ 98%+; A 93-97%; A- 90-92%; B+ 87-89%; B 83-86%; B- 80-82%; C+ 77-79%; C 73-76%; C- 70-72%; D+ 67-69%; D 63-66%; D- 60-62%; E 59% or below. Coursera does not round up or down (e.g. 86.78% = B). Late submissions receive 10% penalty per day.

## Regrade Requests Policy

Graders may make mistakes. Gradescope has a system for regrade requests; please use it to request review of an assignment, and describe why you think that the initial grading was incorrect. Regrade requests will be handled by a different grader. The entire assignment will be regraded, applying all elements of the grading rubric. Your grade could go up or down.

## Revise And Resubmit

You will have the opportunity to revise and resubmit **one** assignment. This is not required, but is rather an opportunity to recover from a misstep and earn additional points by responding to feedback and improving your submission. Your revised assignment may earn up to the median score for that assignment. The assignment will be graded using the same rubric as the initial submission. We do not begin with the median grade and then subtract points, but instead add points as usual and award points up to and including the median score. Points above the median score will not be reflected in your grade. Median score for each assignment will be posted on Slack after the grades are released.

## Ii. Course Schedule Week 1: Introduction To Data Science Ethics, Top Misconceptions About Data Science Ethics, And Data Privacy Learning Objectives:

Apply recommendations and perspectives about data privacy from case studies and literature presented. Recognize instances of Zook's "10 simple rules of responsible big data research". Identify and avoid misconceptions or common mistakes about data science ethics in given situations. Identify different perspectives about data privacy from literature and case studies presented, and describe tensions between these perspectives. Recognize and explain a data privacy problem using professional concepts and terminology.

## Required Readings | Introduction To Data Science Ethics And Top Misconceptions About Data Science Ethics:

Loukides, M., Mason, H., & Patil, D. J. (2018). Doing good data science. In Ethics and data science. O'Reilly Media. > Read Chapter 1 "Doing Good Data Science" Floridi, L. & Taddeo, M. (2016). What is data ethics? Philosophical Transactions of the Royal Society A, 374(2083). https://doi.org/10.1098/rsta.2016.0360 Zook, M., Barocas, S., boyd, d., Crawford, K., Keller, E., Gangadharan, S.P., Goodman, A., Hollander, R., Koenig, B. A., Metcalf, J., Narayanan, A., Nelson, A., & Frank Pasquale. (2017). Ten simple rules for responsible big data research. _PLOS Computational Biology, 13_ (3):1–11.

## Required Readings & Viewing | Data Privacy:

Solove, D. J. (2011, May 15). Why privacy matters even if you have 'nothing to hide'. Chronicle of Higher Education , _15_ . https://www.chronicle.com/article/why-privacy-matters-even-if-you-have-nothing-to-hide/
Barocas, S., & Nissenbaum, H. (2014). Computing ethics: Big data's end run around procedural privacy protections. _Communications of the ACM, 57_ (11): 31-33. Bracken, K., & Harmon, A. (2010, April). Blood journey [Video]. The New York Times. https://www.nytimes.com/video/us/1247467672743/blood-journey.html Madden, M., Gilman, M., Levy, K., & Marwick, A. (2017). Privacy, poverty, and big data: A matrix of vulnerabilities for poor Americans. _Washington University Law Review_ , _95_ . > Read pages 53-67 Harwell, D. (2019, December 24). Colleges are turning students' phones into surveillance machines, tracking the locations of hundreds of thousands. The Washington Post. washingtonpost.com.

## Week 2: Bias And Classification Learning Objectives:

Identify and explain instances when data science incorporates harmful bias and may cause discriminatory outcomes or deepen inequalities Identify and explain ethical problems that arise during routine classification work. Demonstrate familiarity with selected tactics to promote fairness and mitigate harmful discrimination.

## Required Readings & Viewing:

Gandy, O. (2012). Statistical surveillance: Remote sensing in the digital age. In K. Ball, K. Haggerty, K., & D. Lyon (Eds.). _Routledge Handbook of Surveillance Studies_ (1st ed.) (pp. 125 -
132). Routledge. https://doi-org.proxy.lib.umich.edu/10.4324/9780203814949 > Read chapter by Oscar Gandy American Civil Liberties Union. (2004). _Scary pizza_ [Video]. Youtube. https://www.youtube.com/watch?v=33CIVjvYyEk Raji, D. (2020, December 10). How our data encodes systematic racism. MIT Technology Review. Angwin, Ju., Larson, J., Mattu, S., & Kirchner, L. (2016, June 6). Machine bias: Two drug possession arrests. _The Louisiana Weekly, 90_ (38). > Note: This reporting provides additional context related to the COMPAS data and risk assessment in the criminal justice system. It is not required but may be useful to add to your understanding.

[Recommended] Bao, M., Zhou, A., Zottola, S., Brubach, B., Desmarais, S., Horowitz, A., Lum, K., & Venkatasubramanian, S. (2022, April 28). It's COMPASlicated: The messy relationship between RAI datasets and algorithmic fairness benchmarks. 35th Conference on Neural Information Processing Systems.

Hill, K. (2020, August 3). Wrongfully Accused By an Algorithm. _The New York Times_ . https://www-proquest-com.proxy.lib.umich.edu/docview/2416163146 (with The New York Times subscription: https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html ) > Note: This incident in Detroit transpired after the field trip and interview with Tawana Petty was recorded. It is a very striking example of some of the unintended harmful consequences emerging from the deployment of facial recognition technology by police departments. Citron, D. K., and Pasquale, F. (2014). The scored society: Due process for automated predictions. _Washington Law Review 89_ (1). Hanna, A., Denton, E., Smart, A., & Smith-Loud, J. (2020). Towards a critical race methodology in algorithmic fairness. Proceedings of the 2020 conference on fairness, accountability, and transparency , 501-512. https://dl.acm.org/doi/10.1145/3351095.3372826

## Week 3: Data Provenance, Aggregation, And Trust Learning Objectives:

Identify ethical issues raised by different sources of data. Draw logical conclusions about problems with using publicly available data in data science work. Draw logical conclusions about the problems of sampling in data science work. Conduct an impact assessment for a hypothetical automation system that employs data science.

## Required Readings:

Rieder, G. & Simon, J. (2016) Datatrust: Or, the political quest for numerical evidence and the epistemologies of Big Data. _Big Data & Society 3_ (1), 1–6. https://doi.org/10.1177/2053951716649398 Onuoha, M. (2016). The point of collection. Data & Society: Points, https://points.datasociety.net/the-point-of-collection-8ee44ad7c2fa Martinex, E. & Kirchner. L. (2021, August 25). Secret bias hidden in mortgage-approval algorithms. The Markup, https://themarkup.org/denied/2021/08/25/the-secret-bias-hidden-in-mortgage-approval-algorithm s Melendez, S. & Pasternak, A. (2019, March 2). Here are the data brokers quietly buying and selling your personal information. Fast Company. Kalluri, P. (2020, July 9). Don't ask if artificial intelligence is good or fair, ask how it shifts power. Nature, 583, 169. https://www.nature.com/articles/d41586-020-02003-2 Hao, Karen. (2022, April 22). A new vision of artificial intelligence for the people. MIT Technology Review. https://www.technologyreview.com/2022/04/22/1050394/artificial-intelligence-for-the-people/

## Week 4: Accountability And Governance Learning Objectives:

Understand different data governance mechanisms and strategies. Understand the utility and limits of algorithm audits and reverse engineering as accountability strategies. Recognize and infer the limits of the transparency ideal. Recognize and infer major challenges of conducting an external audit. Discuss and explain the design of checklists and related tactics as a way to improve data science ethics in organizations.

## Required Readings | Accountability & Governance:

Wallach, H. (2014, December 14). Big data, machine learning, and the social sciences: Fairness, accountability, and transparency. Medium.

https://hannawallach.medium.com/big-data-machine-learning-and-the-social-sciences-927a8e2 0460d Ananny, M., & Crawford, K. (2018). Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability. _new media & society, 20_ (3), 973 - 989. Sandvig, C., Hamilton, K., Karahalios, K., & Langbort, C. (2014). Auditing algorithms: Research methods for detecting discrimination on internet platforms. Computational Culture. Diakopoulos, N. (2015). Algorithmic accountability. _Digital Journalism, 3_ (3): 398-415.

## Required Readings | Conclusion: Professional Ethics Oaths, Pledges, Checklists:

Loukides,M., Mason, H., & Patil, D. J. (2018). Of oaths and checklists. In Ethics and Data Science. O'Reilly Media.

> Read Chapter 2, Of oaths and checklists

## Iii. Further Readings/Listenings Week 1: Introduction To Data Science Ethics, Top Misconceptions About Data Science Ethics, And Data Privacy Further Readings/Listenings: Introduction To Data Science Ethics & Top Misconceptions About Data Science Ethics

Ananny, M. (2016). Toward an ethics of algorithms : Convening observation , probability , and timeliness. _Science, Technology, & Human Values, 41_ (1):93–117. Brey, P. A. E. (2012). Anticipating ethical issues in emerging IT. Ethics and Information Technology, 14, 3015-317. D'Ignazio, C. and Klein, L.F. (2020). _Data feminism_ . MIT Press. Labbé, C. (Host). (2019, May 2). Solon Barocas on teaching ethics in data science (Episode 8) [Audio podcast episode]. In _Good Code._ Cornell Tech. Metcalf, J., Moss, E., & boyd, d. (2019). Owning ethics: Corporate logics, Silicon Valley, and the institutionalization of ethics. _Social Research: An International Quarterly, 82_ (2):449–76. Moor, J. H. (2005). Why we need better ethics for emerging technologies, Ethics and Information Technology, 7, 111-119. O'Neil, C. (2014). On being a data skeptic. O'Reilly Media, Inc. https://learning.oreilly.com/library/view/on-being-a/9781491947227/ Salganik, M. J. (2019). Ethics. In _Bit by bit: Social research in the digital age_ (pp. 281-354). Princeton University Press. https://www.bitbybitbook.com/en/1st-ed/ethics/ Singer, N. (2018, February 12). Tech's ethical 'dark side': Harvard, Stanford and others want to address it. The New York Times.

## Further Readings/Listenings: Data Privacy (General)

Cate, F. H. (2006). The failure of fair information practice principles. In J. K. Winn, & G. Howells (Eds.), _Consumer protection in the age of the "information economy"_ (pp. 341 - 433).

Taylor & Francis Group. > The following sections are likely most relevant: The Evolution of Fair Information Practice Principles, 343-346 (stop at "The OECD Guidelines"); The FTC Privacy Principles, 350-351 (stop at "The APEC Privacy Framework"); The Focus on Consumer Control/The Focus on Notice and Choice/Many Notices that Few People Read/Notices that Few People Understand/The Cost of Choice/The Benefits of No Choice/The Illusion of Choice, 354-365 (stop at "National Law in a Global World"); A Modest Proposal, 367-372 (stop at "Conclusion") Cate, F. H. and Mayer-Schonberger, V. (May 20, 2013). Notice and consent in a world of big data. _International Data Privacy Law 3_ (2) , 67–73. Helm, P. (2018). Treating sensitive topics online: A privacy dilemma. Ethics and Information Technology 20 (4), 303–13. Labbé, C. (Host). (2019, March 26). Helen Nissenbaum on Post-Consent Privacy. (Episode 2) [Audio podcast episode]. In _Good Code._ Cornell Tech. Narayanan, A., & Shmatikov, V. (2010). Myths and fallacies of "personally identifiable information." _Communications of the ACM 53_ (6), 26. Nissenbaum, H. (2010). Privacy in context : Technology, policy, and the integrity of social life . Stanford Law Books. Sambasivan, N., Checkley, G., Batool, A., Ahmed, N., Nemer, D., Gaytán-Lugo, L. S., Matthews, T., Consolvo, S., & Churchill, E. (2018). "Privacy is not for me, it's for those rich women": Performative privacy practices on mobile phones by women in South Asia. USENIX Symposium on Usable Privacy and Security, 127-142. https://nithyasambasivancom.files.wordpress.com/2018/06/performativeprivacy_soups.pdf Schermer, B. W., Custers, B. H. M., & Van der Hof, S. (2014). The crisis of consent: How stronger legal protection may lead to weaker consent in data protection. Ethics and Information Technology, 16, 171-182. Solove, D. J. (2013). Introduction: Privacy self-management and the consent dilemma. Harvard Law Review 126 (7), 1880–1903. > The following section is likely most relevant: I. privacy self-management 1880-1893

## Further Readings/Listenings: Data Privacy (Genetics Domain Example)

Allyse M. A., Robinson, D.H., Ferber, M. J., & Sharp, R. R. (2018). Direct-to-consumer genetic testing 2.0: Emerging models of direct-to-consumer genetic testing. Mayo Clinic Proceedings, 93 (1), 113-20 Kowal, E., Radin, J., & Reardon, J. (2013). Indigenous body parts, mutating temporalities, and the half-lives of postcolonial technoscience. _Social Studies of Science 43_ (4), 465-483.

Mcguire, A. L., & Beskow, L. M. (2010). Informed consent in genomics and genetic research. Annual Review of Genomics and Human Genetics, 11, 361–81. Messner, D. A. (2011). Informed choice in direct-to-consumer genetic testing for Alzheimer and other diseases: Lessons from two cases. _New Genetics and Society, 30,_ 59-72. https://doi-org.proxy.lib.umich.edu/10.1080/14636778.2011.552300 Udesky, L. (2011). The ethics of direct-to-consumer genetic testing. _The Lancet 376_ (9750), 1377–78.

## Week 2: Bias And Classification

Angwin, J., Larson, J., Kirchner, L., & Mattu, S. (2017, April 5) Minority neighborhoods pay higher car insurance than white neighborhoods with the same risk. ProPublica. Bender, E., Gebru, T., McMillan-Major, A., & Shmitchell. (2021). On the dangers of stochastic parrots: Can language models be too big? FAccT '21. https://dl.acm.org/doi/pdf/10.1145/3442188.3445922 Benjamin, R. (2019). _Race after technology: Abolitionist tools for the new Jim Code_ . Polity Press. Bowker, G. C., & Star, S. L. (1999). Some tricks of the trade in analyzing classification, In Sorting Things Out: Classification and Its Consequences (pp. 33-50). MIT Press. boyd, d., Levy, K., & Marwick, A. (2014). The networked nature of algorithmic discrimination. Open Technology Institute. Buolamwini, J. & Gebru, T. (2017). Gender shades: Intersectional accuracy disparities in commercial gender classification. _Proceedings of Machine Learning Research, 81,_ 77-91.

- Also see Buolamwini, J. (2016, November). How I'm fighting bias in algorithms   [Address]. TEDxBeaconStreet, Brookline, MA. https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms   Chen, L., Ma, R., Hannák, A., & Wilson, C. (2018). Investigating the impact of gender on rank in resume search engines. Proceedings of the 2018 ACM Conference on Computer-Human Interaction (CHI'18). Eubanks, V. (2018). Automating inequality: How high-tech tools profile, police, and punish the poor . St. Martin's Press. Haimson, O. L., & Hoffmann, A. L. (2016). Constructing and enforcing 'authentic' identity online: Facebook, real names, and non-normative identities. _First Monday, 21,_ 6.

Noble, S. U. (2018). _Algorithms of oppression: How search engines reinforce racism_ . New York University Press. Sandvig, C. (2015). Seeing the sort: The aesthetic and industrial defense of 'The Algorithm.' Media-N: Journal of the New Media Caucus 10 (3).

## Week 3: Data Provenance, Aggregation, And Trust

Allen, M. (2018, July 17). Health insurers are vacuuming up details about you - and it could raise your rates. ProPublica. https://www.propublica.org/article/health-insurers-are-vacuuming-up-details-about-you-and-it-co uld-raise-your-rates Benjamin, R. (2021). Race to the Future? Reimagining the Default Settings of Technology & Society [Video]. AAAS Annual Meeting. https://www.youtube.com/watch?v=8IJKA8ciZCg > watch first 12:30 minutes Franz, N. M. (2018). To increase trust, change the social design behind aggregated biodiversity data. Database. https://academic-oup-com.proxy.lib.umich.edu/database/article/doi/10.1093/database/bax100/47 91171 Martin, K.E. (2015, June). Ethical issues in the big data industry. _MIS Quarterly Executive, 14_ (3), 67 - 85. https://www.researchgate.net/profile/Kirsten-Martin-2/publication/340465839_Ethical_Issues_in_ the_Big_Data_Industry/links/61b753e44b318a6970db2f70/Ethical-Issues-in-the-Big-Data-Indust ry.pdf McFarland, M. (2012). Ethical implications of data aggregation. Makkula Center for Applied Ethics at Santa Clara University.

https://www.scu.edu/ethics/focus-areas/internet-ethics/resources/ethical-implications-of-data-ag gregation/

## Week 4: Accountability And Governance Further Readings/Listenings | Accountability & Governance:

boyd, d. (2017) Toward Accountability: Data, Fairness, Algorithms, Consequences. Data and Society: Points. [blog post] D'Ignazio, C. and Klein, L.F. (2020). The power chapter. In _Data Feminism_ (pp. 21-47). MIT Press. https://direct-mit-edu.proxy.lib.umich.edu/books/book/4660/Data-Feminism Green, B. (2019, December). "Good" isn't good enough . AI for Social Good workshop, NeurIPS, Vancouver, Canada. Karppi, T., & Crawford, K. (2015). Social media, financial algorithms and the hack crash. Theory, Culture & Society, 33 (1), 73–92. Pasquale, Frank. (2015). The black box society: The secret algorithms that control money and information. Harvard University Press. > Read the following chapters: Ch. 1: The Need to Know, Ch. 6: Toward an Intelligible Society. Pasquale, Frank. (2006). Rankings, reductionism, and responsibility . Cleveland State Law Review, 54(1), 115-139.

Song, C., & Shmatikov. (2019). Auditing text generation models. KDD '19.

https://dl.acm.org/doi/pdf/10.1145/3292500.3330885

## Further Readings/Listenings | Conclusion: Professional Ethics Oaths, Pledges, Checklists:

Loukides, M., Mason, H., & Patil, D. J. (2018). Data's Day of Reckoning. In Ethics and Data Science. O'Reilly Media. > Read Chapter 4, Data's day of reckoning Simonite, T. (2018, February 8). Should data scientists adhere to a Hippocratic Oath? _Wired_ . https://www.wired.com/story/should-data-scientists-adhere-to-a-hippocratic-oath/ United Nations. (1948). _Universal Declaration of Human Rights_ . https://www.un.org/en/universal-declaration-human-rights/

## Iv. Additional Course Policies Academic Integrity Collaboration

UMSI strongly encourages collaboration while working on some assignments, such as work on team projects and interpreting reading assignments as a general practice. Active learning is effective. You must, however, write your individual assignment submissions on your own, in your own words. You should not collaborate on quizzes. Read the instructions carefully and request clarification about collaboration when in doubt.

## Plagiarism

Unless otherwise specified in an assignment, all submitted work must be your own original work. Any excerpts, statements, or phrases from the work of others must be clearly identified as a quotation, and a proper citation provided (inline and reference list). Ideas and concepts from course or external materials used in assignment submissions must also be properly cited (inline and in a reference list). If you do not cite the source of the ideas or quotations you use, this is considered plagiarism. In this course, an assignment containing plagiarized material will receive zero points. This applies whether the plagiarism is intentional or inadvertent. Any violation of the School's policy on Academic and Professional Integrity (stated in the MADS Student Handbook ) will also be reported to UMSI Student Affairs. The University Library also offers information about academic integrity and how you can protect yourself. If you are unsure about whether a passage in your writing constitutes plagiarism, you are encouraged to seek help from the teaching team or from the Sweetland Writing Center. Be sure to plan sufficiently ahead in your writing so that you can receive and incorporate feedback if you are uncertain about the boundaries of plagiarism. AI-generated text tools: ChatGPT is a new AI product that has become very popular over the last few months. It is a generative AI tool that uses large language models to produce answers and responses to questions. There are many potentially productive uses of ChatGPT (and likely some important ethical questions), but the use of ChatGPT or any other AI-generated text tool to write text for class assignments is not allowed. Any assignments found to have used ChatGPT to write text for course assignments will earn zero points.

## Accommodations

Refer to the Accommodations for Students with Disabilities section of the UMSI Student Handbook. Information regarding SSD, the services available to students with disabilities, and the rights and responsibilities of students with disabilities is available on the Services for Students with Disabilities website. If you have questions about obtaining authorized accommodations, please contact the MADS Academic Advising Team at umsi.advising.mads@umich.edu .

## Library Access

Refer to the U-M Library's information sheet on accessing library resources from off-campus. For more information regarding library support services, please refer to the U-M Library Resources section of the UMSI Student Handbook (access to the Student Orientation course required).

## Student Mental Health

Refer to the University's Resources for Stress and Mental Health website for a listing of resources for students.

## Student Services

Refer to the Introduction to UMSI Student Life section of the UMSI Student Handbook (access to the Student Orientation course required).

## V. Acknowledgements

2022 (v2.0): This course has evolved (including a major iteration in Summer 2022) in scope, structure, and content thanks to the perspectives, feedback, and continuous investment of attention by members of the instructional team, MADS students, and CAI staff. Thank you all! 2019 (v1.0): Thank you to Casey Fiesler, Natalie Garrett, and Nathan Beard's work on ethics and their ethics syllabi research project. This syllabus is in debt to the syllabi of Paul Conway. Thanks for specific suggestions from Solon Barocas and Karrie Karahalios. Thank you to our generous beta-testers and guest speakers, as well as to James Wexler, Fernanda Viegas, and Google PAIR (People + AI Research). Finally, general thanks to the Ethical Tech Collective and the FAT\* community.
